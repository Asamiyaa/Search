kafkaSource
0.架构:   https://www.processon.com/view/5fff01bb6376897ae0b610ff#map
1.与其他mq对比：
1.如何和zookeeper结合，完成了哪些      https://www.processon.com/view/5f1fd7d5e401fd181aded65a
2.高吞吐体现在哪里
3.分区 - 同步
4.选举
5.幂等
6.代码上如何做到高效对接
7.

6.Kafka【入门】就这一篇！ https://www.wmyskxz.com/2019/07/17/kafka-ru-men-jiu-zhe-yi-pian/ + kafka源码整理以及笔记整理 == 解决方案
                        1.kafka 后台命令登录和topic查看，而不是完全依赖前台  判断是否有消息阻塞
                        2.Kafka运维填坑 ：https://www.jianshu.com/p/d2cbaae38014
                        3.kafka书籍：http://kafkadoc.beanmr.com/020_api/01_api_cn.html#highlevelconsumerapi
                        4.Kafka导致重复消费原因和解决方案 ： https://segmentfault.com/a/1190000023282843
                        5.消息回溯 

0.代码剖析
    1.
    2.



=================

0.架构:   https://www.processon.com/view/5fff01bb6376897ae0b610ff#map
          kafka架构.png

1.与其他mq对比：
        共同点：
         1.对于数据密集型应用来说，如何应对数据量激增、数据复杂度增加以及数据变化速率变快，是彰显大数据工程师、架构师功力的最有效表征。
         2.异步(解耦)：有效隔离上下游业务
         3.削峰：将上游突增的流量缓存起来，以平滑的方式传导到下游子系统中，避免了流量的不规则冲击
         4.

        不同点:
            1.kafka特点:一套框架就能在实际业务系统中实现消息引擎应用、应用程序集成、分布式存储构建，甚至是流处理应用的开发与部署
                        1.流处理：流处理在意的是如何处理无限数据集的问题
                        2.流处理组件 Kafka Streams,Apache Storm、Apache Spark 和 Apache Flink 同等级的实时流处理平台。
            2.kafka:消息引擎系统  这类系统引以为豪的消息传递属性，就像引擎一样，具备某种能量转换传输的能力
            3.


2.特点
        1.消息格式
            1. CSV、XML 亦或是JSON；又或者你可能熟知国外大厂开源的一些序列化框架，比如 Google 的 ProtocolBuffer 或 Facebook 的 Thrift  ； Kafka 的选择：它使用的是纯二进制的字节序列
        2.传输方式
            1.点对点模型
            2.发布 / 订阅模型


    ===> 思考：kafka，怎么解决实时结果响应问题呢？比如秒杀商品，生产者产生订单，消费者处理订单结果，那这结果如何实时返回给用户呢？
              这个场景使用Kafka Streams比较适合，它就是为read-process-write场景服务的
   
    ===> 思考:是不是上游发送消息成功就认为业务成功了，可能下游过很久去消费，那实时性要求很高的业务怎么办呢?
              mq和rpc的区别往大了说属于数据流模式（dataflow mode）的问题。
              我们常见的数据流有三种：1. 通过数据库；2. 通过服务调用（REST/RPC）; 3. 通过异步消息传递（消息引擎，如Kafka）
              RPC和MQ是有相似之处的，毕竟我们远程调用一个服务也可以看做是一个事件，
              但不同之处在于：1. MQ有自己的buffer，能够对抗过载（overloaded）和不可用场景
                            2. MQ支持重试
                            3. 允许发布/订阅模式当然它们还有其他区别。应该这样说RPC是介于通过数据库和通过MQ之间的数据流模式。
    ===> 思考：kafka的容许丢消息，如何看待？违背了一致性么
    ===> 思考：kafka突然宕机或者临时停止服务进行更新，上游服务的消息该怎么正确更好处理呢？怎么保证消息的能够在kafka恢复工作的时候正确传递
            如果是升级Kafka这种主动停机，应该采用rolling upgrade来做，不至于服务中断。如果是大面积突然宕机，快速处理反而是最重要的。如果在乎上游系统的消息delivery语义，增加retries的同时试试幂等producer吧

    ===> 思考：kafka目前主要在大数据领域、金融领域多是rocketmq。如何理解？是否因为kafka不能保证消息丢失造成的呢/






1.如何和zookeeper结合，完成了哪些      https://www.processon.com/view/5f1fd7d5e401fd181aded65a
1.实现高可用的方式：
        1.不同的 Broker 分散运行在不同的机器
                1.Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。
        2.备份机制（Replication）
                1.领导者副本（LeaderReplica）对外提供服务，这里的对外指的是与客户端程序进行交互
                2.追随者副本（Follower Replica）被动地追随领导者副本而已，不能与外界进行交互。(mysql则是follower提供读)
        3.消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助.假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）.存在许多问题 ， p2p可以理解为特殊版的pub/sub

2.实现伸缩性Scalability
        1.分区  
                1.分区（Partitioning）。如果你了解其他分布式系统，你可能听说过分片、分区域等提法，比如 MongoDB 和 Elasticsearch 中的 Sharding、HBase 中的Region，其实它们都是相同的原理     <=== 领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了,进行数据切割
                2.消息在分区中的位置信息由一个叫位移（Offset）的数据来表征

    ===>三层架构
                第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
                第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。不同分区的领导者和追随者不同时在一个机器上，减少压力
                第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。最后，客户端程序只能与分区的领导者副本进行交互。
                    消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。--消费者维护自己

3.Kafka Broker 是如何持久化数据
        1.顺序io
            Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作。通过日志段（Log Segment）机制。当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的‘
        2.

4.高吞吐量
        1.cosumer group 
            1.多个消费者实例共同组成的一个组，同事消费多个区分以实现高吞吐。组：多个消费者消费一个生产者生产的数据，并能保证每个消费者消费的消息不会重复，做到并行消费


        ===>思考：请思考一下为什么 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务？
            1，kafka的分区已经让读是从多个broker读从而负载均衡，不是MySQL的主从，压力都在主上；
            2，kafka保存的数据和数据库的性质有实质的区别就是数据具有消费的概念，是流数据，kafka是消息队列，所以消费需要位移，而数据库是实体数据不存在这个概念，如果从kafka的follower读，消费端offset控制更复杂；
            3，生产者来说，kafka可以通过配置来控制是否等待.

            https://www.zhihu.com/question/327925275/answer/705690755



        ===>思考：kafka是按照什么规则将消息划分到各个分区的？2、既然同一个topic下的消息分布在不同的分区，那是什么机制将topic、partition、record关联或者说管理起来的？
            1. 如果producer指定了要发送的目标分区，消息自然是去到那个分区；
               否则就按照producer端参数partitioner.class指定的分区策略来定；如果你没有指定过partitioner.class，那么默认的规则是：           看消息是否有key，如果有则计算key的murmur2哈希值%topic分区数；
                          如果没有key，按照轮询的方式确定分区。
            2. 这个层级其实是逻辑概念。在物理上还是以日志段（log segment）文件的方式保存，日志段文件在内存中有对应的Java对象，里面关联了你说的这些。


5.kafka作为流处理平台和 Apache Storm、Apache Spark 和 Apache Flink对比
            1.容易实现端到端的正确性
                1.要实现正确性和提供能够推导时间的工具。实现正确性是流处理能够匹敌批处理的基石。正确性一直是批处理的强项
                2.你只能保证在 Spark 或 Flink 内部，这条消息对于状态的影响只有一次。但是计算结果有可能多次写入到 Kafka，因为它们不能控制Kafka 的语义处理。相反地，Kafka 则不是这样，因为所有的数据流转和计算都在 Kafka内部完成，故 Kafka 可以实现端到端的精确一次处理语义???
            2.定位
                1.Kafka 提供类似于集群调度、弹性部署等开箱即用的运维特性，你需要自己选择适合的工具或系统来帮助 Kafka 流处理应用实现这些功能。对于数据量较少，公司较小的需求来说，没有必要搭建重量级的完整性平台。后者需要hadoop相关支持，hdfs,yarn,....
                后者通过将消息写入文件，在由应用调用方式进行map-reduce操作计算完成，前者提供了从 '消息维度'直接处理思路，考验消费者
            3.分布式存储


6.生产部署
            1.操作系统
                    1.I/O 模型的使用
                             1.5 种类型：阻塞式 I/O、非阻塞式 I/O、I/O 多路复用、信号驱动I/O 和异步 I/O。
                             每种 I/O 模型都有各自典型的使用场景，比如 Java 中 Socket 对象的阻塞模式和非阻塞模式就对应于前两种模型；
                             而 Linux 中的系统调用 select 函数就属于 I/O多路复用模型；
                             大名鼎鼎的 epoll 系统调用则介于第三种和第四种模型之间；
                             至于第五种模型，其实很少有 Linux 系统支持，反而是 Windows 系统提供了一个叫 IOCP 线程模型属于这一种。
                    
                            2. Kafka 客户端底层使用了 Java的 selector。 linux上执行时最好得
                    2.数据网络传输效率
                            1.Kafka 需要在磁盘和网络间进行大量数据传输 。 
                            零拷贝（Zero Copy）技术，就是当数据在磁盘和网络进行传输时避免昂贵的内核态数据拷贝从而实现快速地数据传输
                    3.社区支持度
            2.磁盘
                    1.机械盘 ：
                    Kafka 大量使用磁盘不假，可它使用的方式多是顺序读写操作，一定程度上规避了机械磁盘最大的劣势，即随机读写操作慢。
                    2.磁盘阵列（RAID）：
                            1.提供冗余的磁盘存储空间
                            2.提供负载均衡
                             Kafka 自己实现了冗余机制来提供高可靠性；另一方面通过分区的概念，Kafka 也能在软件层面自 行实现负载均衡。

            3.磁盘容量
                    1.容量估算
                        假设你所在公司有个业务每天需要向 Kafka 集群发送 1 亿条消息，每条消息保存两份以防止数据丢失，另外消息默认保存两周 时间。现在假设消息的平均大小是 1KB，那么你能说出你的 Kafka 集群需要为这个业务预 留多少磁盘空间吗？

                        每天 1 亿条 1KB 大小的消息，保存两份且留存两周的时间，那么总的空 间大小就等于 1 亿 * 1KB * 2 / 1000 / 1000 = 200GB。一般情况下 Kafka 集群除了消息 数据还有其他类型的数据，比如索引数据等，故我们再为这些数据预留出 10% 的磁盘空 间，因此总的存储容量就是 220GB。既然要保存两周，那么整体容量即为 220GB * 14， 大约 3TB 左右。Kafka 支持数据的压缩，假设压缩比是 0.75，那么最后你需要规划的存储 空间就是 0.75 * 3 = 2.25TB。

            4.带宽(问题 60%)
                    1.假设你公司 的机房环境是千兆网络，即 1Gbps，现在你有个业务，其业务目标或 SLA 是在 1 小时内处 理 1TB 的业务数据。那么问题来了，你到底需要多少台 Kafka 服务器来完成这个业务呢？

                    由于带宽是 1Gbps，即每秒处理 1Gb 的数据，假设每台 Kafka 服务 器都是安装在专属的机器上。通常情况下你只能假设 Kafka 会用到 70% 的带宽资源( 70% 的阈值就有网络丢包的可能性了)，因为总要为其 他应用或进程留一些资源。你不能让 Kafka 服务器常规性使用这么多资源， 故通常要再额外预留出 2/3 的资源，即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps.有了 240Mbps，我们就可以计算 1 小时内处理 1TB 数据所需的服务器数量了。根 据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。如果 消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台。

7.配置参数  === 从参数角度，可以看到优秀软件在思考方面不同维度得考量,全面。
            1.brocker参数
                    1.log.dirs：/home/kafka1,/home/kafka2,/home/kafka3 最好保证这些目录挂载到不同的物理 磁盘上
                            1.提升读写性能：比起单块磁盘，多块物理磁盘同时读写数 据有更高的吞吐量。
                            2.故障转移：即 Failover。 Broker 使 用的任何一块磁盘挂掉了，整个 Broker 进程都会关闭。 坏掉的磁盘上的数 据会自动地转移到其他正常的磁盘上，而且 Broker 还能 正常工作。改进正是我们舍弃 RAID 方案的基 础：没有这种 Failover 的话，我们只能依靠 RAID 来提 供保障。
            2. ZooKeeper - 分布式协调框架，负责协调管理并保 存 Kafka 集群的所有元数据信息
                            1.集群都有哪些Broker 在运行
                            2.、创建了哪些 Topic，每个 Topic 都有多少 分区以及这些分区的 Leader 副本都在哪些机器上等信息

                            1.zookeeper.connect：zk1:2181,zk2:2181,zk3:2181  chroot 
            3.brocker连接
                            listeners：学名叫监听器，其实就是告诉外部连接者 要通过什么协议访问指定主机名和端口开放的 Kafka 服 务。 三元组的格式为<协议名称，主机 名，端口号>
                            advertised.listeners：和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的， 就是说这组监听器是 Broker 用于对外发布的。 
                            host.name/port：列出这两个参数就是想说你把它们 忘掉吧，压根不要为它们指定值，毕竟都是过期的参数 了。

            4.topic
                            1.auto.create.topics.enable：是否允许自动创建 Topic。 
                                    建议false
                            faunclean.leader.election.enable：是否允许 Unclean Leader 选举。 
                                    只有保存数据比较多的那些副本才有资格竞选，那些落
                                    后进度太多的副本没资格做这件事。
                            auto.leader.rebalance.enable：是否允许定期进 行 Leader 选举。
                                    换leader。建议false
                            retention.ms：规定了该 Topic 消息被保存的时长。 默认是 7 天
                            retention.bytes：规定了要为该 Topic 预留多大的磁 盘空间 通常 -1

            5.数据留存
                            1.log.retention.{hour|minutes|ms}：这是个“三 兄弟”，都是控制一条消息数据被保存多长时间。从优先 级上来说 ms 设置最高、minutes 次之、hour 最低。 很多公司把 Kafka 当做存储来使 用，那么这个值就要相应地调大。

                            2.log.retention.bytes：这是指定 Broker 为消息保存 的总磁盘容量大小。
                                多租户使用限定
                            3. message.max.bytes：控制 Broker 能够接收的最大消 息大小。


            6.jvm参数
                            1. JVM 堆大小设置成 6GB   Kafka Broker 在与客户端进行交互时会在 JVM 堆上创建大量的 ByteBuffer 实例，Heap Size 不能太小
                            2.垃圾回收器
                                1.Broker 所在机器的 CPU 资源非常充裕，建议使用 CMS 收集器。启用方法是指定XX:+UseCurrentMarkSweepGC。 2.使用吞吐量收集器。开启方法是指定XX:+UseParallelGC。


            7.操作系统参数
                            1.文件描述符限制
                                    ulimit -n 1000000  ==> Too many open files
                            2.文件系统类型
                            3.Swappiness
                                    swappniess 配置成一个接近 0 但不为 0 的值，比如 1.使其可以有报警调优的机会
                            4.提交时间
                                    刷盘 - 5s - 

2.高吞吐体现在哪里
            1.分区：提供负载均衡的能力，或者说对数据进 行分区的主要原因，就是为了实现系统的高伸缩性 （Scalability）。不同的分区能够被放置到不同节点的机器 上，而数据的读写操作也都是针对分区这个粒度而进行的， 这样每个节点的机器都能独立地执行各自分区的读写请求处 理。并且，我们还可以通过添加新的节点机器来增加整体系 统的吞吐量。
                    分区策略：
                            1.轮询策略  Round-robin 
                            2.随机策略  Randomness 
                            3.按消息键保序策略  Key-ordering  Kafka 允许为每条消息定义消息键它可以是一个有着明确业务含义的字符

                                        Math.abs(key.hashCode()) % partitions.size();

                                有序又使用高吞吐：在消息体中都封装了固定的标志位，后来 我就建议他们对此标志位设定专门的分区策略，保证同一标 志位的所有消息都发送到同一分区，这样既可以保证分区内 的消息顺序
                            4.地理位置的分区策略、ip定制化



            2.压缩  希望以较 小的 CPU 开销带来更少的磁盘占用或更少的网络 I/O 传输
                    1.v2版本中对整个消息set统一压缩。
                    2.v2版本中 CRC 校验,对set校验而不是每条消息  --> 金融行业呢？
                    3.压缩地方
                            生产者端和 Broker 端。
                            Kafka 会将启用了哪种压缩算法封装进消息集合中，这样当 Consumer 读取 到消息集合时，它自然就知道了这些消息使用的是哪种压缩算
                            zstd 压缩

3.扩展
            1.拦截器  <--因为框架要提供给别人口子-- 设计模式 <--if逻辑 主次分明 职责--
                    1.AddTimeStampInterceptor / UpdateCounterInterceptor /消费者ConsumerInterceptor 
                            1.onSend / onAcknowledgement  的调用要早于 callback 的调用
                                1.onAcknowledgement这个方法和 onSend 不是在同一个线程中被调用的， 因此如果你在这两个方法中调用了某个共享可变对象，一定要保证线程安全哦。
                                2.这个方法处在 Producer 发送的主路径中，所以最好别放一些太重的逻辑进 去，否则你会发现你的 Producer TPS 直线下降。 === 隔离

                                1. onConsume：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处 理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。 
                                2. onCommit：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记 账类的动作，比如打日志等。

                    2.Kafka 拦截器可以 应用于包括客户端监控、端到端系统性能检测(trace)、消息审计(message audi)等多种功能在内的场景。
                                1.用当前的时钟时间减去封装在消息中的创建时间，然后累计得到这批消息总的端到端处理延 时并更新到 Redis 中。种端到端的指标监控能够从全局角度俯察和审视业务运行情况，及时查看 业务是否满足端到端的 SLA 目标

            2.控制器(activeController)
                    1.作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群
                    2.特点：
                            1.集群中任意一台 Broker 都能充当控制 器的角色
                            2.只能有一个 Broker 成为控制器，


                ====>>>> zookeeper
                        1.https://blog.csdn.net/lipinganq/article/details/81029499
                        2.Zookeeper到底是干嘛的 : http://www.uml.org.cn/zjjs/202006052.asp
                        3.特点：
                                1.临时 znode 则与创建该 znode 的 ZooKeeper 会话绑定，一旦会话结束，该节点会被自动删除
                                2.ZooKeeper 赋予客户端监控 znode 变更的能力，即所谓的 Watch 通知功能。监听器
                                3.ZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。
                    3.kafka使用zookeeper创建znode
                    4.第一个成功创建 /controller 节点的 Broker 会被指定为控制器。
                        1.主题管理（创建、删除、增加分区）
                        2.分区重分配
                        3.Preferred 领导者选举
                        4.集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）
                        5.数据服务 所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存 中的缓存数据。

                        他不是从 db 中读取信息，而是从zookeeper中读取
                    5.failover == 故障转移
                        1.当 Broker 0 宕机后，ZooKeeper 通过 Watch 机制感知 到并删除了 /controller 临时节点。之后，所有存活的 Broker 开始竞选新的控制器身份。 



                 TODO:===>>> 把多线程的 方案改成了单线程加事件队列的方案。
                             将之前同步操作 ZooKeeper 全部改为异步操作
                             赋予 StopReplica 请求更高的优先级，使它能够得到 抢占式的处理。



问题：
            rocketmq的name server和用zk的区别和优劣势？






3.分区 - 同步
4.选举
5.幂等
6.代码上如何做到高效对接
7.如何做到的一致性
        1.(可靠性)
           精确消费一次
                
                1.幂等    
                        1.重复消息场景
                                1.broker接受到消息，返回ack给producer时，丢失，producer重试导致消息重复。
                                        1.如果你允许消息丢失，那么设置最多一次
                                        2.如果你不允许丢失，只能处理重复消费
                                2.kafka实现  Kafka 自动帮你做消息的重复去重
                                        1. props.put(“enable.idempotence”, ture)
                                           props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CO NFIG， true)。

                                                局限性：
                                                        1.一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消 息，它无法实现多个分区的幂等性
                                                        2.只能实现单会 话上的幂等性，不能实现跨会话的幂等性

                                        2.消费方做幂等从库中对比 <--- 从数据库
                                    
                                    ==>想实现多分区以及多会话上的消息 无重复

                2.事务 ACID 即原子性（Atomicity）、一致性 (Consistency)、隔离性 (Isolation) 和持久性 (Durability)
                        1.事务型 Producer
                                1.和幂等性 Producer 一样，开启 enable.idempotence = true。
                                2.设置 Producer 端参数 transctional. id。最好为其设置一 个有意义的名字。
                                3.如 initTransaction、 beginTransaction、commitTransaction 和 abortTransaction

                                    ==>注意的是productor多条消息的事务，而不是发送和消费 == vs ==> rocketmq中事务一致性。

          持久性
                1.





        2.异常、crash恢复、同步
                0.在 Kafka 的世界里什么 才算是消息丢失，或者说 Kafka 在什么情况下能保证消息不丢失。这点非常关键，因为很 多时候我们容易混淆责任的边界，如果搞不清楚事情由谁负责，自然也就不知道由谁来出解 决方案了。
                1.Kafka 只对“已提交”的消息（committed message）做 ‘有限度’ 的持久化保证。
                        1.已提交：
                                1.并不是send...完事。
                                    当 Kafka 的若干个 Broker 成 功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。
                                    
                                2.。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会 丢失。
                        2.常见 ‘丢消息’情况
                                1. producer.send(msg, callback)而不是producer.send(msg) 
                                            1.网络 抖动，导致消息压根就没有发送到 Broker 端；
                                            2.消息本身不合格导致 Broker 拒绝接收 （比如消息太大了，超过了 Broker 的承受能力）等

                                                        1.消息重试
                                                        2.转换格式

                                2.消费者程序丢失数据
                                            1.维持先消费消息（阅读），再更新位移（书签）的顺序即可。这样就能最大限度地保 证消息不丢失。问题是消息的重复处理

                                3.如果是多线程异步处理消费消息，Consumer 程序不要开 启自动提交位移，而是要应用程序手动提交位移。编码困难
                                        其实这种情况单线程也是存在的，即：未正确完整处理程序，只是读取消费。

                                        vs tcp握手,为什么kafka不适用http/其他协议
                                            1.java生产者如何管理tcp连接?
                                                1.开发客户端时，人们能够利用 TCP 本身提供的一些高级功能，比如多路复用请求以及同时轮询 多个连接的能力。
                                                        1.多路复用;指将两 个或多个数据流合并到底层单一物理连接中的过程.其实严格来说， TCP 并不能多路复用，它只是提供可靠的消息交付语义保 证，比如自动重传丢失的报文。

                                                2.何时建立tcp连接？
                                                        1.new vs send
                                                             new 会和 ‘ 所有 ’的brocker构建连接
                                                        2.Producer 向某一台 Broker 发送了 METADATA 请求，尝 试获取集群的元数据信息——这就是前面提到的 Producer 能够获取集群所有信息的方法。
                                                3.tcp创建场景？<-- 耗时
                                                        1.。当 Producer 更新 了集群的元数据信息之后，如果发现与某些 Broker 当前没 有连接，那么它就会创建一个 TCP 连接
                                                        2.发送消息

                                             2.java消费者如何管理tcp连接?
                                                        1.和生产者不同的是，构建 KafkaConsumer 实例时是不会创建任何 TCP 连接的
                                                        2.TCP 连接是在调用 KafkaConsumer.poll 方法时被创建的
                                                                1.发起 FindCoordinator 请求时。
                                                                2.连接协调者时。
                                                                    只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等
                                                                3.消费数据时

                                                        3.



                                                ==> 那么kafka集群就是3-4台服务器吗？还是有1000台的可能？




                                4.增加主题
                                        “不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区 前，Producer 发送的这些消息就全部“丢失”了


                2.综上所述可以采取措施：
                                1. 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一 定要使用带有回调通知的 send 方法。 
                                2. 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。 如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。 这是最高等级的“已提交”定义。 
                                3. 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到 的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了
                                        retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。 
                                4. 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪 些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么 它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false， 即不允许这种情况的发生。
                                5. 设置 replication.factor >= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将 消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 
                                6. 设置 min.insync.replicas > 1。这依然是 Broker 端参数，控制的是消息至少要被写入 到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千 万不要使用默认值 1。 
                                    为了约束2中all=1的情况
                                7. 确保 replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂 机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要 在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 
                                8. 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设 置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程 处理的场景而言是至关重要的。


                3.消费者滞后程度 --> 水位 --> 宕机后如何选举
                        1. Consumer Lag ： 滞后程度，就是指消费者当前落后于生产者的程度。
                        2.特点：
                                1.分区级别，得到主题lag,需要加起来
                                2. Lag 值应该很小，甚至是接近于 0 
                                        1.消息堆积
                                        2.有可能导致它消费的数据已经不 在操作系统的页缓存中了，那么这些数据就会失去享有 Zero Copy 技术的资格。这样的 话，消费者就不得不从磁盘上读取它们，这就进一步拉大了与生产者的差距，进而出现马太 效应

                        3.监控
                                1. 使用 Kafka 自带的命令行工具 kafka-consumer-groups 脚本。 
                                    ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test
                                2. 使用 Kafka Java Consumer API 编程。 
                                     Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedO                    return endOffsets.entrySet().stream().collect(Collectors.toMap(entry                            entry -> entry.getValue() - consumedOffsets.get(entry.getKey                } 
                                3. 使用 Kafka 自带的 JMX 监控指标。
                                     kafka.consumer:type=consumer-fetch-managermetrics,client-id=“{client-id}”的 JMX 指标
                                     这里的 Lead 值是指消费者最新消费 消息的位移与分区当前第一条消息位移的差值
                                     lead：逆向指标  lead在左，lag在右
                                     records-lag-max 
                                     records-lead-min

                                     Kafka 的消息是有留存时间设置的，默认是 1 周. Lag 值从 100 万增加到 200 万这件事情，远不如 Lead 值从 200 减少到 100 这件事来得重要。在实际生产环境中，请你一定要同时监控 Lag 值和 Lead 值。

                4.副本机制(分布式系统技术) --- kafka高可用，高持久性基石
                            1.Replication
                                    1. 提供数据冗余。即使系统部分组件失效，系统依然能够继续运转，因而增加了整体可用 性以及数据持久性。 
                                    2. 提供高伸缩性。支持横向扩展，能够通过增加机器的方式来提升读性能，进而提高读操 作吞吐量。 
                                    3. 改善数据局部性。允许将数据放入与用户地理位置相近的地方，从而降低系统延时。
                            2.特点
                                    1.副本的 概念实际上是在分区层级下定义的，每个分区配置有若干个副本
                                    2.本质就是一个只能 ‘ 追加写 ’消息的提交日志
                            3.如何同步多副本
                                    1.用基于领导者（Leader-based）
                                            1.追随者副本只是拉取信息同步，不对外提供服务。
                                                它既不能像 MySQL 那样帮助领 导者副本“抗读”，也不能实现将某些副本放到离客户端近的地方来改善数据局部性。

                                                好处：
                                                        1.方便实现Read-your-writes 
                                                            由于副本同步是异步的， 因此有可能出现追随者副本还没有从领导者副本那里拉取到最新的消息，从而使得客户端看 不到最新写入的消息。(微博发表)
                                                        2.方便实现单调读（Monotonic Reads)
                                                            第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性。但是，如果 所有的读请求都是由 Leader 来处理，那么 Kafka 就很容易实现单调读一致性。
                                    2.ISR(In-sync Replicas)
                                            1.因为副本机制导致副本和领导者间存在差距风险
                                            2.ISR 中的副 本都是与 Leader 同步的副本
                                            3.ISR 不只是追随者副本集 合，它必然包括 Leader 副本。甚至在某些情况下，ISR 只有 Leader 这一个副本。

                                        如何判断flower和领导者同步呢？判断依据是什么/
                                            1.不是看与leader消息数差距，而是 Broker 端参数 replica.lag.time.max.ms 参数值。
                                                Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒。这就是说，只 要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒

                                                同步过程的速度持续慢于 Leader 副本的消息写入速度， 那么在 replica.lag.time.max.ms 时间后，此 Follower 副本就会被认为是与 Leader 副本 不同步的，因此不能再放入 ISR 中。此时，Kafka 会自动收缩 ISR 集合，将该副本“踢 出”ISR。

                                                ==> 同一条消息处理，leader和follower处理相差10s,就认为是不同步的

                                            ==> 那就是选择了ISR中的任意一个作为leader，不还是存在消息丢失么？？？
                                答：不会丢失。还是那句话：Kafka只对已提交消息做持久化保证。如果你设置了最高等级 的持久化需求（比如acks=all），那么follower副本没有同步完成前这条消息就不算已提交，也就 不算丢失了。

                                    所以说：ISR中才分高水位、低水位，其实消费在低水位下。而‘是否是已提交’则是判断指定副本数是否满足
                                           而不是说leader的水位是提交的。所以不存在丢失。


                                            2.Unclean 领导者选举（Unclean Leader Election）
                                                 1.如果isr中从者都为0，那么，选举这种副本的过 程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否 允许 Unclean 领导者选举。

                                                 2.若设置为允许，那么一定存在leader，提供可用。但存在消息丢失
                                                 3.一个分布式系统通常只能同时满足一致性 （Consistency）、可用性（Availability）、分区容错性（Partition tolerance）-是由于网络故障部分网络被切 断，与其他网络断开了连接 。。中的两 个。显然，在这个问题上，Kafka 赋予你选择 C 或 p的权利
                                                 4.根据需要判断是否开启unclean,不建议，丢失了一致性


                                            3.高水位和Leader Epoch
                                                  0.leader/flower高水位及leo更新:http://zhongmingmao.me/2019/09/20/kafka-high-watermark-leader-epoch/

                                            4.什么叫与 Leader 副本保持同步
                                                1. 该远程 Follower 副本在 ISR 中。 
                                                2. 该远程 Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参 数 replica.lag.time.max.ms 的值。如果使用默认值的话，就是不超过 10 秒。

                                                因为目前某个副本能否进入 ISR 就是靠第 2 个条件判 断的。但有些时候，会发生这样的情况：即 Follower 副本已经“追上”了 Leader 的进 度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 1 个条件的话， 就可能出现某些副本具备了“进入 ISR”的资格，但却尚未进入到 ISR 中的情况。此时，分 区高水位值就可能超过 ISR 中副本 LEO，而高水位 > LEO 的情形是不被允许的。

                5.选举
                              1.控制器（Broker）选主
                                  所谓控制器就是一个Borker，在一个kafka集群中，有多个broker节点，但是它们之间需要选举出一个leader，其他的broker充当follower角色。集群中第一个启动的broker会通过在zookeeper中创建临时节点/controller来让自己成为控制器，其他broker启动时也会在zookeeper中创建临时节点，但是发现节点已经存在，所以它们会收到一个异常，意识到控制器已经存在，那么就会在zookeeper中创建watch对象，便于它们收到控制器变更的通知。
                                  那么如果控制器由于网络原因与zookeeper断开连接或者异常退出，那么其他broker通过watch收到控制器变更的通知，就会去尝试创建临时节点/controller，如果有一个broker创建成功，那么其他broker就会收到创建异常通知，也就意味着集群中已经有了控制器，其他broker只需创建watch对象即可。
                                  如果集群中有一个broker发生异常退出了，那么控制器就会检查这个broker是否有分区的副本leader，如果有那么这个分区就需要一个新的leader，此时控制器就会去遍历其他副本，决定哪一个成为新的leader，同时更新分区的ISR集合。
                                  如果有一个broker加入集群中，那么控制器就会通过Broker ID去判断新加入的broker中是否含有现有分区的副本，如果有，就会从分区副本中去同步数据。
                                  集群中每选举一次控制器，就会通过zookeeper创建一个controller epoch，每一个选举都会创建一个更大，包含最新信息的epoch，如果有broker收到比这个epoch旧的数据，就会忽略它们，kafka也通过这个epoch来防止集群产生“脑裂”。

                              2.分区多副本选主
                                  在kafka的集群中，会存在着多个主题topic，在每一个topic中，又被划分为多个partition，为了防止数据不丢失，每一个partition又有多个副本，在整个集群中，总共有三种副本角色：
                                  首领副本（leader）：也就是leader主副本，每个分区都有一个首领副本，为了保证数据一致性，所有的生产者与消费者的请求都会经过该副本来处理。
                                  跟随者副本（follower）：除了首领副本外的其他所有副本都是跟随者副本，跟随者副本不处理来自客户端的任何请求，只负责从首领副本同步数据，保证与首领保持一致。如果首领副本发生崩溃，就会从这其中选举出一个leader。
                                  首选首领副本：创建分区时指定的首选首领。如果不指定，则为分区的第一个副本。
                                  follower需要从leader中同步数据，但是由于网络或者其他原因，导致数据阻塞，出现不一致的情况，为了避免这种情况，follower会向leader发送请求信息，这些请求信息中包含了follower需要数据的偏移量offset，而且这些offset是有序的。
                                  如果有follower向leader发送了请求1，接着发送请求2，请求3，那么再发送请求4，这时就意味着follower已经同步了前三条数据，否则不会发送请求4。leader通过跟踪 每一个follower的offset来判断它们的复制进度。
                                  默认的，如果follower与leader之间超过10s内没有发送请求，或者说没有收到请求数据，此时该follower就会被认为“不同步副本”。而持续请求的副本就是“同步副本”，当leader发生故障时，只有“同步副本”才可以被选举为leader。其中的请求超时时间可以通过参数replica.lag.time.max.ms参数来配置。
                                  我们希望每个分区的leader可以分布到不同的broker中，尽可能的达到负载均衡，所以会有一个首选首领，如果我们设置参数auto.leader.rebalance.enable为true，那么它会检查首选首领是否是真正的首领，如果不是，则会触发选举，让首选首领成为首领。

                              3.消费组选主
                                  在kafka的消费端，会有一个消费者协调器以及消费组，组协调器GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader，那么如何选举的呢？
                                  如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader，如果某一个时刻leader消费者由于某些原因退出了消费组，那么就会重新选举leader，如何选举？
                                  private val members = new mutable.HashMap[String, MemberMetadata]
                                  leaderId = members.keys.headOption
                                  上面代码是kafka源码中的部分代码，member是一个hashmap的数据结构，key为消费者的member_id，value是元数据信息，那么它会将leaderId选举为Hashmap中的第一个键值对，它和随机基本没啥区别。

        3.性能加速
                    1.

                    2.多线程consumer处理
                                1.但在很多场景下，Consumer 端是有非阻塞需求的，比如在流处 理应用中执行过滤（filter）、连接（join）、分组（group by）等操作时就不能是阻塞式 的。基于这个原因，社区为新版本 Consumer 设计了单线程 + 轮询的机制。？？？
                                2. KafkaConsumer 不是线程安全
                                    1.消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。
                                3.方案：
                                    1.多线程+kafkaconsumer实例
                                            优点：
                                                    1.方便实现
                                                    2.速度快，无线程间交互开销
                                                    3.易于维护分区内消费顺序
                                            缺点：
                                                    1.占用资源，内存，tcp资源..
                                                    2.线程数受限于分区数，扩展性差
                                                    3.线程自己处理消息容易超时，从而引发rebalance

                                    2.单线程+单kafkaconsumer实例+消息处理worker (多组线程协调)   
                                            优点:
                                                    1.可独立扩展消费获取线程数和worker线程数
                                                    2.伸缩性好
                                            缺点:
                                                    1.实现难度大
                                                    2.那一维护分区内消息消费顺序
                                                        不必考虑两者之间是否相互影 响。如果你的消费获取速度慢，那么增加消费获取的线程数即可；如果是消息的处理速度 慢，那么增加 Worker 线程池线程数即可。
                                                    3.处理链路拉长，不宜于位移提交管理
                                        问题：如何管理线程池和提交位移?

                                    TODO:方案二不就是reactor模型么。将委派线程和worker线程分开  <==      kafka其实就是这么处理productor到broker ***借助可以改造consumer

                                                    1.Acceptor 线程只是用于请求分发，不涉及具体的逻辑处理，非常得轻量级，因此有很高的吞吐量表现。而这些工作线程可以根据实际业务处理需要任意增减，从而 动态调节系统负载能力。

                                                    2.Acceptor默认3，work线程默认8
                                                    3.当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个共享请求队列中。 Broker 端还有个 IO 线程池，负责从该队列中取出请求，执行真正的处理 。 注意这里不是直接调用worker线程池来直接处理...
                                                    4.请求队列是所有网络线程共享的，而响应 队列则是每个网络线程专属的

                                                    5.Purgatory : 。它是用来缓存延时请求（Delayed Request）的。所谓延时请求，就是那些一 时未满足条件不能立刻处理的请求。比如设置了 acks=all 的 PRODUCE 请求，一旦设置了
                                                    acks=all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该 请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存 在 Purgatory 中。稍后一旦满足了完成条件，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。

                                                    双队列设计，分别存放数据类和控制类请求，每次先处理完所有控制类请求再处理数据类 请求。









         4.扩展  kafka connector / kafka manager(监控)  自身扩展和对外扩展
                    1.Consumer Group 
                            1.是 Kafka 提供的可扩展且 具有容错性的消费者机制

                                    1.每个分区只能由 同一个消费者组内的一个 Consumer 实例来消费==> 说明组和分区是对应的
                                    2.Consumer Group 下可以有一个或多个 Consumer 实 例。这里的实例可以是一个单独的进程，也可以是同一进 程下的线程。在实际场景中，使用进程更为常见一些。 
                                    3. Group ID 是一个字符串，在一个 Kafka 集群中，它标识 唯一的一个 Consumer Group。
                            2. kafka group 推出
                                    1.传统的消息队列模型的缺陷在于消息 一旦被消费，就会从队列中被删除，而且只能被下游的一个 Consumer 消费  --- 伸缩性 （scalability）很差 因为下游的多个 Consumer 都 要“抢”这个共享消息队列的消息。
                                    2.发布 / 订阅模型倒是允 许消息被多个 Consumer 消费，但它的问题也是伸缩性不 高，因为每个订阅者都必须要订阅主题的所有分区。这种全 量订阅的方式既不灵活(下面的组本质其实了添加了consumer来解决的)，也会影响消息的真实投递效果。

                                    3.组：通过逻辑上组成一个组，底层是多个cosumer来完后一件事情()
                                            1.，假设一个 Consumer Group 订阅了 3 个 主题，分别是 A、B、C，它们的分区数依次是 1、2、3， 那么通常情况下，为该 Group 设置 6 个 Consumer 实例是 比较理想的情形，因为它能最大限度地实现高伸缩性。

                                            如果你有 3 个实例，那么平均下来每个实例大约消费 2 个 分区（6 / 3 = 2）？？？
                                            ===> 不同的consumer能这么平均下来处理别人的信息呢？
                    2.offset
                                1.Consumer Map<TopicPartition, Long>
                                2.zookeeper保存offset
                                    1.减少 了 Kafka Broker 端的状态保存开销。现在比较流行的提法 是将服务器节点做成无状态的，这样可以自由地扩缩容，实 现超强的伸缩性。Kafka 最开始也是基于这样的考虑，才将 Consumer Group 位移保存在独立于 Kafka 集群之外的框 架中。
                                    2. ZooKeeper 这类元 框架其实并不适合进行频繁的写更新
                                    3.位移 保存在 Kafka 内部主题的方法

                                3.位移主题
                                    1.将 Consumer 的位移数据作为一 条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说， __consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息
                                    2.要求这个提交过程 不仅要实现高持久性，还要支持高频的写操作。显然，Kafka 的'       主题设计天然就满足这两个 条件 ' ===> 用自己的设计解决问题 ，因此，使用 Kafka 主题来保存位移这件事情，实际上就是一个水到渠成的想法
                                    3.特点
                                            1.<key,value> 
                                                     key:三元组：<Group ID，主题名，分区号 > 普通的consumer也有groupid
                                                     value: 消息体还保存了位移提交的一些其他元数 据，诸如时间戳和用户自定义的数据等。保存这些元数据是为了帮助 Kafka 执行各种各样 后续的操作，比如删除过期位移消息等。但总体来说，我们还是可以简单地认为消息体就是 保存了位移值。
                                            2.默认创建50个分区   Kafka 日志路径下冒出很多 __consumer_offsets-xxx 这样的目录



                                    4.其他种类
                                            1. 用于保存 Consumer Group 信息的消息。 
                                            2. 用于删除 Group 过期位移甚至是删除 Group 的消息。tombstone 消息，即墓碑消息，也称 delete mark.消息体是 null
                                    5.位移提交方式
                                            1.Consumer 端有个参数叫 enable.auto.commit=true
                                                    问题:
                                                            1.如果没有新消息产生，位移还是会一直写入最后的位置，导致磁盘膨胀
                                            2...false
                                    6.删除主题中消息
                                            1.compaction-整理  只保留该key的最新值即可
                                            2.Kafka 提供了专门的 ‘ 后台线程 ’ 定期地巡检待 Compact 的主题，看看是否存在满足条件的 可删除数据。这个后台线程叫 Log Cleaner。很多实际生产环境中都出现过位移主题无限膨 胀占用过多磁盘空间的问题，如果你的环境中也有这个问题，我建议你去检查一下 Log Cleaner 线程的状态，通常都是这个线程挂掉了导致的。

                                    7.提交下一条消费消息的offset
                                    8.从用户的角度来说位移提交分为自动提交和手动提交；
                                      从 Consumer 端的角度来说，位移提交分为同步提交和异步提交

                                            1.手动提交需要调用cosumer.conmmitSync，事务处理前如果报错，则造成提交失败，消息重复
                                            2.自动提交 如果Consumer 每 5 秒自动提交一次位移(不是每消费一条就提交一次吗？？？)
                                                 3 秒发生了 Rebalance 。则同样会重复消费
                                            3.cosumer.conmmitASync.*****不会重试，因为此时的offset已经不是最新的了****

                                        ===> commitSync 和 commitAsync 组合使用才能到达 理想的效果
                                               1. 我们可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动， Broker 端 GC 等。因为这些问题都是短暂的，自动重试通常都会成功，因此，我们不想 自己重试，而是希望 Kafka Consumer 帮我们做这件事。 
                                               2. 我们不希望程序总处于阻塞状态，影响 TPS
                                            
                                            代码
                                                1.主逻辑中  commitAysnc(); // 使用异步提交规避阻塞 
                                                2.finally中   consumer.commitSync(); // 最后一次提交使用同步阻塞式提交 
                                    9.避免大事务一次提交失败，切割成小事务  --- 每次poll多条
                                            1. if（count % 100 == 0）       //每100条提交一次                             consumer.commitAsync(offsets, null); // 回调处理逻辑是                        count++; 

                                    10.CommitFailedException
                                            1.消息处理的总时间超过预设的 max.poll.interval.ms 参数值
                                                    1.缩短单条消息处理的时间
                                                    2.增加 Consumer 端允许下游系统消费一批消息的最大时长 session.timeout.ms 
                                                    3.减少下游系统一次性消费的消息总数 max.poll.records 
                                                    4.下游系统使用多线程来加速消费
                                                        多个线程间如何处 理位移提交这个问题上，更是极容易出错
                                            2.应用中同时出现了设置相同 group.id 值的消费者组程序和独立消 费者程序，那么当独立消费者程序手动提交位移时，Kafka 就会立即抛出 CommitFailedException 异常







                                    ==>TODO:建立的后台线程、轮询处理 timer类+线程池=定时线程 excutors.scheduled...
                                    ==>TODO:组下的多个consumer和多个多线程处理如何协调.为什么放到临时queue中，是否自动提交？
                                            如何处理异常的？
                                    ==>TODO:offset vs checkpoint

                       Coordinator：Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。
                                       。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送 各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操 作。

                                    1.hash取模定位保存该group-id的分区。比如group-id=test-group,50个分区，则hash(xx)%50
                                    2.找到对应分区的leader对应的broker就是该主题的coordinator


     


                    3.Rebalance 
                                1.Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance。
                                2.触发条件
                                    1.组成员数发生变更。比如有新的 Consumer 实例加入组 或者离开组，抑或是有 Consumer 实例崩溃被“踢 出”组。 
                                    2. 订阅主题数发生变更。Consumer Group 可以使用正则 表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表 明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主 题。在 Consumer Group 的运行过程中，你新创建了一 个满足这样条件的主题，那么该 Group 就会发生 Rebalance。
                                    3. 订阅主题的分区数发生变更。Kafka 当前只能允许增加一 个主题的分区数。当分区数增加时，就会触发订阅该主题 的所有 Group 开启 Rebalance。
                                3.问题所在：
                                    1.Rebalance 过程对 Consumer Group 消费过程有极 大的影响。如果你了解 JVM 的垃圾回收机制，你一定听过 万物静止的收集方式，即著名的 stop the world，简称 STW。在 STW 期间，所有应用线程都会停止工作，表现为 整个应用程序僵在那边一动不动。Rebalance 过程也和这个 类似，在 Rebalance 过程中，所有 Consumer 实例都会停 止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病 的一个方面。影响conusmer tps
                                    2.Rebalance 的设计是所有 Consumer 实例共同 参与，全部重新分配所有分区。其实更高效的做法是尽量减 少分配方案的变动。例如实例 A 之前负责消费分区 1、2、 3，那么 Rebalance 之后，如果可能的话，最好还是让实例 A 继续消费分区 1、2、3，而不是被重新分配其他的分区。 这样的话，实例 A 连接这些分区所在 Broker 的 TCP 连接 就可以继续用，不用重新创建连接其他 Broker 的 Socket 资源。****未考虑局部性原理****做到影响性最小
                                    3.每次执行耗时长

                                4.解决：
                                    1.StickyAssignor，即有粘性 的分区分配策略。所谓的有粘性，是指每次 Rebalance 时，该策略会尽可能地保留之前的 分配方案，尽量实现分区分配的最小变动
                                    2.Consumer 实例会被 Coordinator 错误地认为“已停 止”从而被“踢出”Group。如果是这个原因导致的 Rebalance -- 心跳请求 
                                        1.session.timout.ms 决定了 Consumer 存活性的时间间隔/探测次数/heartbeat.interval.ms心跳请求频率
                                                1.生产环境参数参考
                                                        设置 session.timeout.ms = 6s。
                                                        设置 heartbeat.interval.ms = 2s。
                                                        要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms >= 3 * heartbeat.interval.ms。



                                        2.max.poll.interval.ms 参数。它限定了 Consumer 端应用程序两次 调用 poll 方法的最大时间间隔，Consumer 会主动发起“离开组”的请求
                                                1.业务处理逻辑留下充足的时间。这样，Consumer 就不会因为处理这些 消息的时间太长而引发 Rebalance 了

                                        3.consumer GC参数
                                                1.full GC导致(常见)

                        ==> 要想真正的理解细节，解决问题，就需要源码细节。无论是mysql和还是kafka都是源码层面，比如这里的触发条件，就是代码中调用了reblance方法的ctrl+g查看，然后找对策

                                5.心跳线程
                                        1.当协 调者决定开启新一轮重平衡后，它会将“REBALANCE_IN_PROGRESS”封装进心跳请求 的响应中，发还给消费者实例。

                                6.重平衡流程
                                        1.Broker 端的协调者组件利用State Machine完成状态变化和比如消费者组的 过期位移（Expired Offsets）删除
                                        2.消费者端，重平衡分为两个步骤：分别是加入组和等待领导者消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup 请求和 SyncGroup 请求。
                                        SyncGroup 请求的主要目的，就是让协调者把领导者制定的分配方案下发给各个组内成 员。当所有成员都成功接收到分配方案后，消费者组进入到 Stable 状态，即开始正常的消 费工作。







                    2.
                    3.




6.Kafka【入门】就这一篇！ https://www.wmyskxz.com/2019/07/17/kafka-ru-men-jiu-zhe-yi-pian/ + kafka源码整理以及笔记整理 == 解决方案
                        1.kafka 后台命令登录和topic查看，而不是完全依赖前台  判断是否有消息阻塞
                        2.Kafka运维填坑 ：https://www.jianshu.com/p/d2cbaae38014
                        3.kafka书籍：http://kafkadoc.beanmr.com/020_api/01_api_cn.html#highlevelconsumerapi
                        4.Kafka导致重复消费原因和解决方案 ： https://segmentfault.com/a/1190000023282843
                        5.消息回溯 

0.代码剖析
    1.
    2.


问题:Confluence的演讲，题目是ETL is dead，其中讲到了Kafka在流处理平台的来龙去脉


使用 - 运维
            0../kafka-log-dirs.sh --help 直接运行脚本加 --help参数查看具体使用情况
               脚本参数中各种参数的灵活使用：压缩算法、延时时间等 是消息批次（RecordBatch）或消息集合 （MessageSet）的元数据信息
               、CRC 校验值

              如何从shell调用java代码：RESULT=$($JAVA_HOME/bin/java -Xmx1524m -cp $CLASSPATH $JAVA_FILE $PARAM_1 $PARAM_2)
              https://blog.csdn.net/qq_36289377/article/details/79203540


              bootstrap.servers只是用于客户端启动的时候有一个可以热启动的一个连接者，一旦启动完毕客户端就应该可以得知当前集群的所有节点的信息，日后集群扩展的时候客户端也能够自动实时的得到新节点的信息，即使bootstrap.servers里面的挂掉了也应该是能正常运行的，除非节点挂掉后客户端也重启了。  vs  zookeeper 相当于一个存储元数据的服务器



            1.计算给定主题特定分区当前的早位移 和新位移 ,加起来就是整个topic未消费总数
                     bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port 


            1. bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  
                partitions 和 replication factor 分别设置了主题的分区 数以及每个分区下的副本数
                使用bootstrap-server参数代替zookeeper 1.安全验证  2.标准交互
            2. bin/kafka-topics.sh --bootstrap-server broker_host:port --list
            3.bin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic <topic_name>

                问题：如何找到当前kafka对应的bootstrap-server呢？
            4. bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic <topic_name> --p
            5. kafka-reassign-partitions 脚本，帮助我们增加主题的副本数。
            6. 修改主题限速
                先设置 Broker 端参数 leader.replication.throttled.rate 和 follower.replication.throttled.rate
                bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replic
            7. 主题分区迁移
            8.删除主题
                 bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic <topic_name>
            9.消费者组提交的位移数据
                bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offs
            10.读取该主题消息，查看消费者组的状态信息
                bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offs

            11.动态配置
                    1.场景
                            动态调整 Broker 端各种线程池大小，实时应对突发流量。
                            动态调整 Broker 端连接信息或安全配置信息。
                            动态更新 SSL Keystore 有效期。
                            动态调整 Broker 端 Compact 操作性能。
                            实时变更 JMX 指标收集器 (JMX Metrics Reporter)。
                    2.原理
                            1.Kafka 将动态 Broker 参数保存在 ZooKeeper   在zookeeper上get /config/brokers/1查看1的配置
                            2.per-broker 参数 > cluster-wide 参数 > static 参数 > Kafka 默认值。

                    3.操作 bin/kafka-configs.sh ...  删除动态参数要指定 delete-config

                    4.1.log.retention.ms。
                      2.num.io.threads 和 num.network.threads。
                      3.与 SSL 相关的参数。
                      4.num.replica.fetchers
            12.回溯 -  重置位移 
                    0.像 RabbitMQ 或 ActiveMQ 这样的传统消息中间件，它们处理和响应消息的方式是破坏性 的（destructive），即一旦消息被成功处理，就会被从 Broker 上删除。反观 Kafka，由于它是基于日志结构（log-based）的消息引擎，消费者在消费消息时，仅是从磁盘文件上读取数据而已，是只读的操作，因此消费者不会删除消息数据。同时，由于位移数据是由消费者控制的，因此它能够很容易地修改位移的值，实现重复消费历史数据 的功能。

                    1.位移维度 5
                      时间维度 2
                      共7种维度介绍
                    2.两种方式调整
                      通过消费者 API 来实现。 seek
                      通过 kafka-consumer-groups 命令行脚本来实现。 -- 对应参数
            13.常用脚本
                    《31常见工具骄脚本汇总》
            14.kafkaadmin  === 相对于上面所说的脚本查看（跳过权限验证）
                    1. 主题管理：包括主题的创建、删除和查询。 
                    2. 权限管理：包括具体权限的配置与删除。 
                    3. 配置参数管理：包括 Kafka 各种资源的参数设置、详情查询。所谓的 Kafka 资源，主 要有 Broker、主题、用户、Client-id 等。 
                    4. 副本日志管理：包括副本底层日志路径的变更和详情查询。 
                    5. 分区管理：即创建额外的主题分区。 
                    6. 消息删除：即删除指定位移之前的分区消息。 
                    7. Delegation Token 管理：包括 Delegation Token 的创建、更新、过期和详情查询。 
                    8. 消费者组管理：包括消费者组的查询、位移查询和删除。 
                    9. Preferred 领导者选举：推选指定主题分区的 Preferred Broker 为领导者。
            15. 跨集群备份解决方案MirrorMaker
            16.kafka监控
                    1.我的主 机有 4 个 CPU 核，总 CPU 使用率是 102.3，那么，平均每个 CPU 的使用率大致是 25%。
                    2.监控
                            1.broker
                            2.jvm
                            3.集群
                                    1. 查看 Broker 进程是否启动，端口是否建立 而不是单看容器
                                    2. 查看 Broker 端关键日志
                                    3.查看 Broker 端关键线程的运行状态
                                            1.Log Compaction 线程，这类线程是以 kafka-log-cleaner-thread 开头
                                            2.副本拉取消息的线程，通常以 ReplicaFetcherThread 开头
                                    4.查看 Broker 端的关键 JMX 指标。
                                        BytesIn/BytesOut：即 Broker 端每秒入站和出站字节数。你要确保这组值不要接近你的 网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。
                                        NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你 应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁 忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减 负。
                                        RequestHandlerAvgIdlePercent：即 I/O 线程池线程平均的空闲比例。同样地，如果 该值长期小于 30%，你需要调整 I/O 线程池的数量，或者减少 Broker 端的负载。
                                        UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有 的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区 有可能会出现数据丢失。因此，这是一个非常重要的 JMX 指标。
                                        其实，Broker 端还有很多很多 JMX 指标，除了上面这些重要指标，你还可以根据自己业 务的需要，去官网查看其他 JMX 指标，把它们集成进你的监控框架。
                                        5. 监控 Kafka 客户端。
                                        客户端程序的性能同样需要我们密切关注。不管是生产者还是消费者，我们首先要关心的是 客户端所在的机器与 Kafka Broker 机器之间的网络往返时延（Round-Trip Time， RTT）。通俗点说，就是你要在客户端机器上 ping 一下 Broker 主机 IP，看看 RTT 是多 少。
                                        我曾经服务过一个客户，他的 Kafka 生产者 TPS 特别低。我登到机器上一看，发现 RTT 是 1 秒。在这种情况下，无论你怎么调优 Kafka 参数，效果都不会太明显，降低网络时延反 而是最直接有效的办法。
                                        除了 RTT，客户端程序也有非常关键的线程需要你时刻关注。对于生产者而言，有一个以 kafka-producer-network-thread 开头的线程是你要实时监控的。它是负责实际消息发送 的线程。一旦它挂掉了，Producer 将无法正常工作，但你的 Producer 进程不会自动挂 掉，因此你有可能感知不到。对于消费者而言，心跳线程事关 Rebalance，也是必须要监 控的一个线程。它的名字以 kafka-coordinator-heartbeat-thread 开头。
                                        除此之外，客户端有一些很重要的 JMX 指标，可以实时告诉你它们的运行情况。
                                        从 Producer 角度，你需要关注的 JMX 指标是 request-latency，即消息生产请求的延 时。这个 JMX 最直接地表征了 Producer 程序的 TPS；而从 Consumer 角度来说， records-lag 和 records-lead 是两个重要的 JMX 指标。我们在专栏第 22 讲解释过这两个
                                        ISRShrink/ISRExpand：即 ISR 收缩和扩容的频次指标。如果你的环境中出现 ISR 中副 本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出 ISR 的 原因，并采取适当的措施。
                                        ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下， Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。 如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查 看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障， Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作 的。
                                    5. 监控 Kafka 客户端
                                        1.网络往返时延
                                        2.kafka-coordinator-heartbeat-thread 开头
                kafka监控框架
                        1.bin/kafka-run-class.sh kafka.tools.JmxTool
                        2.kafka manager
                        3.Burrow
                        4.JMXTrans + InfluxDB + Grafana

            17.kakfa调优
                        1.应用程序  
                                1.不要频繁地创建 Producer 和 Consumer 对象实例
                                2.用完关闭  如 Socket 连接、ByteBuffer 缓冲 区等。不及时关闭的话，势必造成资源泄露。
                                3.合理利用多线程来改善性能。
                        2.框架层
                                1.尽力保持客户端版本和 Broker 端版本一致。不一致Kafka 丧失很多性能收益，比如 Zero Copy
                        3.jvm层
                                1.将 你的 JVM 堆大小设置成 6～8GB。关注 Full GC 之后堆上存活对象的总大 小，然后把堆大小设置为该值的 1.5～2 倍。如果你发现 Full GC 没有被执行过，手动运行 jmap -histo:live < pid > 就能人为触发 Full GC

                                2.GC 收集器的选择  G1 收集器，避免Full GC 是单线程运行
                                  。如果你的 Kafka 环境中经 常出现 Full GC，你可以配置 JVM 参数 -XX:+PrintAdaptiveSizePolicy，来探查一下到底 是谁导致的 Full GC。
                                3.大对象   Large Object
                                    除了增加堆大小之外，你还可以适当地增加
                                    区域大小，设置方法是增加 JVM 启动参数 -XX:+G1HeapRegionSize=N。默认情况下， 如果一个对象超过了 N/2，就会被视为大对象，从而直接被分配在大对象区。如果你的 Kafka 环境中的消息体都特别大，就很容易出现这种大对象分配的问题。



                        4.操作系统层
                                1.挂载（Mount）文件系统时禁 掉 atime 更新。mount -o noatime 命令。减少文件系统的写操作数
                                2.选择 ext4 或 XFS文件系统，高效io
                                3.将 swappiness 设置成一个很小的值，比如 1～ 10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程sudo sysctl vm.swappiness=N 来临时设置该值，如果要永久生效，可以修改 /etc/sysctl.conf 文件， 增加 vm.swappiness=N，然后重启机器即可。
                                4.ulimit -n 和 vm.max_map_count
                                        1. /etc/sysctl.conf 文件，增加 vm.max_map_count=655360  sysctl -p
                                        2.vm.max_map_count如果太小， 在一个主题数超多的 Broker 机器上，你会碰到OutOfMemoryError
                                5.页缓存大小   log.segment.bytes 默认值是 1GB
                                        预留出 一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页
                                                缓存，这样，消费者程 序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I/O 操作。



                        性能指标   
                                1.吞吐量和延时
                                        1.批次和微批
                                             Producer 不是每次发送一条消息，而是在 发送前等待一段时间，然后统一发送一批消息，比如 Producer 每次发送前先等待 8ms， 8ms 之后，Producer 共缓存了 1000 条消息，此时总延时就累加到 10ms（即 2ms + 8ms）了，而 TPS 等于 1000 / 0.01 = 100,000 条 / 秒。由此可见，虽然延时增加了 4 倍，但 TPS 却增加了将近 200 倍。这其实也是批次化（batching）或微批次化（microbatching）目前会很流行的原因。

                                            用较小的延时增加的代价，去换取 TPS 的显著提升。复用了io和网络。在内存buffer

                                        2.tps调优.png







开发任何一款分布式系统都要面临和解决的问 题，比如我们耳熟能详的一致性问题、领导者选举问题、分区备份问题等。这些问题在 Kafka 中都有体现，我们在专栏里面也有所涉及。因此，分布式系统的诸多基础性概念，是 帮助你日后深入掌握大数据分布式框架的重要因素。


============kafka脚本使用及整体梳理夯实形成体系 + kafka架构 connector/core... + 面试题=========


==============zookeeper如何做到协调的。解决什么问题，遇到什么问题==========
    1.它通过将认证用户信息保存在 ZooKeeper 的方式，避免了动态修改需要重启 Broker 的弊端

======================kafka与流处理============
流处理是什么，和普通编程区别是什么？
与mapreduce 、flink对比。如何借鉴思想。。
java8 stream使用场景

============================
问题定位和jvm
    掌握 JVM 调优和 GC。我推荐你去读一读“Java Performance”这本书。虽然目前 GC 收集器大部分演进到了 G1 时代，但书中大部分的调优内容依然是适用的。调优
    Kafka 的 JVM，也要依赖这部分知识给予我们指导。

=================
多线程 并发 
 提升自己的 Java 多线程开发以及 I/O 开发能力。很多大数据框架底层都大量使用 Java 多线程能力以及 NIO 帮助实现自身功能。就拿 Kafka 来说，多线程自不必说， Kafka 可是大量使用 NIO 实现网络通信的。所以，这部分的知识是你必须要熟练掌握 的。 

==============

总体调优


===== 以梦为马，莫负韶华！   真正的实践一定要包含你自己的思考和验证，而且要与真实业 务相绑定。


问题及解决：
        0.分布式技术
              1.cap/base理论及分布式解决方案  ******* https://www.cnblogs.com/duanxz/p/5229352.html
              	p:分区容忍度即扩展性
	              CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。
	              CP without A：如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。
	              AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。

              但如果以算法划分，到能分出几类：
                  1.以Leader选举为主的一类算法，比如paxos、viewstamp，就是现在zookeeper、Chuby等工具的主体
                  2.以分布式事务为主的一类主要是二段提交，这些分布式数据库管理器及数据库都支持
                  3.以若一致性为主的，主要代表是Cassandra的W、R、N可调节的一致性
                  4.以租赁机制为主的，主要是一些分布式锁的概念，目前还没有看到纯粹“分布式”锁的实现
                  5.以失败探测为主的，主要是Gossip和phi失败探测算法，当然也包括简单的心跳
                  6.以弱一致性、因果一致性、顺序一致性为主的，开源尚不多，但大都应用在Linkedin、Twitter、Facebook等公司内部
                  7当然以异步解耦为主的，还有各类Queue
            
          ===> 其实源码查看就是查看解决方案  在cap基础上 + 性能       
            
        1：主题删除失败。
            当运行完上面的删除命令后，很多人发现已删除主题的分区数据依然“躺在”硬盘上，没有 被清除。这时该怎么办呢？
            实际上，造成主题删除失败的原因有很多，最常见的原因有两个：副本所在的 Broker 宕机 了；待删除主题的部分分区依然在执行迁移过程。
            如果是因为前者，通常你重启对应的 Broker 之后，删除操作就能自动恢复；如果是因为后 者，那就麻烦了，很可能两个操作会相互干扰。
            不管什么原因，一旦你碰到主题无法删除的问题，可以采用这样的方法：
                    第 1 步，手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。
                    1 bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offs
                    1 bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offs
                    第 2 步，手动删除该主题在磁盘上的分区目录。
                    第 3 步，在 ZooKeeper 中执行 rmr /controller，触发 Controller 重选举，刷新 Controller 缓存。
                    在执行后一步时，你一定要谨慎，因为它可能造成大面积的分区 Leader 重选举。事实 上，仅仅执行前两步也是可以的，只是 Controller 缓存中没有清空待删除主题罢了，也不 影响使用。


     2：__consumer_offsets 占用太多的磁盘。
            一旦你发现这个主题消耗了过多的磁盘空间，那么，你一定要显式地用jstack 命令查看一 下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了， 无法及时清理此内部主题。倘若真是这个原因导致的，那我们就只能重启相应的 Broker 了。另外，请你注意保留出错日志，因为这通常都是 Bug 导致的，好提交到社区看一 下。

     3.如何选择传统的mq和kafka


     4.如何对比传统的mq分布式事务和kafka事务

     5.kafka中的checkpoint和db中的区别对比



