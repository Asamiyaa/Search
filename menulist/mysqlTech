DB技术本质：在一致性的基础上(事务、断电、并发、因为缓存造成的不一致),通过算法(大数据量写入、搜索)、内存、硬件(顺序独写)加速。充分利用硬件的能力

问题：矛盾点：
				1.可重复读隔离级别，事务 T 启 动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数 据，事务 T 看到的仍然跟在启动时看到的一样
				2.一个事务要更新一行，如果刚好有 另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。
				
				begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start	transaction with consistent snapshot 这个命令。

				是默认 autocommit=1。


			  读锁？写锁？两个update事务时等待，一个读一个写则遵循1

		事务和锁关系：
				1.两个视图
					1.它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结 果。创建视图的语法是 create view … ，而它的查询方法与表一样。
					2.InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用 于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离 级别的实现
						
						1.基于整库---InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒 级创建快照”的能力。
									1.每个事务有一个唯一transaction id,递增申请。和每行变化的事务id进行比对，判断是否要找‘上一个’版本
									2.每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本， 并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。 。。excel:行+列(rowid)
									3.同时，旧的数据 版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。只记录update的版本和undolog而不是所有的事务操作都记录
										单向链表定位 <--- undoLog实现 V1、V2、V3 并不是物理上真实存 在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。
						2.如何定义快照
									1.一个事务启动的时候，能够看到所有已经提交的事务结果。但是之 后，这个事务执行期间，其他事务的更新对它不可见 。 如果“上一个版本”也不可见，那就得继续往前找。 
									2.如果是这个事务自己更新 的数据，它自己还是要认的。
									3. InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正 在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。
										a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
									    b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 ？？？ 

						3.读写关系
									1.读默认不加锁  所以当前镜像  如果加了了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。
 lock in share mode  / for update  则会读取最新事务提交的数据

 									2.对于update默认先读后写，读：当前读，读最新数据			<-- 类似 读提交
 									3.如果update操作时，有其他事务未提交改行锁，造成锁等待


 						4.对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
						  对于读提交，查询只承认在语句启动前就已经提交完成的数据；
						  对于当前读，查询该行数据最新版本数据；

		普通索引 vs 唯一索引

				1.id_card是否做主键
					1.不建议，因为id_card较长，主键作为其他索引的引用，消耗太大了
					2.解决方案：倒排id_card  reverse(id_card)并使用前缀   ， 注意索引不是一定能唯一定位到一行(唯一索引)，对于普通索引只能定位范围，在轮询查找对比判断

				2.普通索引 vs 唯一索引 性能对比
						1.查询
								1.对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直 到碰到第一个不满足 k=5 条件的记录。
								2.对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止 继续检索。
								==> 差距不大
								虽然存在db读取页的形式，多一次查询可能正好跨页导致加载，但每页近千个key,所以出现这种概率低
						2.更新	
								1.如果数据在内存中，则直接更新
								2.这个数据页还没有在内 存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了
								3.定期 merge。在数据库正常关闭 （shutdown）的过程中，也会执行 merge 操作 <-- hook


								唯一索引：判断是否违反唯一性约束，所以使用了内存，不使用change buffer 
								普通索引：change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大 小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的 时候，表示 	change buffer 的大小最多只能占用 buffer pool 的 50%。

				3.是否所有的普通索引都走change buffer呢？ -- 适用场景
							no 
								1.对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
								2.一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新 先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。 这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代

				4.索引选择和实践
						1.在不使用db唯一约束情况下，优先使用普通索引，更好的update性能
						2.普通索引和 change buffer 的配合使用，对于数据量大的表的 更新优化还是很明显的。
						3.在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。
						4.“历史数据”的库，
						5.归档数据已经是确保没有唯一键冲突 了

				5.change buffer 和 redo log
						1. Page 1 在内存中，直接更新内存； 
						2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入 一行”这个信息 
						3. 将上述两个动作记入 redo log 中（图中 3 和 4）。

					二者不同：二者维度不同，redolog是为了记录所有操作过程，不管是否读取磁盘。
							 change buffer
							 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是 写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写 的。

				6.有了change buffer如何保证一致性呢？
						1. 读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后 如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以 返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但 是这里直接从内存返回结果，结果是正确的。
						
						2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里 面的操作日志，生成一个正确的版本并返回结果。可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。
						
		所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的 是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘 的 IO 消耗。


				问题：如果断电丢失change buffer ,如何保证一致性？
						会导致change buffer丢失，会导致本次未完成的操作数据丢失，但不会导致已完成操作的 数据丢失。 1.change buffer中分两部分，一部分是本次写入未写完的，一部分是已经写入完成的。 2.针对未写完的，此部分操作，还未写入redo log，因此事务还未提交，所以没影响。 2.针对，已经写完成的，可以通过redo log来进行恢复。 … 

						1、changebuffer跟普通数据页一样也是存在磁盘里，区别在于changebuffer是在共享表 空间ibdata1里 2、redolog有两种，一种记录普通数据页的改动，一种记录changebuffer的改动 
						3、只要内存里脏页（innodb buffer pool）里的数据发生了变化，就一定会记录2中前

				问题：有点疑惑: 主键id也是唯一索引吧? 那我们的新增操作如何利用 change buffer呢?
							作者回复: 所以主键索引用不上，都是对于那些二级索引的才有效。  
	 
							一个insert语句要操作所有索引的嘛，收益在二级索引

							insert的时候，写主键是肯定不能用change buffer了，但是同时也会要写其它索引，而其它索引 中的“非唯一索引”是可以用的这个机制的； 

	优化器导致索引失效
			1. 现场准备：批量插入 - 执行计划 -查看扫描行数 - 执行时间 - 设置慢查询set long_query_time=0 - 打印执行信息
			2. MySQL 选错索引依据：扫描的行数越少,是否使用临时表、是否排序等
					select * from t  where a between 10000 and 20000; 使用索引  -- 扫描:10001
					开启事务A ; 事务B :delete table ; 重新插入(由于事务A导致其实没有真正删除，每行有两个版本)
					select * from t  where a between 10000 and 20000; 没有使用索引		-- 扫描:全量
					select * from t force index(a) where a between 10000 and 20000; 强制使用索引 		-- 扫描:3w多
		问题：上面的查询语句中，mysql优化器如何判断错了行数?
				1.索引的“区分度 : 一个索引上不同的值越多，这个索引的区分度 就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说， 这个基数越大，索引的区分度越好。
				2.到精确的结果，但是代 价太高了，所以只能选择“采样统计”。
				3.InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个 平均值，然后乘以这个索引的页面数，就得到了这个索引的基
				4.当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。
				5.错误一：它认为使用索引 b 可以避免排序（b 本身是索引，已 经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行 数多，也判定为代价更小。
				  错误二：总体上因为综合了多个指标，所以导致最终没有走向我们期望的索引  <-== MySQL 优化器 bug
				  错误三：为什么删除索引数据快，建立却慢？
				  		删除的时候是标记删除，所以很快。 建索引是要扫描数据和真正生成索引树，是会慢些。
				  		所以2中的例子可能由于真正的索引并没有删除，不是真实态导致选择索引有误

				6.解决
				1.analyze table t 修正表  <== 发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采 用这个方法来处理。
				2. select * from t force index(a) where a between 10000 and 20000 == 不推荐
				3. 引导选择：“order by b,a limit 1 解决错误一让mysql认为b,a都要排序，所以行数就作为重要依据。不具有通用性
				4.以新建一个更合适的索引，来提供给优化器做选择
				5.删掉误用的索引。

	如何给字符串加索引
				1.前缀索引，减少占用 。  alter table SUser add index index2(email(6)); 邮箱都是xxxxqq.com
				2.效果 -- 索引区分度评估 -- 评估占用和扫描(因为普通前缀索引会造成想相同索引对应不同数据，需要找到索引后
				    到主键到数据进行遍历判断) -- 只有唯一索引才会找到直接拿出，而不用遍历

				 		1.select count(distinct email) as L from SUser;
				 		2.select   count(distinct left(email,4)）as L4,     <=== 函数的使用
				 				   count(distinct left(email,5)）as L5,  
				 				   count(distinct left(email,6)）as L6,  
				 				   count(distinct left(email,7)）as L7,
				 			 from SUser;
				 		3.Ln / L >= 0.95
				 3.前缀索引会因为前缀影响到覆盖索引，如果
				 select id,email from SUser where email='zhangssxyz@xxx.com'  <---- 不使用前缀。可以不回表
				 select id,name,email from SUser where email='zhangssxyz@xxx.com' <---- 使用，因为都要回表 

				 4.为了增加区分度又减少占用
				 		1.倒序存储(身份证)  select field_list from t where id_card = reverse('input_id_card_string')
				 		2.使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验 码，同时在这个字段上创建索引
				 				 alter table t add id_card_crc int unsigned, add index(id_card_crc);
				 				 由于 校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相 同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。

				 	==> 对比：
				 		1.都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符 串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。
				 		同样地，hash 字段的方式也只能支持等值查询。
				 				1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是 不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。 
				 				2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来 看的话，reverse 函数额外消耗的 CPU 资源会更小些。 
				 				3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来 的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。 而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

	mysql抖动
					1.当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写 入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。，都在内存

					2.引发数据库的 flush 场景
							1.粉板满了，记不下了；危险 ，因为此时不能执行update.，这时候更新数会跌为 0
							2(通常).系统内存不足 新的内存页，而内存不够用的时候，就要淘   汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到 磁盘。 
									1. innodb_io_capacity = 磁盘的 IOPS；充分利用磁盘
									2. 不能全力刷脏页，因为还要处理用户请求 -- 控制策略
											1.一个是脏页比例，参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75
											2.一个是 redo log 写 盘速度。  SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。避免连坐刷周边脏页。机械盘的话可以考虑
											MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 


							3.生意不忙的时候，或者打烊之后
							4.是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度 会很快。





