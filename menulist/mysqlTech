DB技术本质：在一致性的基础上(事务、断电、并发、因为缓存造成的不一致),通过算法(大数据量写入、搜索)、内存、硬件(顺序独写)加速。充分利用硬件的能力


mysql
			1.一条sql的执行：
				SQL语句执行深入讲解（MySQL架构总览->查询执行流程->SQL解析顺序）																https://www.jb51.net/article/155350.htm\
					1.执行器：操作引擎，返回结果
					2.存储引擎：存储数据，提供读写接口

			2.长连接 vs 短连接
					数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。
					短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。
					建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。
				   但如果一直倡长连接可能导致oom,so :
				   			1.定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
				   			2.如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。


			3.关闭db默认缓存 -- 8.0之后已删除
					1.查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。导致命中率低。
					  除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。


			====> 从连接建立 - 权限校验 - 查询缓存命中 - 分析器 - 优化器 - 执行器      其实这些思考下来就是自己写代码的时候的  校验-缓存-执行 .存储引擎就是封装了io流读写+自己各个引擎特性

			4.更新操作涉及redoLog(重做)/binlog(归档)
					0.只有更新操作才会记录两日志
					1.为什么两个日志对比
							1.性能看，redolog：MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。(酒馆赊账) == 顺序写、组提交.优化
							2.如果未等打烊，粉版写满了(InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写)
							  write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
							====> 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe
							3.binlog: Server 层，它主要做的是MySQL 功能层面的事情； Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。
							4.两个日志的对比
								1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
								2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
								3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

							5.事务id对应二者


			5.两阶段提交 - 让数据恢复到半月内任意秒  === 事务概念
					1.checkpoint ： redoLog中的位置(要清理缓存的)。 write pos就是写入db的位置

					update流程：
								1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
								2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
								3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
								4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
								5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。更改最终状态 。
					db恢复流程： --- 必须现有redo后有binlog ; 恢复库其实根本在binlog记录了操作过程
								1. 找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
								2. 从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

								1.备份机制取决于业务重要性和存储资源权衡，考虑最短恢复，肯定是越短越好

							====> 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
					保证主从一致：常见的做法也是用全量备份加上应用binlog 来实现的
					redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致

			6.两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。

			7.隔离级别 -  创建对应视图
					1. ACID: 原子性、一致性、隔离性、持久性
					2. 你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：
							读未提交是指，	一个事务还没提交时，它做的变更就能被别的事务看到。
							读提交是指，		一个事务提交之后，它做的变更才会被其他事务看到。		oracle 默认
							可重复读是指，	一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。  mysql 默认
							串行化			顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行



			8.长事务 - 尽量不要使用  ==
					1.事务可能访问任意一段数据，而数据库保留对应的回滚记录，占用空间 - checkpoint回滚点
					2.占用锁资源


							导读：MySQL运维中长事务和锁等待排查  ： https://dbalife.info/2018/06/28/MySQL%E8%BF%90%E7%BB%B4%E4%B8%AD%E9%95%BF%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81%E7%AD%89%E5%BE%85%E6%8E%92%E6%9F%A5/	
							查询长事务：查看长事务  ： select t.*,to_seconds(now())-to_seconds(t.trx_started) idle_time from INFORMATION_SCHEMA.INNODB_TRX t;
									   获得长事务id   :  select t.*,to_seconds(now())-to_seconds(t.trx_started) idle_time ,concat('kill ',trx_mysql_thread_id,';') kill_sql from INFORMATION_SCHEMA.INNODB_TRX t ； 
									   获取长事务用户  :  select * from information_schema.INNODB_TRX i, information_schema.processlist p where i.trx_mysql_thread_id=p.id and p.time > 60;
									   查看长事务对应sql : SELECT ps.id 'PROCESS ID',ps.user,ps.host, esh.EVENT_ID, trx.trx_started,esh.event_name 'EVENT NAME',esh.sql_text 'SQL' ,ps.time from performance_schema.events_statements_history esh   join performance_schema.threads th on esh.thread_id = th.thread_id       join information_schema.processlist ps on ps.id = th.processlist_id left join information_schema.innodb_trx trx on trx.trx_mysql_thread_id = ps.id      where ps.time > 60 AND trx.trx_id is not null and ps.USER != 'SYSTEM_USER'  order by   esh.EVENT_ID;
					分类：
						 读长事务
								比如研发同事连接查询机（从库）查询，没有启用autocommit, 执行了一个查询SQL，没有commit(一般执行查询都不会再执行commit)，连接就这样长时间挂起。这就造成了一个读长事务。这个事务持有一个share_read DML锁，它会影响对该表的DDL操作。如果这时DBA在主库对这个表执行了DDL操作，这个DDL操作复制到从库的时候，会因等待MDL锁而无法执行。这会造成从库复制大量延迟！

								还有一种读长事务的情况就是研发人员执行了一个复杂的统计类SQL，这个SQL执行完本身就耗时很长，这也会造成长时间占用DML锁，即使启用了autocommit也没用。而且还有可能大量数据文件排序造成磁盘空间耗尽。

								更有甚者，程序的连接执行了查询，没有commit,而程序用的是连接池，连接又不关闭。这个问题就很严重了。

						 写长事务
								写长事务比较好理解，就是批量更新、插入，造成事务长时间执行。还有就是事务本身逻辑比较复杂，存在锁竞争、锁等待。锁等待都会有超时，超时后应用端应该回滚或者重试。

								面对复杂的应用场景，DBA要以不变应万变，这个法宝就是监控。监控的目的是即时发现，发现了就能即时处理。对于读长事务，一旦超过一定阈值（比如10m）可立马kill,对于写操作则不能这么任性，需要结合业务来分析。

								INFORMATION_SCHEMA.INNODB_TRX表中包含了当前innodb内部正在运行的事务信息，包括只读事务。这个表中给出了事务的开始时间，我们可以稍加运算即可得到事务的运行时间。



				查询锁等待：锁等待与长事务由密切关系，不管哪种长事务都会造成MDL锁等待。 
							5.6之前：SELECT r.trx_state wating_trx_state, r.trx_id waiting_trx_id, r.trx_mysql_thread_Id waiting_thread,r.trx_query waiting_query,b.trx_state blocking_trx_state,b.trx_id blocking_trx_id,b.trx_mysql_thread_id blocking_thread,b.trx_query blocking_query FROM information_schema.innodb_lock_waits w INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id

							5.6之后： SELECT waiting_trx_id, waiting_pid, waiting_query, blocking_trx_id,blocking_pid,blocking_query FROM sys.innodb_lock_waits;


				如何避免长事务：

						首先，从应用开发端来看：
								1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
								2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
								3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
						其次，从数据库端来看：
								1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
								2. Percona 的 pt-kill 这个工具不错，推荐使用；
								3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
								4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。




			9.索引：
					0.每一张表其实就是多个个B+树，树结点的key值就是某一行的主键，value是该行的其他数据。新建索引就是新增一个B+树，查询不走索引就是遍历主B+树。非主键索引关联主键索引，主键索引的值就是整行数据值

					1.实现方式
							1.hash表  
									优点：增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。
									缺点：如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。
									哈希表这种结构适用于只有等值查询的场景 
							2.有序数组
									优点：仅仅看查询效率，有序数组就是最好的数据结构。 更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
									缺点：更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
									有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。
							3.树
									优点：查询更新都是O(log(n))
									缺点：

								分类:
									二叉树
									多叉树：= B+树  为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。
											以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了

										问题：N叉树的N由什么决定？
											1.5.6以后可以通过page大小来间接控制
											2.计算方法、前缀索引

									红黑树
									LSM树

					2.主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
					  非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。
					  没有主键的表，innodb默认rowId主键


					3.索引维护
							1.旋转
							2.追加 - 如果中间值则需要挪动后面数据 - 如果改页满了则页分裂(性能和利用率降低)(页合并)

							手动创建、删除顺序：
								1.
								2.

					4.从索引维护角度分析为什么使用自增主键  === 每个非主键索引的叶子节点上都是主键的值
							1.递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
							2.由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。
							从性能和存储空间方面考量，自增主键往往是更合理的选择

							适合业务主键：
								1. 只有一个索引；2. 该索引必须是唯一索引。你一定看出来了，这就是典型的 KV    ===>为什么用树的思维去考虑呢？KV不一般都是hash散列吗？

								由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。
								这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。
					5.覆盖索引
							1. select ID from T where k between 3 and 5，查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。无需回表

					6.复合(联合索引)索引 来满足覆盖索引
							1.有一个 ‘ 高频请求 ’，要根据市民的身份证号查询他的姓名，这个身份证号和姓名联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。

							====>  当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。

							2.最左前缀原则
								0.不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。意思是：查询不必须全部使用name/age两个条件，对于符合索引之只要按照name进行条件查询就可以匹配到最左前缀。使用索引
								  这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。
								1.索引项是按照索引定义里面出现的字段顺序排序的。比如(name,age) 则对应索引就是（zhangsan,23）...
								2.由索引组织的数据是 ‘ 有序 ’的。 比如 先按name排，再按age排，所以就是zhang后面都是zhang开头....匹配后，往后遍历直到不满足 。 
								3.为了最左前缀，在建立联合索引的时候，如何安排索引内的字段顺序。
							3.索引的复用
								1.高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持 “ 根据身份证号查询地址 ”的需求==最左前缀 + 覆盖索引。
								2.(a,b)符合索引满足条件查询 a ； a+b ;两种 （索引：zhangsan,10 ; zhangsan,20==> 
										那么当我们使用条件where name = 'zhangsan' and age = 10这个时候是完全从左向右匹配的，所以符合索引完全使用了。 
										但当我们使用where name like "zhang%" and age = 10 这个时候由于中断，所以只能匹配到索引的zhang..后面的san,age都没有匹配到。这时age其实就没有使用到联合索引的好处。--索引下推
								） ，单独使用b查询则不能使用联合索引。想要使用则需要再建b索引
								3.所以使用联合索引可以适应更多的场景和复用，减少占用
							 4.索引下推
							 	1.对联合索引中的后半部分没有使用到的，先进行过滤，最后再回表

				10.锁
					1.并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构
					2.全局锁
						1.全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。  
							Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

							VS 用 set global readonly=true 
								一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。
								二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

						2.对于支持事务的引擎， mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的
							MVCC:https://juejin.cn/post/6844903778026536968

					4.表锁
						1.一种是表锁，一种是元数据锁（meta data lock，MDL) mdl是默认添加的每个sql
						2.读锁 - 写锁 -由于读锁未释放，写锁获取阻塞，导致后面的读写都会阻塞。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session 再请求的话，这个库的线程很快就会爆满。

					5.如何给表加字段
						1.首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。
						如果你要做DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDLNOWAIT/WAIT n 这个语法。

						online ddl

					6.行锁
						1.MyISAM 引擎就不支持行锁。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
						2.两阶段锁协议
							在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
						3.死锁
						   解决方案
							1.直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。---- 设置时间长短容易误伤
							2.发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 --- 使用但需要遍历判断所有的依赖是否死锁性能

						   解决方案：
							1.头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。
							
							2.控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前 ‘ 排队 ’ 。这样在 InnoDB 内部就不会有大量的死锁检测工作了。

							3.考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。

							4.批次执行，减少冲突操作 - 通过queue来暂存数据

						4.锁竞争：
							如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到
								1.直接执行 delete from T limit 10000;
								2.在一个连接中循环执行 20 次 delete from T limit 500;
								3.在 20 个连接中同时执行 delete from T limit 500。

								答案：	--- 其它客户端 
								1.事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长。且大事务还会导致主从延迟
								2.串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。
								3.人为自己制造锁竞争，加剧并发量。

					
					11.	事务之间既然是隔离的，事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。
						问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候	？ 锁和事务的关系



问题：矛盾点：
				1.可重复读隔离级别，事务 T 启 动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数 据，事务 T 看到的仍然跟在启动时看到的一样
				2.一个事务要更新一行，如果刚好有 另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。
				
				begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start	transaction with consistent snapshot 这个命令。

				是默认 autocommit=1。


			  读锁？写锁？两个update事务时等待，一个读一个写则遵循1

		事务和锁关系：
				1.两个视图
					1.它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结 果。创建视图的语法是 create view … ，而它的查询方法与表一样。
					2.InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用 于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离 级别的实现
						
						1.基于整库---InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒 级创建快照”的能力。
									1.每个事务有一个唯一transaction id,递增申请。和每行变化的事务id进行比对，判断是否要找‘上一个’版本
									2.每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本， 并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。 。。excel:行+列(rowid)
									3.同时，旧的数据 版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。只记录update的版本和undolog而不是所有的事务操作都记录
										单向链表定位 <--- undoLog实现 V1、V2、V3 并不是物理上真实存 在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。
						2.如何定义快照
									1.一个事务启动的时候，能够看到所有已经提交的事务结果。但是之 后，这个事务执行期间，其他事务的更新对它不可见 。 如果“上一个版本”也不可见，那就得继续往前找。 
									2.如果是这个事务自己更新 的数据，它自己还是要认的。
									3. InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正 在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。
										a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
									    b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 ？？？ 

						3.读写关系
									1.读默认不加锁  所以当前镜像  如果加了了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。
 lock in share mode  / for update  则会读取最新事务提交的数据

 									2.对于update默认先读后写，读：当前读，读最新数据			<-- 类似 读提交
 									3.如果update操作时，有其他事务未提交改行锁，造成锁等待


 						4.对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
						  对于读提交，查询只承认在语句启动前就已经提交完成的数据；
						  对于当前读，查询该行数据最新版本数据；

		普通索引 vs 唯一索引

				1.id_card是否做主键
					1.不建议，因为id_card较长，主键作为其他索引的引用，消耗太大了
					2.解决方案：倒排id_card  reverse(id_card)并使用前缀   ， 注意索引不是一定能唯一定位到一行(唯一索引)，对于普通索引只能定位范围，在轮询查找对比判断

				2.普通索引 vs 唯一索引 性能对比
						1.查询
								1.对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直 到碰到第一个不满足 k=5 条件的记录。
								2.对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止 继续检索。
								==> 差距不大
								虽然存在db读取页的形式，多一次查询可能正好跨页导致加载，但每页近千个key,所以出现这种概率低
						2.更新	
								1.如果数据在内存中，则直接更新
								2.这个数据页还没有在内 存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了
								3.定期 merge。在数据库正常关闭 （shutdown）的过程中，也会执行 merge 操作 <-- hook


								唯一索引：判断是否违反唯一性约束，所以使用了内存，不使用change buffer 
								普通索引：change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大 小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的 时候，表示 	change buffer 的大小最多只能占用 buffer pool 的 50%。

				3.是否所有的普通索引都走change buffer呢？ -- 适用场景
							no 
								1.对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
								2.一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新 先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。 这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代

				4.索引选择和实践
						1.在不使用db唯一约束情况下，优先使用普通索引，更好的update性能
						2.普通索引和 change buffer 的配合使用，对于数据量大的表的 更新优化还是很明显的。
						3.在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。
						4.“历史数据”的库，
						5.归档数据已经是确保没有唯一键冲突 了

				5.change buffer 和 redo log
						1. Page 1 在内存中，直接更新内存； 
						2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入 一行”这个信息 
						3. 将上述两个动作记入 redo log 中（图中 3 和 4）。

					二者不同：二者维度不同，redolog是为了记录所有操作过程，不管是否读取磁盘。
							 change buffer
							 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是 写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写 的。

				6.有了change buffer如何保证一致性呢？
						1. 读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后 如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以 返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但 是这里直接从内存返回结果，结果是正确的。
						
						2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里 面的操作日志，生成一个正确的版本并返回结果。可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。
						
		所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的 是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘 的 IO 消耗。


				问题：如果断电丢失change buffer ,如何保证一致性？
						会导致change buffer丢失，会导致本次未完成的操作数据丢失，但不会导致已完成操作的 数据丢失。 1.change buffer中分两部分，一部分是本次写入未写完的，一部分是已经写入完成的。 2.针对未写完的，此部分操作，还未写入redo log，因此事务还未提交，所以没影响。 2.针对，已经写完成的，可以通过redo log来进行恢复。 … 

						1、changebuffer跟普通数据页一样也是存在磁盘里，区别在于changebuffer是在共享表 空间ibdata1里 2、redolog有两种，一种记录普通数据页的改动，一种记录changebuffer的改动 
						3、只要内存里脏页（innodb buffer pool）里的数据发生了变化，就一定会记录2中前

				问题：有点疑惑: 主键id也是唯一索引吧? 那我们的新增操作如何利用 change buffer呢?
							作者回复: 所以主键索引用不上，都是对于那些二级索引的才有效。  
	 
							一个insert语句要操作所有索引的嘛，收益在二级索引

							insert的时候，写主键是肯定不能用change buffer了，但是同时也会要写其它索引，而其它索引 中的“非唯一索引”是可以用的这个机制的； 

	优化器导致索引失效
			1. 现场准备：批量插入 - 执行计划 -查看扫描行数 - 执行时间 - 设置慢查询set long_query_time=0 - 打印执行信息
			2. MySQL 选错索引依据：扫描的行数越少,是否使用临时表、是否排序等
					select * from t  where a between 10000 and 20000; 使用索引  -- 扫描:10001
					开启事务A ; 事务B :delete table ; 重新插入(由于事务A导致其实没有真正删除，每行有两个版本)
					select * from t  where a between 10000 and 20000; 没有使用索引		-- 扫描:全量
					select * from t force index(a) where a between 10000 and 20000; 强制使用索引 		-- 扫描:3w多
		问题：上面的查询语句中，mysql优化器如何判断错了行数?
				1.索引的“区分度 : 一个索引上不同的值越多，这个索引的区分度 就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说， 这个基数越大，索引的区分度越好。
				2.到精确的结果，但是代 价太高了，所以只能选择“采样统计”。
				3.InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个 平均值，然后乘以这个索引的页面数，就得到了这个索引的基
				4.当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。
				5.错误一：它认为使用索引 b 可以避免排序（b 本身是索引，已 经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行 数多，也判定为代价更小。
				  错误二：总体上因为综合了多个指标，所以导致最终没有走向我们期望的索引  <-== MySQL 优化器 bug
				  错误三：为什么删除索引数据快，建立却慢？
				  		删除的时候是标记删除，所以很快。 建索引是要扫描数据和真正生成索引树，是会慢些。
				  		所以2中的例子可能由于真正的索引并没有删除，不是真实态导致选择索引有误

				6.解决
				1.analyze table t 修正表  <== 发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采 用这个方法来处理。
				2. select * from t force index(a) where a between 10000 and 20000 == 不推荐
				3. 引导选择：“order by b,a limit 1 解决错误一让mysql认为b,a都要排序，所以行数就作为重要依据。不具有通用性
				4.以新建一个更合适的索引，来提供给优化器做选择
				5.删掉误用的索引。

	如何给字符串加索引
				1.前缀索引，减少占用 。  alter table SUser add index index2(email(6)); 邮箱都是xxxxqq.com
				2.效果 -- 索引区分度评估 -- 评估占用和扫描(因为普通前缀索引会造成想相同索引对应不同数据，需要找到索引后
				    到主键到数据进行遍历判断) -- 只有唯一索引才会找到直接拿出，而不用遍历

				 		1.select count(distinct email) as L from SUser;
				 		2.select   count(distinct left(email,4)）as L4,     <=== 函数的使用
				 				   count(distinct left(email,5)）as L5,  
				 				   count(distinct left(email,6)）as L6,  
				 				   count(distinct left(email,7)）as L7,
				 			 from SUser;
				 		3.Ln / L >= 0.95
				 3.前缀索引会因为前缀影响到覆盖索引，如果
				 select id,email from SUser where email='zhangssxyz@xxx.com'  <---- 不使用前缀。可以不回表
				 select id,name,email from SUser where email='zhangssxyz@xxx.com' <---- 使用，因为都要回表 

				 4.为了增加区分度又减少占用
				 		1.倒序存储(身份证)  select field_list from t where id_card = reverse('input_id_card_string')
				 		2.使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验 码，同时在这个字段上创建索引
				 				 alter table t add id_card_crc int unsigned, add index(id_card_crc);
				 				 由于 校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相 同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。

				 	==> 对比：
				 		1.都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符 串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。
				 		同样地，hash 字段的方式也只能支持等值查询。
				 				1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是 不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。 
				 				2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来 看的话，reverse 函数额外消耗的 CPU 资源会更小些。 
				 				3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来 的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。 而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

	mysql抖动
					1.当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写 入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。，都在内存

					2.引发数据库的 flush 场景
							1.粉板满了，记不下了；危险 ，因为此时不能执行update.，这时候更新数会跌为 0
							2(通常).系统内存不足 新的内存页，而内存不够用的时候，就要淘   汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到 磁盘。 
									1. innodb_io_capacity = 磁盘的 IOPS；充分利用磁盘
									2. 不能全力刷脏页，因为还要处理用户请求 -- 控制策略
											1.一个是脏页比例，参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75
											2.一个是 redo log 写 盘速度。  SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。避免连坐刷周边脏页。机械盘的话可以考虑
											MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 


							3.生意不忙的时候，或者打烊之后
							4.是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度 会很快。





				数据库是：数据结构、算法、一致性、性能、取舍多角度的解决方案
				

				问题
							1、什么情况下创建索引才有意义？有哪些限制？比如字段长度
									有这个索引带来的查询收益，大于维护索引的代价，就该建😄对于可能变成大表的表，实际上如果不建索引会导致全表扫描，这个索引就是必须的
							2、如何查看索引占用多少空间？
									可以估算出来的，根据表的行数和索引的定义。
							3、查看索引数的结构，比如多少个层，多少节点？
									跟2一样。 如果要精确的，就要解数据文件，这个工具可以看看https://github.com/jeremycole/innodb_diagrams
							4、如何查看索引的利用率。比如我创建了一个索引，是否可以有记录这个索引被调用了
									performance_schema.table_io_waits_summary_by_index_usage能看到一些信息
							5、“N叉树”的N值在MySQL中是可以被人工调整吗？
									1， 通过改变key值来调整
											N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。我们通过改变Key的大小，就可以改变N的值
									2， 改变页的大小
											页越大，一页存放的索引就越多，N就越大。

										数据页调整后，如果数据页太小层数会太深，数据页太大，加载到内存的时间和单个数据页查询时间会提高，需要达到平衡才行。
							6、一个innoDB引擎的表，数据量非常大，根据二级索引搜索会比主键搜索快，文章阐述的原因是主键索引和数据行在一起，非常大搜索慢，我的疑惑是：通过普通索引找到主键ID后，同样要跑一边主键索引？
									1.覆盖索引。
							7.什么情况下会重建索引
									1.索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。否则就造成了浪费和性能下降


							8、如果你要重建索引 k，你的两个 SQL 语句可以这么写：

									alter table T drop index k;
									alter table T add index(k);
									如果你要重建主键索引，也可以这么写：
									alter table T drop primary key;
									alter table T add primary key(id);

									重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB 

									所以说索引的构建是在主键的基础上加强的


							9、只要用户定义的索引字段中包含了主键中的字段，那么这个字段就不会再被InnoDB自动加到索引中了，如果用户的索引字段中没有完全包含主键字段，InnoDB就会把剩下的主键字段加到索引末尾。
	 

							10、innodb行级锁是通过锁索引记录实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表吗？比如update t set t.name='abc' where t.name='cde'; name字段无索引

										是的。但是你可以再往前考虑一下，如果是 你的update 语句后面加个limit 1, 会怎么锁？
										1.可以自己实践一下,当加上limit1之后 更新语句的执行流程是先去查询再去更新,也就是查询sql为 select * from t where name = "abc" limit 1 for  update,相当于扫描主键索引找到第一个满足name="abc"的条件为止,此时锁的区间为(负无穷,当前行的id],如果在这个id之后的更新和插入时都不会锁住的,在这个id之前的更新和插入会阻塞,之后则不会阻塞 **** 悲观锁 vs 乐观锁  

										2.如果不加limit 1的话,因为此时是整个主键索引全表扫描则整个表锁住了

										3.你说的回表的行锁,比如字段name有普通索引,在更新操作时普通索引会锁住的同时,如果更新操作需要回表的话对应的主键索引也会存在锁(主键索引锁临界锁会退化为行锁),普通索引(间隙锁和行锁)
						
							11.索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。
										rename +新建表

							12.where 过滤条件的顺序会影响sql的执行顺序吗?


表数据删除，表文件大小不变

			1.存放原理
				1.innodb_file_per_table 
					1. OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放
					2. ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件。drop table 命令，系统就会直 接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。
				2.删除只是标记为删除，如果插入对应区间数据则复用；对于页，是不分区间的重新复用


			2.空洞
				1.删除
				2.插入：数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可 能造成索引的数据页分裂。
						300 - 500 - 600 为一页 ； 插入550时，则需要重新申请页，即300-500 / 550-600 数据移动
				3.更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是 会造成空洞的。\

			3.解决
				1.重建表
						1. alter table A engine=InnoDB 命令来重建表。 MySQL 会自动完成转存数据、交换表名、删除旧表的操作
						   按照索引顺序进行重新顺序插入，减少空洞
						2.在整个 DDL 过程中，表 A 中不能有更新。也 就是说，这个 DDL 不是 Online 的。
						   MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化
						3.通过在ddl时，记录row log来完成新的更新记录

						4.几种方式对比
							optimize table、analyze table 和 alter table 这三种方式重建表
							从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就 tmp_file
							analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这 个过程中加了 MDL 读锁；
							optimize table t 等于 recreate+analyze。


				2.在线DDL对锁的使用
						1.alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正 拷贝数据之前就退化成读锁了。
							为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。

						2.那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。

						3.Online DDL 耗时的过程就是拷贝数据到临时表的过程，这个步骤 的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对 业务来说，就可以认为是 Online 的
						
						4.为何不直接就加个MDL读锁 ,这样DDL 也执行不了,应用redo 替换文件后释放读锁即可 。
						 如果有别的线程正在读这个表的数据，得等下。所以存在 降级现象


						4.消耗 IO 和 CPU 资源 ===>  GitHub 开源的 gh-ost
						5.从server层 - innodb引擎层
				
				问题：如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？
						答案是不能。因为，tmp_file 也是要占用临时空间的。

		
		count(*)操作

				1.为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？直接返回呢？
					InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版 本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因 此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能 够用于计算“基于这个查询”的表的总行数。

						优化一：InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节 点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪 个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到小的那棵树来遍 历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之 一。


				2.如果需要实时页面展示数量？ 这种对实时的count(*)性能消耗大
						1.用缓存系统保存计数
								1.内存易丢失  --> redis的保存机制如何处理？
								2.即使 Redis 正常工作，这个计数值还是逻辑上不精确的。计数和插入两个线程

						2.使用一张计数表
								1.解决了已丢失 InnoDB 是支持崩溃恢复不丢数据的
								2.事务解决计数不精确问题
										1.事务A 计数表+1，insert一条数据，事务B查询count,limit 100; 事务A commit;
										2.根据事务，事务B看不到事务A的+1；所以逻辑上就是当前的数量，当前的100；
										  所以说是一致的。
										3.肯定不可能实现完全实时。
					==> 计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因， 是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图

				3.不同count()操作性能对比 count(字段) - 不准确<count(主键 id)<count(1)≈count(*)
						1.innodb引擎返回，在server层进行添加计数

		orderby
				1.流程
						1.sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的 数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不 下，则不得不利用磁盘临时文件辅助排序。
						  查看参数：number_of_tmp_files 

						2.排序的单行长度太大会怎么做？
								1.SET max_length_for_sort_data = 16;
								2.新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。
							    3.拿得到的id回表查询数据

						3.对于1/2 优先使用内存=全字段排序，减少2的磁盘操作
				2.优化：
						1.创建一个 city 和 name 的联合索引 
						alter table t add index city_user(city, name) where条件和order排序字段 。 
						这样的话就有一个聚合索引(city,name)对应具体的主键，所以操作的时候name就本身就是有序的。
						上面排序需要特殊操作是因为取出数据对于name是无序的。所以这样的explain就没有using filesort 

						2.覆盖索引是指，索引上的信息足够满足查询请求，不需要再 回到主键索引上去取数据。
							 alter table t add index city_user_age(city, name, age)
							 explain Using index，表示的就是使用了覆盖索引

				这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合 索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。

		

		基于数据库数据随机显示 == 随机排序
						1.select word from words order by rand() limit 3;
						2.explain:	Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是 需要执行排序操作。
						3.order by rand() 
								1.内存临时表，内存临时表排序的时候,因为不需要读取磁盘直接读取内存所以
						  			无需考虑读取性能影响，直接考虑减少行排序数据为准。 使用了 rowid 排序方法。
						  		2.磁盘临时表	tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M
						  		3.MySQL 5.6 版本引入的一个新的排 序算法。为什么没有使用临时文件的算法，也 就是归并排序算法，而是采用了优先队列排序算法。
						  				1.取前三行作为初始化值(R,rowId) 固定的数组或者堆
						  				2.遍历比较，如果大于则更改覆盖
						  				3.这样话就避免了其他没有用的排序，只需要维护需要返回的几条就可以了

						  	问题：select city,name,age from t where city='杭州' order by name limit 1000  ;
						  	      为什么没有使用上面的优先队列算法？
						  	      (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。

						  	    ===> 从不同维度动态调整算法 <===
						4.随机排序法  rand()计算过程复杂 
								1. 取得这个表的主键 id 的最大值 M 和最小值 N; 
								2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N; 
								3. 取不小于 X 的第一个 ID 的行。

								=====
								mysql> select max(id),min(id) into @M,@N from t ; 
								set @X= floor((@M-@N+1)*rand() + @N); 
								select * from t where id >= @X limit 1;
								=====

								因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。

								这个算法本身并不 严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是 真正的随机。这四行的 id 分别是 1、2、40000、40001 取40000的概率就太大了。就是bug了。

								===优化随机性===
								1. 取得整个表的行数，并记为 C。 
								2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。 
								3. 再用 limit Y,1 取得一行   
								4. 扫描C+Y+1 行，执行代价比随机算法 1 的代价要高。

								===优化取值====
								问题：对于取多个值扫描; C+(Y1+1)+(Y2+1)+(Y3+1)，
								假设Y1，Y2，Y3是由小到大的三个数，则可以优化成这样，这样扫描行数为
								Y3 id1 = select * from t limit @Y1，1； 
								id2= select * from t where id > id1 limit @Y2-@Y1，1； 
								select * from t where id > id2 limit @Y3 - @Y2，1； 
								直接定位来减少扫描
						5.随机其他思路  业务开发复杂性综合考虑
								1.k缓存或者redis缓存。由于需要随机 访问，数组比较好。假如一个单词平均10个字节，10*10000，不到1M就装下了
								2.数据库来做，上面方案空洞的问题，如果单词库不变，可以在上 线前整理数据，把空洞处理调。比如：原来单词存在A表，新建B表 ，执行 insert into B(word) select word from A. B的id是自增的，就会生成连续的主键

			为什么这些SQL语句逻辑相同，性能却差异巨大

						1.条件字段函数操作		
								1.对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走 树搜索功能。
								  函数处理后的值无法运用原来的索引树
								2.虽然explain中索引走的是对应字段，但改字段是遍历处理的，没有使用多叉树直接定位 从
								  扫描row可以看到

								优化  从select count(*) from tradelog where month(t_modified)=7; 
														|
										1. select count(*) from tradelog where    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or     -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
								3.select * from tradelog where id + 1 = 10000 
										==> where id = 10000 -1 


						2.隐式类型转换

								1.如果类型不一致则将string转换int
									相当于mysql帮你做了select * from tradelog where  CAST(tradid AS signed int) = 110717;
									即对索引做了函数操作

						3.隐式字符编码转换
								1.字符集不同，不使用索引
									CONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集
									 CONVERT 函数是加在输入参数上的，可以使用索引

						索引字段不能进行函数操作，但是索引字段的参数可以玩函数
						
			
			为什么我只查一行的语句，也执行这么慢
						1.查询长时间不返回    
								1.show processlist 查看状态
								2.等 MDL 锁 Waiting for table metadata lock 
								3.现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。
								4.select blocking_pid from sys.schema_table_lock_wait 查看阻塞id
								5.kill <=== mysql如何kill呢？
						2. Waiting for table flush
						3. 等行锁
								1. select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G
								2.KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被 断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁

						4.查询慢
								1.A:开始事务 - Bupdate +1 100w次 - A select id = 1 - A select id =1 lock in share mode
								2.结果A1查到：1 A2查到100001；为什么A1比A2慢呢？A2不是都加了锁么？

							==>带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所 以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，判断和当前事务关系是否可见 。才将 1 这个结果返回。


			幻读是什么，幻读有什么问题
						1.A: 开启事务 - 	select *from t where d =5 for update（q1）;						 q2				q3
					      B:												update set d=5 where id = 0;
					      C:																				insert..
					    过程：
					    		1. Q1 只返回 id=5 这一行； 
					    		2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行； 
					    		3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、 id=1 和 id=5 的这三行。


					    解释：
					    		1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因 此，幻读在“当前读”下才会出现。 === for update使其成为了当前读 == 读到所有 已经提交的记录的新值
					    		2. 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能 称为幻读。 ===  幻读仅专指“新插入的行”。


					    todo：幻读没有完全看完

					    
						MySQL有哪些“饮鸩止渴”提高性能的方法
							1.短链接
								现象: max_connections加大会造成负载可能会进一步加大，大量的资源耗费在 权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求
									1.先处理掉那些占着连接但是不工作的线程。
										1.show processlist 
										2.select * from information_schema . innodb_trx\G 查询事务状态
										  比如select语句执行完可以中断连接，但update没有commit之前是不可以的
										3.优先断开事务外空闲太久的连接；如果这样还不够，再考 虑断开事务内空闲太久的连接。

										有损：客户端在发起下一个 请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。不重新连接， 而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没 恢复”。
											不重新连接， 而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没 恢复”。

									2.减少连接过程的消耗
										–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内

							2.慢查询
									1.原因：
											1. 索引没有设计好； 
													1.过紧急创建索引
															1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句 加上索引； 2. 执行主备切换； 3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。

															gh-ost 工具

											2. SQL 语句没写好； 
											3. MySQL 选错了索引。

									2.测试过程提前定位到问题
											1.慢查询日志（slow log）打开，并且把 long_query_time 设置 成 0，确保每个语句都会被记录入慢查询日志； 
											2.在测试表里插入模拟线上的数据，做一遍回归测试； 
											3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。 


							3.qps突增或者应用bug
									1.全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是 一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么 快，那么就可以从数据库端直接把白名单去掉。 2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后 断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。 
									3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。 		这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写 成"select 1"返回。 <-- 评估

							==> sql审计

						*********
						MySQL是怎么保证数据不丢？

							1.流程
								1.binlog写入：
									1.一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入
									2.binlog cache --write-> page cache(文件系统) --fsync-->(磁盘) 
									3.write 和 fsync 的时机
											1. sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； 
											2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； 
											3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。提升性能。对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

									问题：写入到page cache 不怕丢失吗？ 会 

									==> 服务器一般都是双路电源的，磁盘电池，磁盘阵列 。保证不会断电。 

									==> 对于服务调用来说，我们没有必要用一个线程从头到尾处理完，在返回用户；比如这里的 ‘暂存’位置。我们认为这是 ‘写入成功的地方’ ---不会需要其结果 ；需要另一个线程定时轮询处理可以了。。。 像：kafka...当然也提供了灵活的flush机制去选择
										kafka:
											  1.集群 - 分区
											  2.

									==> 无论是mysql还是kafka，为了保证一致性其实这种 ‘ 由各自的组件完成功能，比如自己维护持久化...而不是完全由client控制 ’
									==> 异步思路：1.上面讲的暂存在安全位置，另外线程来刷盘    平时使用的大幅优化 vs 特殊(都断电)情况下数据的丢失
												 2.异步触发，主线程回到位置处理自己，在合适地方栅栏他们一起处理。
												   或者说使用futruecompate,调用多个异步任务内部关联性执行。



								2.redolog写入：
									1.redo log buffer -- page cache -- 磁盘
									2.一致性：
										如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交， 所以这时日志丢了也不会有损失。

						 		
						 		===> 两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。
						    		 到底是如何保证一致性的?	
						    		 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等 待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

						    		 page模式 vs row模式	




						    	3.磁盘能力也就两万左右,mysql tps 四万次磁盘怎么实现的
						    		1.group commit  
						    		2.log sequence number，LSN  每次写入长度为 length 的 redo log， LSN 的值就会加上 length。

									==> 思路：组提交，减少iotps / 延迟加载

								问题:
									事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这 会不会导致主备不一致呢？
									回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。

								实际上数据库的 crash-safe 保证的是：
										1. 如果客户端收到事务成功的消息，事务就一定持久化了；  ---> 如何保证的呢
										2. 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了； 
										3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的 逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以 了。


						MySQL是怎么保证主备一致的

								1.为什么备库执行了 binlog (归档)就可以跟主库 保持一致了呢？高可用架构  一主一备演化过
										1.备库设置为readonly
											1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作； 
											2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
											3. 可以用 readonly 状态，来判断节点的角色

											readonly 设置对超级 (super) 权限用户是无效的，而用于同 步更新的线程，就拥有超级权限。

										2.binlog 的三种格式对比
											1.statement
												statement 格式下，记录到 binlog 里的是 ' 语句原文 '，因此可能会出现这样一种情 况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时 候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的
											2.row
												 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的 主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同 行的问题。

											3.mixed
												因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。

												但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如 果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占 用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。

												所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意 思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。

								2.越来越多的场景要求把 MySQL 的 binlog 格式设置成 row，为了：恢复数据
												新增 - 删除
												update： binlog 里面会记录修改前整行的数据和修改后的整行数据

												如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？set 中函数now操作
													mysqlbinlog多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的 返回时间。

												同步时，mysql内部维护的上下文，共同作用完成同步

								3.主备切换
										1.互为主备，循环复制问题
												1.通过server id标记是否时自己产生的日志

								演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。

						MySQL是怎么保证高可用？
								1.主备延迟，又如何做到切换呢？
										1.如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？
												其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函 数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。
								2.主备延迟原因
										1.备库所在机器的性能要比主库所在的机器性能差。因为主备可能发生切换，备库随时可能变成主库，所以主备 库选用相同规格的机器，并且做对称部署，
										2.备库的压力大
												1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
											    2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的 能力。
										3.大事务
												1.不要一次性地用 delete 语句删除太多数 据。其实，这就是一个典型的大事务场景。
												2.大表 DDL
										4.备库的并行复制能力
								3.切换过程
										1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一 步，否则持续重试这一步；
										2. 把主库 A 改成只读状态，即把 readonly 设置为 true； 
										3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止； 4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false； 5. 把业务请求切到备库 B。


										1.可靠性优先策略
										2.可用性优先策略

										1.并行复制策略

						读写分离
								1.

									==> 验证完整性：每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。



						********锁  todo:
								1.《30.用动态观点看加锁》
								2.《43.要不要使用分区表》
								3.《44.说一些好问题》




						误删数据后除了跑路，还能怎么办？
								1. 使用 delete 语句误删数据行； 
								2. 使用 drop table 或者 truncate table 语句误删数据表；
							    3. 使用 drop database 语句误删数据库； 
							    4. 使用 rm 命令误删整个 MySQL 实例

							    解决方案:《31:误删数据后除了跑路，还能怎么办？》针对不同情况进行恢复

							    建议：四个脚本分别是：备份脚 本、执行脚本、验证脚本和回滚脚本


						为什么有的语句kill不掉？ --- hook以及其他状态处理 --设置状态
								1.kill类型
										1.kill query + 线程 id，表示终止这个线程中正在执 行的语句；
										2.kill connection + 线程 id，这里 connection 可缺省，表示断开这个线 程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的
								2.kill执行流程
										1.信号：类似于linux中kill -n thread_id;调用是发送‘ 信号 ’，而不是直接调用底层kill..，也不是类似api同步调用，而是异步，
										  等价于发送信号。异步：事务的处理不直接需要该调用返回值，流程仍可以继续，减少等待。信号相对于平时的异步还是更加一层
										  的含义：就是可以中断某个状态，比如这里的线程等待，锁等待。相当于执行了interrupt,而不是将当前处理命令放到等待队列
										  比如：timeOut等底层也是发一个信号给执行线程

										  中断含义：必然这个方法只能由其它线程来执行了（自己都阻塞了，执行个鬼），而且是在请求进入熔断器时，并在超时时间之后执行，有点绕，比如超时时间是200ms，那么请求进入熔断器之后，再过200ms，就执行 interrupt()，但是在200ms之内有数据返回，那么就不执行 interrupt()了。

										2.一个语句有多处‘ 埋点 ’，判断后执行对应逻辑
											1.是数据采集领域（尤其是用户行为数据采集领域）的术语，指的是针对特定 '  用户行为或事件进行捕获、处理和发送的相关技术及其实施过程  ' 。比如用户某个icon点击次数、观看某个视频的时长等等
											2.埋点：https://blog.csdn.net/weixin_40106836/article/details/95490497
											3. vs 日志 

										3.Listner模式 - event事件 
												inteceptexx(){
													callListerHandler()
												}

								3.为什么在执行 kill query 命令时，这条语句不像第一个例子的 update 语句一样退出呢
										1.这个等待进入 InnoDB 的 ‘ 循环过程 ’ 中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。所以虽然是killed状态本质还是在后台存在该线程的
										2.只有等到满足进入 InnoDB 的条件后，session C 的查询语句继续执行，然后才有 可能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION，再进入终止逻辑 阶段。

										场景：
											1.线程没有执行到判断线程状态的逻辑  IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程 的状态。
											2.终止逻辑耗时较长
													1. 超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本 做回收操作，耗时很长。 
													2. 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删 除临时文件可能需要等待 IO 资源，导致耗时较长。 
													3. DDL 命令执行到后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资 源影响耗时较久

										ctrl + c 只是中止了客户端线程，服务段线程仍然存在且在执行

										3.如何加快kill呢？
											1.InnoDB 并发度的问题，你就可以临时调大 innodb_thread_concurrency 的值
											2.停掉别的线程，让出位子给这个线程执行。
											3.如果是回滚逻辑由于受到 IO 资源限制执行得比较慢，就通过减少系统压力让它加速。


								4.客户端误解
										1.表多不会造成客户端连接慢
											1.原因是：当使用默认参数连接的时候，MySQL 客户端会提 供一个本地库名和表名补全的功能。创建对应hash。耗时在这里
											2.-quick参数：会让本地变快，但服务端变慢。 比如：跳过缓存、跳过历史记录行为



						我查这么多数据，会不会把数据库内存打爆？
								1.db server端对全表扫描的处理 
									一个select大表结果集保存在哪里呢？  mysql -h$host -P$port -u$user -p$pwd -e "select * from db1.t" > $target_file
										1.服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：
											1. 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的， 默认是 16k。 
											2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。 
											3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。 
											4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。
											5.也就是说每次查询占用内存大小就是net_buffer这么大 

											MySQL 是“边读边发的”

											如果客户端接收得 慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。
											从不同数据量、性能维度提供多种策略：
											如果有一个业务的逻辑比较复杂，每读 一行数据以后要处理的逻辑如果很慢，就会导致客户端要过很久才会去取下一行数据就会出现send to client的state
											可以使用mysql_store_result 这个接口，直接把查询结果保存到本地内存。
											有同学说到自己因为执行了一个大 查询导致客户端占用内存近 20G，这种情况下就需要改用 mysql_use_result 接口了。


									以上内容是考虑db服务器端内存问题、那client的内存问题如何解决呢？
										1.分批读取(分页查询)
										2.



									2.send to data
										1.是发送数据整体状态(正在执行)，可能在任意阶段，比如send to client ,也可能在锁等待

								2.全表扫描对 InnoDB引擎的影响
										1.buffer pool 内存命中率  show engine innodb status ，可以看到“Buffer pool hit rate”字样，显示的就是 当前的命中率。比如图 5 这个命中率，就是 99.0%。
										2.InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成 可用物理内存的 60%~80%。
											可以看出db内存占用主要在 ‘ engine的bufffer pool上 ’ 
										3.流程
											1.如果查询命中缓存buffer pool直接返回
											2.否则从磁盘中load,如果不是最新就拿该数据 + redolog 拿到最新
													1.通过LRU更新buffer pool(本质就是一个链表)
															1.问题：如果我们查询一个不常使用的历史全量数据，导致全部没有命中buffer,耗时，并且由于该从操作导致刷新了 ‘ 只为一次 ’的buffer,那么是无意义的。后面回到原查询还是耗时。的内存命中率急剧下 降，磁盘压力增加，SQL 语句响应变慢。 <---冷数据
													2.优化： InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域
															1.要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法 一样，将其移到链表头部，变成状态 2。 
															2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但 是新插入的数据页 Px，是放在 LRU_old 处。 
															3. 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断： 
																	1.若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；
																	2.如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间， 是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。
													
											==>特定场景下，从特点、全局优化了策略。

													这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历 史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：
															1. 扫描过程中，需要新插入的数据页，都被放到 old 区域 ; 
															2. 一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数 据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；
															3. 再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会 移到链表头部（也就是 young 区域），很快就会被淘汰出去。

											        问题：
											        		1.如果join多次呢，导致冷数据访问间隔超过1s，会挪到list head
											        		2.如果冷数据较大，无法放入到3/8区域呢？业务正常访问的数据页，没有机会进入 young 区域。



											3.最新(一致)则直接返回

								思考：写代码时，从磁盘、db load数据后，如何判断这些数据是否会撑爆处理机内存？大数据场景下呢？

						到底可不可以使用join？
									1.join是否影响性能、会影响到哪些方面
										1. 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引， 其实是没问题的； 
										2. 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不 要用。

									2.如何优化join
										1.选择驱动表 ： 驱动表是走全表扫描，而被驱动表是走树搜索。
												1.被驱动表： 2 为底的 M 的对数，记为 log M，查一行的时间复杂度是 2*log M。
												2.驱动表的行数是 N，执行过程就要扫描驱动表 N ， 复杂度是 N + N*2*log M。

											这个结论的前提是“可以使用被驱动表的索引”。如果没有的化，则是很慢的

											对于没有索引的join则是:
												1.把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因 此是把整个表 t1 放入了内存；

												2.扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条 件的，作为结果集的一部分返回。

												问题：这和上面没有索引一样都是扫描了M*N行，处理这么多次，有什么提升？
													1.后者判断是内存操作，速度上会快很多，性能也更好

												如果join_buffer放不下呢？ 分段+清空buffer复用 
												==>join_buffer_size 越大，一次可以放入的 行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。


										2.什么是小表
												 1.select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50; t2就是小表
												 2.select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
												 		两个表的数据本身就是100行
												 		表 t1 只查字段 b，因此如果把 t1 放到 join_buffer 中，则 join_buffer 中只需要放入 b 的值；
														表 t2 需要查所有的字段，因此如果把表 t2 放到 join_buffer 中的话，就需要放入三个字 段 id、a 和 b
														“只需要一列参与 join 的 表 t1”是那个相对小的表。

											 ===> 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过 滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”， 应该作为驱动表。


										3.Multi-Range Read 优化 (MRR)   主要目的是尽量使用顺序读盘
												1.索引 - 主键索引 - 回表查询数据(回表肯定是一行行搜索主键索引的)
												2.大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的 递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。
													1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ; 
													2. 将 read_rnd_buffer 中的 id 进行递增 ‘ 排序 ’ ； 
													3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

												默认不使用。 使用set optimizer_switch="mrr_cost_based=off"会强制用到

										4.Batched Key Access(BKA)
												1.从驱动表取出一部分值，放到join_buffer中
												2.BKA依赖于MRR



									3.join中驱动表的影响  --explain可以看到
										1.指定表驱动select * from t1 straight_join t2 on (t1.a=t2.a); t1驱动t2
										2.使用小表驱动大表
											1. 从表 t1 中读入一行数据 R； 
											2. 从数据行 R 中，取出 a 字段到表 t2 里去查找； 
											3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分； t1走的全部、t2走的是索引(快)。
													相当于嵌套循环
											4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

										join相对于应用中拼接sql，在拿for去查好处：比join 多了 100 次交互。除此之外，客户端还要自己拼接 SQL 语句和结果。

									4.大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中 率。
										影响：
											1. 可能会多次扫描被驱动表，占用磁盘 IO 资源； 
											2. 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会 占用非常多的 CPU 资源； 
											3. 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。
										优化：
											1. 给被驱动表 的 join 字段加上索引，把 BNL 算法转成 BKA 算法
													1.如果sql是低频，则不用添加索引
													2.where..等条件过滤后,数据量较小 从100w - 2000 则不用添加索引
											2.问题：加索引占用空间、不加索引浪费时间，则两全其美的办法
												考虑使用临时表。使用临时表的大致思路是：
													1. 把表 t2 中满足条件的数据放在临时表 tmp_t 中； 
													2. 为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引； 
													3. 让表 t1 和 tmp_t 做 join 操作。
															create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb; 
															insert into temp_t select * from t2 where b>=1 and b<=2000; 
															select * from t1 join temp_t on (t1.b=temp_t.b);


									5.扩展 -hash join
											1. MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join
											2.实现：
													1. select * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构， 比如 C++ 里的 set、PHP 的数组这样的数据结构。 
													2. select * from t2 where b>=1 and b<=2000; 获取表 t2 中满足条件的 2000 行 数据。 
													3. 把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。 满足匹配的条件的这行数据，就作为结果集的一行。

						为什么临时表可以重名		create temporary table temp_t like t1; <==	create temporary table temp_t like t1;
									1.临时表和普通表区别
											1.临时表不是内存表
											2.一个临时表只能被创建它的 session 访问，对其他线程不可见。临时表就特别适合我们文章开头的 join 优化这种场景
													1.不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要 担心表名重复导致建表失败的问题。 
													2. 不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断 开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表 由于会自动回收，所以不需要这个额外的操作。

											3.show tables 命令不显示临时表
											4.可重复

											为什么使用临时表？
													1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就 需要额外的内存，来保存中间结果；
												    2. join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；
													3. 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中， union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

									2.临时表应用
											1.不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程
													相当于局部变量.在线程退出的时 候，临时表也能自动删除，省去了收尾和异常处理的工作。

											2.分库分表系统的跨库查询就是一个典型的使用场景。
													proxy层-路由 N%1024
														语句包含分区字段：
																分区 key 的选择是以“减少跨库和跨表查询”为依据的。如果大部分的语 句都会包含 f 的等值条件，那么就要用 f 做分区键。这样，在 proxy 这一层解析完 SQL 语 句以后，就能确定将这条语句路由到哪个分表做查询。
														语句不包含分区字段：
																第一种思路是，在 proxy 层的进程代码中实现排序。
																	问题:
																		 1. 需要的开发工作量比较大。我们举例的这条语句还算是比较简单的，如果涉及到复杂的 操作，比如 group by，甚至 join 这样的操作，对中间层的开发能力要求比较高； 
																		 2. 对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题。

																第二种思路是：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在 这个汇总实例上做逻辑操作。
																		 1.创建一个临时表 temp_ht

																第三种思路是：在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放 到 32 个分库中的某一个上。
											3.主备复制
													1.临时表只在线程内自己可以访问，为什么需要写到 binlog 里面
													2.binlog中的row模式：insert into t_normal select * from temp_t; 
														insert插入的是具体的数据，而不需要temp_t

											4.从sort buffer/ join buffer 到临时表
													1.执行计划中(Using temporary)
													2.场景
															1.union
															2.group by  内存临时表转成磁盘临时表
																	优化：
																		索引：
																			如果有序则当碰到第一个 1 的时候，已经知道累积了 X 个 0，结果集里的第一行就是 (0,X);当碰到第一个 2 的时候，已经知道累积了 Y 个 1，结果集里的第二行就是 (1,Y);不需 要临时表，也不需要再额外排序。

																			 alter table t1 add column z int generated always as(id % 100), add index(z);
																			 select z, count(*) as c from t1 group by z;
																		
																		直接排序： group by 语句中加入 SQL_BIG_RESULT ，直接用磁盘临时表。
																			select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;

																			MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然 你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。

																	总结:
																		1. 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；
																			跳过排序，直接返回
																	    2. 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort； 
																	    3. 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表； 
																	    4. 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算 法得到 group by 的结果。

									2.临时表可以重命名
											1.用进程id_线程id_序列号完成

						Memory引擎优点：
									1.特点
										1.Memory 引擎的数据和索引是分开的
										2.主键 id 索引里，存的是每个数据 的位置。 innodb直接索引对应数据而不是位置
										3.主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。
										4. Memory 引擎 支持 hash 索引。当
										5.内存表的所有数据都保存在内存，而内存的读写 速度总是比磁盘快。

										问题：
										1.锁粒度问题； 
										2.数据持久化问题。


									2.vs innodb
									3.使用场景

						自增主键为什么不连续
									1.查看下次主键值
										show create table  t\G;  AUTO_INCREMENT=2就是下次的值
									2.自增值保存在哪里？
										1.MyISAM 引擎的自增值保存在数据文件中
										2.innodb 
											 MySQL 8.0 版本后，才有 了 自增值持久化
											 MySQL 5.7 及之前的版本  每次重启db, max(id)+1 
									3.不连续发生的场景
											1.唯一键冲突是导致自增主键 id 不连续的第一种原因。
											2.事务回滚也会产生类似的现象
											3.数据同步 基于binlog生成主键
									4.不设计回退
									5.只要递增就能使用优化策略，不必要连续
									6.自增锁
											1.MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值 是 1。
											1.这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束 后才释放锁； 
											2.这个参数的值被设置为 1 时：
													普通 insert 语句，自增锁在申请之后就马上释放；
													类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
											3.这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。

											思考：多个会话发生时，对就策略的影响


						insert为什么那么多锁
									1.并发问题  导致执行sql和写入binlog的顺序不一致，导致在 ‘ 备库 ’ 中主键不一致。最终导致不一致
									2.insert循环写入
									3.insert 唯一键冲突



						怎样最快复制一张表


						InnoDB 内存的一个作 用，是保存更新的结果，再配合 redo log，就避免了随机写盘。
						至于长事务的影响，就要结合我们前面文章中提到的锁、MVCC 的知识点了。
						如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；
						当然读的事务也有问题，就是会导致 undo log 不能被回收，导致回滚段空间膨

						 Using index，表示只使用了覆盖索引，


						show processlist 查看进程信息，比如sql_id、命令、状态、	

=================从后往前

				要不要使用分区
						1.CREATE TABLE `t` (  `ftime` datetime NOT NULL,  `c` int(11) DEFAULT NULL,  KEY (`ftime`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 PARTITION BY RANGE (YEAR(ftime))
						(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB, PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB, PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB, PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB); insert into t values('2017-4-1',1),('2018-4-1',1);
						对于引擎层来说，这是 4 个表；
						对于 Server 层来说，这是 1 个表。
						一个.frm 文件和 4 个.ibd 

						2.间隙锁
							1.

			===44章：问题解答

				自增id用完怎么办？
						1.row_id:对于没有指定主键的表，则默认row_id,且如果用完后，不会报冲突而是覆盖。所以还是定义主键，报错比数据丢失(可靠性)要好
						2.xid:事务id global_query_id， MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件 里，Xid 一定是惟一的。
						   一种极端情况：一个binlog中用完了所有的xid,重0开始，导致问题。这个值是2^64。理论上
						3.Innodb trx_id
							 1.Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的
							 2.trx_id :判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。
							   可以通过 information_schema.innodb_trx 查看
							 3.对于只读事务，该值默认都是0，但显示会很大。对于select..for update /update操作才会申请对应
							   id。不显示0而显示一个很大的值，是因为该值由事务指针地址转换而来，便于链路查看。如果是0就无法
							 4.并不是完全—+1，因为会涉及内部比如级联索引更新、删除旧数据打标等
							 5.max_trx_id 会持久化存储，重启也不会重置为 0，理论上如果用完会出现脏读 <== bug
						4.thread_id





				主键作为外键如何刷新？
						1.尽量不要修改原来关联的id
						2.修改类型，关联表的类型也需要修改


1.对于数据库优化，其实许多不同的方案之间是如何对比性能呢？实验？
2.如何使用性能工具或者指标定位性能问题点？ioutil（IO 利用率）? jvm各个指标查看 ? 如何符合起来分析？运行时？
3.多少数据量算大表
4.学完mysql后,函数转换excel + sql语句的准确性<书籍：xxxx>/sql语句规范 + explain xx + 建表规范 + mysql 
5.边界、异常、统一模型解决方案 === 
  学习过程中喜欢的就是这种交叉的瞬间。交叉多了，就形成了网络。 而有了网络以后，吸收新知识的速度就很快了。
6.如果我们懂得一些参数，并可以理解这些参数，就可以做正确的设置了。而如果我们 进一步地懂得一些原理，就可以更巧妙地解决问题了
  <== 源码逻辑 == 本质

explain 的结果里 面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地 判断 tradeid 的值是否匹配。

全表扫描默认是值“扫瞄主键索引

	
问题：
		1.多版本并发控制（MVCC）
		2.changebuffer和redolog区别，binlog,undolog

			详见：《15丨答疑文章（一）：日志和索引相关问题》

				1.binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明 了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。

				2.在两阶段提交的不同瞬间，MySQL 如果发生异常重启， 是怎么保证数据完整性的？

					1.是写入 redo log 处于 prepare 阶段之后、写 binlog 之 前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢 复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库
					2.是 binlog 写完，redo log 还没 commit 前发生 crash
							1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 
							2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并 完整：
								 a. 如果是，则提交事务； b. 否则，回滚事务。
				问题：MySQL 怎么知道 binlog 是完整的?
							1.格式statement 格式的 binlog，后会有 COMMIT；
								row 格式的 binlog，后会有一个 XID event。
							2. MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。

				3.redo log 和 binlog 是怎么关联起来的?
					1.它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log
					2.如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
						如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应 的事务
				
				4.......

		3.事务在mvcc中使用，和独写锁的读写
		4.不一致问题场景：
				1.主从不一致
				2.

完整的构建表要有描述/引擎/字符集/表空间/主键/索引/扩展字段/只读
 CREATE TABLE `tradelog` (  `id` int(11) NOT NULL,  `tradeid` varchar(32) DEFAULT NULL,  `operator` int(11) DEFAULT NULL,  `t_modified` datetime DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `tradeid` (`tradeid`),  KEY `t_modified` (`t_modified`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

select count(*) from tradelog where month(t_modified)=7; 而不是使用截取。直接函数。




show table status 命令显示的行数也不能直接使用。估算采样来的


因为不论是在事务支持、并发能 力还是在数据安全方面，InnoDB 都优于 MyISAM

构建全文索引：alter table t add FULLTEXT(field_name) 但会阻塞增删改操作，是非 Online 的。

如果一个高配的机器，redo log 设置太小，会发生 什么情况。
	redo log写满后，停止update;推进对应的checkpoint;现象就是磁盘压力很小，但是数据库出现间歇性的性能下跌。

下分布式ID（雪花算法生成的ID）生成的索引会比自增长的ID性能低吗？
	性能一样的，没有一定要“连续”，只要是递增


最优的动态平衡

================jvm对内存、磁盘管理、加载....

		参考大神：https://dbalife.info/categories/MySQL/
		参数参考：
				innodb_flush_log_at_trx_commit   这个参数设置成1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
				sync_binlog 					 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。
				transaction-isolation 			 show variables like '%transaction-isolation%';  / show variables like '%tx_isolation%';
				set autocommit=1     			 通过显式语句的方式来启动事务，避免查询开启事务，需要commit来完成 并不会因为多一步交互 。 执行 commit work and 	chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。
				show variables like '%char%' ;	 注意事项：修改编码 只对“之后”创建的数据库生效，因此 我们建议 在mysql安装完毕后，第一时间 统一编码。
				show variables like '%storage_engine%' ;
				show variables like '%innodb_lock_wait_timeout%';  锁等待
				show variables like '%innodb_deadlock_detect%';    死锁监测，出现死锁则回滚部分事务使其解锁
				show engine innodb status 

问题：	
	0.sql对应的函数 - sql写法 <== sql部分
			update T set c=c+1 where id = 1;
			update T set replace(xxx,x222) where id = 1;
			update T set contact(c,‘xxxx’) where id = 1;



	1.binlog/ relog 
	2.慢日志
	3.行列转换
	4.分页
			1.offset和rows的正负带来的影响；
				当偏移量很大时效率是很低的，可以这么做：
				采用子查询的方式优化，在子查询里先从索引获取到最大id，然后倒序排，再取N行结果集
				采用INNER JOIN优化，JOIN子句里也优先从索引获取ID列表，然后直接关联查询获得最终结果
    5.存储引擎区别对比  memory引擎 vs redis
    6.优化器是怎么选择索引的，有没有可能选择错等等
