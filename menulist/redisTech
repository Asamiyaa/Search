redis

    0.参考mysql关系型数据库去学习键值数据库
            1.场景”和“案例”作为驱动 == 整体和细节都要结合
                在“案例”层面，我会介绍数据结构的合理使用、避免请求阻塞和抖动、避免内存竞争和提升内存使用效率的关键技巧；
                在“场景”层面，我会重点介绍缓存和集群两大场景。       
                        1.缓存基本原理及淘汰策略，还有雪崩、穿透、污染等异常情况；
                        2.集群方案优化、数据一致性、高并发访问等问题  
            2.Redis 是一个非常优秀的系统，它在 CPU 使用、内存组织、存储持久化和网络通信这四大方面的设计非常经典


    1.分布式下几大特性
            0.redis全景图.png  + redis问题画像.png <== 重要
            1.高可用(可靠性)  数据尽量少丢失(持久化)，服务尽量少中断(主从)
                    1.一致性
                            1.主从 - 读写 - 同步
                                    1.读操作：主库、从库都可以接收；写操作：首先到主库执行，然后，主库将写操作同步给从库。
                                        1.如果从库可以写入，就存在不一致问题，如果要强一致，则加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销

                                        主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？

                                        操作
                                                replicaof  172.16.19.3  6379  从库上执行来备主库
                                                主从同步流程.png

                                    2.主从级联模式分担全量复制时的主库压力
                                        1.如果从库过多，就会fork多个子进程进行生成RDB,并且发送rdb到从库会影响到主库带宽。-主-从-从

                                    3.长连接
                                        基于长连接的命令传播，可以避免频繁建立连接的开销   <==无论怎样这种同步存在不一致为了性能和一致性并没有那么高

                                    4.主从断联，增量同步  <=== 所谓的自动处理能力
                                        当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。

                                        环： 主库只用把 master_repl_offset 和 slave_repl_offset之间的命令操作同步给从库就行。

                                        如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。

                                        缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。

                                        如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把repl_backlog_size 设为 4MB

                                        两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致

                                        参数：repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。

                                        ===> 降低所有的可能到最低 ，实际中没有强一致性。没有银弹 vs 是否自己没有想到




                                    5.一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销


                                    6.主库挂了，哨兵机制
                                            1.在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下
                                             ‘ 故障转移的 ’ 这三个问题
                                                    1.主库真的挂了吗？
                                                    2.该选择哪个从库作为主库？
                                                    3.怎么把新主库的相关信息通知给从库和客户端呢？

                                            2.哨兵：特殊模式下的 Redis 进程  监控(ping 心跳)、选主（选择主库）和通知(其他从库 replcaof新主库)
                                                    1.主观下线 vs  客观下线
                                                        避免误判   误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。
                                                        哨兵集群  - 少数服从多数

                                                    2.选举
                                                        筛选：检查从库的当前在线状态，还要判断它之前的网络连接状态(断连次数超出了一定的阈值)
                                                                down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间
                                                                断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库

                                                        打分：
                                                            从库优先级、从库复制进度以及从库 ID 号(如果前两个一样就取id最小)

                                            3.限制Redis Cluster规模的关键因素
                                                    1.通信 - 通信消息大小和通信频率 - 网络带宽 - 维持集群状态的统一 - 集群稳定
                                                            1.Redis Cluster 在运行时，每个实例上都会保存 Slot 和实例的对应关系（也就是 Slot 映射表），以及自身的状态信息
                                                    

                                                     Redis Cluster 的规模控制在 400~500 个实例
                                                     假设单个实例每秒能支撑 8 万请求操作（8 万 QPS），每个主实例配置 1 个从实例，那么，400~ 500 个实例可支持 1600 万~2000 万 QPS（200/250 个主实例 *8 万QPS=1600/2000 万 QPS），这个吞吐量性能可以满足不少业务应用的需求。






                                    7.哨兵挂了，如何处理
                                            1.sentinel monitor <master-name> <ip> <redis-port> <quorum> 
                                            2.哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？
                                                    1.Redis 提供的 pub/sub 机制
                                                    2.哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步
                                            3.哨兵还需要完成把新主库的信息告诉客户端这个任务。
                                                    客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

                                            4.由哪个哨兵执行主从切换？
                                                    leader选举

                                        ***************************
                                        通常，我们在解决一个系统问题的时候，会引入一个新机制，或者设计一层新功能，就像我们在这两节课学习的内容：为了实现主从切换，我们引入了哨兵；为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行。
                                        ****************************


                                        要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。

                                        每个哨兵的定时器执行周期都会加上一个小小的随机时间偏移，目的是让每个哨兵执行上述操作的时间能稍微错开些，也是为了避免它们都同时判定主库下线，同时选举Leader。最后，即使出现了都投给自己一票的情况，导致无法选出Leader，哨兵会停一段时间（一般是故障转移超时时间failover_timeout的2倍），然后再可以进行下一轮投票。

                                     8.Redis主从同步与故障切换  
                                     
                                                1.主从数据不一致
                                                        原因：因为主从库间的命令复制是异步进行的
                                                              网络延迟
                                                              从库本身性能
                                                        解决：
                                                              1.硬件-机房-网络
                                                              2.监控主从复制进度
                                                                    Redis 的 INFO replication 命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset）如果差值过大，从客户端列表中移除；赶上了再加入



                                                2.读到过期数据
                                                        1.惰性删除策略
                                                                当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据

                                                                尽量减少删除操作对 CPU 资源的使用，对于用不到的数据，就不再浪费时间进行检查和删除了

                                                                导致大量已经过期的数据留存在内存中，占用较多的内存资源

                                                                所以，Redis 在使用这个策略的同时，还使用了第二种策略：定期删除策略。
                                                                <==== 融合多种方案的优点，就像RDB + AOF


                                                        2.定期删除策略
                                                                多种策略

                                                        3.读到过期数据原因
                                                                1.Redis 为了避免过多删除操作对性能产生影响，每次随机检查数据的数量并不多。些数据就会留存在 Redis 实例中
                                                                2.从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据
                                                                  3.2后，判断数据过期，返回空。虽然不删除，需要等待主库命令
                                                                3.把数据的过期时间设置为具体的时间点，避免读到过期数据。
                                        
                                        EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点


                                                3.配置项设置得不合理从而导致服务挂掉
                                                        1.protected-mode  no 让哨兵之间通信
                                                        2.cluster-node-timeout 防止误报 10-20s
                                     

                                     9.脑裂
                                                1.多个主节点

                                                2.判断
                                                        1.确认是不是数据同步出现了问题 
                                                                master_repl_offset 和 slave_repl_offset 的差值
                                                        2.排查客户端的操作日志，发现脑裂现象
                                                                 上一步的差值为0，一个客户端仍然连接着宕机的主库
                                                        3.脑裂
                                                                主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。
                                                3.脑裂造成数据丢失
                                                        1.主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。

                                                4.如何解决
                                                        1.min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
                                                        2.min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK 消息的最大延迟（以秒为单位）。

                                                        即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。





                            
                            2.切片集群  -- db分片 -- 
                                    1.避免文件过大造成的处理慢问题
                                    2.纵向扩展 vs 横向扩展
                                            1.数据切片后，在多个实例之间如何分布？
                                                 crc16(key1)%5 -- hash slot(槽16384) -- 实例  redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4
                                                 在手动分配哈希槽时，需要把 16384 个槽都分配完，否则Redis 集群无法正常工作。

                                            2.客户端怎么确定想要访问的数据在哪个实例上？
                                                客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

                                                问题:
                                                    1.在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
                                                    2.为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。复制代码12GET hello:key(error) MOVED 13320 172.16.19.5:6379  vs ask..    

                                                    重定向机制:没有访问到,会返回moved,当前信息的地址


                                                问题:
                                                    1.为什么不直接使用map映射key和slot关系而是要使用crc计算后取值
                                                        1.整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间
                                                        2.并发访问问题;多份的一致性问题.当前计算的化消耗cpu,但不会有上面两个问题
                                                        3.多了一层slot层,则多了一层灵活和扩展 当于虚拟节点，这样可以灵活的扩缩容

                                                        如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。

                                                    2.取模操作相对于range操作可以有效防止数据倾斜

                            2.事务 acid
                    

                    2.持久化
                            1.Redis 需要在磁盘上读写 AOF 和 RDB
                                    1.写 AOF 和RDB 会造成 Redis 性能抖动
                                    2.Redis 集群数据同步和实例恢复时，读 RDB 比较慢，限制了同步和恢复速度。

                                    解决:非易失内存 NVM


                            2.AOF
                                    1.实现数据的持久化，避免从后端数据库中进行恢复(1.慢 2.后端db压力)，是至关重要的。
                                    2.AOF:wal(写前日志)  AOF(写后日志)
                                            1.为了避免额外的检查开销，不会先去对这些命令进行语法检查，aof避免记录了错误的命令
                                            2.不会阻塞当前的写操作

                                            1.先执行后写aof，如果在中间，造成内存和真实数据不一致，做缓存需要重启从db读取，如果做  db就有问题了
                                            2.AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险

                                        ===>能够控制一个写命令执行完后 AOF 日志写回磁盘的时机
                                                Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
                                                Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
                                                sNo，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

                                                取舍

                                                一是，文件系统本身对文件大小有限制，无法保存过大的文件；
                                                二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；
                                                三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。
                                    3.AOF 重写机制  Append Only File
                                            1.多变一 将同一条记录的多次操作整合为最后的操作
                                            2.和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

                                    4.一个拷贝两处日志
                                            1.日志重写.png
                                            “两处日志”又是什么呢？因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。AOF非阻塞的重写过程总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。

                                            <=== 类似于mysql中的主从同步中buff,暂存copy期间的操作

                                    问题：这里的不能保证一致恢复，万一写了内存，两处日志都没写入呢？恢复不就不一致了？

                            3.RDB(Redis DataBase) - 快速恢复 - checkpoint - 内存快照
                                    1.一般而言，只要你采用的不是 always 的持久化策略，就不会对性能造成太大影响。
                                    2.因为记录的是操作命令，而不是实际的数据，所以，用 AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍

                                    3.考虑点：
                                            1.对哪些数据做快照？这关系到快照的执行效率问题； 
                                                    save /bgsave --> bgsave
                                            2.做快照时，数据还能被增删改吗？这关系到 Redis 是否被阻塞，能否同时正常处理请求。    

                                                    避免阻塞和正常处理写操作并不是一回事。此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。

                                                    Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。
                                                    写时复制技术.png(只复制修改的部分，其他的部分主线程和fork共享)
                                            3.多久拍一次快照呢？
                                                    1.频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
                                                    2.bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。

                                            4.增量快照
                                                    同样存在多久拍一次的问题，如何权衡数据丢失和性能损耗

                                            5.混合使用 AOF 日志和内存快照
                                                    内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

                                                    注意操作过程中内存风险和cpu风险
                 


            2.高性能
                    1.数据结构
                            0.redis数据结构和底层数据结构对应关系
                                    1.内存数据库
                                    2.redis数据结构和底层数据结构对应关系.png <== 每个数据结构对应多个底层结构

                            1.从key找到value本身这个过程还是由全局哈希表索引完成 O(1)
                                跳表是在Redis的value类型为有序集合时采用的一种数据组织结构，作为集合内元素的索引，在有序集合中进行操作时会依赖于跳表索引。

                            2.哈希桶中的元素保存的并不是值本身，而是指向具体值的指针   

                            3.压缩列表
                                压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。

                                如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了

                            4.跳表
                                ‘ 有序链表 ’ 只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了‘ 多级索引 ’ ，通过索引位置的几个跳转，实现数据的快速定位
                                当数据量很大时，跳表的查找复杂度就是 O(logN）

                            单元素操作是基础；
                            范围操作非常耗时；
                            统计操作通常高效；
                            例外情况只有几个。
                                ==对上面四句话的解释：
                                    1.单个操作比如hget sadd都是O(1),hmget ...就是O(N)
                                    2.SCAN 系列操作（包括 HSCAN，SSCAN 和ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。
                                    3.类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)
                                    4.例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。直接定位O(1)List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素  <== 对应的api操作 。。尽量不用list的随机读写o(n)借助FIFO队列场景

                            5.问题：既然数组和list的复杂度高，为什么还要用呢？
                                    1.内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。 避免一些内存碎片

                    2.IO模型
                            1.为什么单线程的 Redis 能那么快
                                    1.Redis 是单线程，主要是  ‘ 指 Redis 的网络 IO和键值对读写是由一个线程 ’  来完成的，这也是 Redis 对外提供键值存储服务的主要流程。
                                    但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

                                    2.多线程 vs 单线程 -- 流程中,粒度可以控制在哪里
                                            1.并发访问控制
                                            2.易调试性和可维护性

                                            1.内存操作
                                            2.优秀的数据结构
                                            3.多路复用机制
                                    
                                    3.redis基本io.png   阻塞点
                                            1.当 Redis监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。
                                            2.当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。

                            2.基于多路复用的高性能 I/O 模型
                                    1.指一个线程处理多个 IO 流.select/epoll 机制（select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数）
                                      该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个IO 流的效果。

                                      redis多路复用IO.png

                                    2.在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低
                                      分诊台会一直处理这些诊断前的工作（类似于 Linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 Redis 单线程）

                                      干事要核心分离出来

                                    3.单线程性能瓶颈
                                        1.big key的操作。
                                        2.潜在的大量数据操作，比如 key *或者get all之类的操作，所以才引入了scan的相关操作。
                                        3.特殊的场景，大量的客户端接入

                   3.性能因素
                                1.影响因素 -- 以下内容是对其具体分析
                                    Redis 内部的阻塞式操作
                                    CPU 核和 NUMA 架构的影响；
                                    Redis 关键系统配置；
                                    Redis 内存碎片；
                                    Redis 缓冲区

                                2.交互操作   <===== 梳理流程
                                    redis交互操作.png

                                    客户端：网络 IO，键值对增删改查操作，数据库操作；
                                    磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；
                                    主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB文件；
                                    切片集群实例：向其他实例传输哈希槽信息，数据迁移。


                                3.哪些是阻塞的?  <=====  分析问题所在点
                                    和客户端交互时
                                        1.Redis 使用了 IO 多路复用机制  -- 不阻塞
                                        2.键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 Redis
                                            O(N)操作:如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。删除操作. 这些操作可以作为 Redis 的第一个阻塞点：集合全量查询和聚合操作。

                                        3.删除大量键值对数据的时候，最典型的就是删除包含了大量元素的集合，也称为 bigkey 删除 -- 阻塞操作

                                        当删除有 100 万个元素的集合时，最大的删除时间绝对值已经达到了 1.98s（Hash 类型）。Redis 的响应时间一般在微秒级别，所以，一个操作达到了近 2s，不可避免地会阻塞主线程。

                                        4. Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作) -- 阻塞操作
                                    
                                    和磁盘交互
                                        1.生成 RDB 快照文件，以及执行 AOF 日志重写操作已经由子线程完成.Redis 直接记录 AOF 日志时，会根据不同的写回策略对数据做落盘保存. AOF日志同步写 -- 阻塞 

                                    主从节点交互
                                        1.从库同步rdb文件进行flushdb操作,并且加载rdb文件到内存  ---阻塞

                                    切片
                                        1.Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移

                                4.上述的阻塞操作哪些可以使用异步操作?
                                        如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。我再解释下关键路径上的操作是啥。这就是说，客户端把请求发送给 Redis 后，等着 Redis返回数据结果的操作。

                                        1.集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了
                                        2.删除操作并不需要给客户端返回具体的数据结果,可以使用异步
                                        3.AOF 日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证AOF 日志中的操作记录已经落盘,无需返回具体的执行结果,所以可以异步
                                        4.从库要想对客户端提供数据存取服务，就必须把 RDB 文件加载完成。所以，这个操作也属于关键路径上的操作，我们必须让从库的主线程来执行

                                        主线程会把 ""AOF 写日志操作""封装成一个任务，也放到任务队列中(列表中) <=== 异步操作

                                        键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示： 4.0以后  
                                             FLUSHDB ASYNC 
                                             FLUSHALL AYSNC

                                        4.0以前:先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞

                                5.对于不能使用异步
                                        集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；
                                        从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。



                                6.cpu架构对redis性能影响
                                        1.cpu核心(物理) - 一级指令 - 二级缓存(几K) - L3(几M) - 内存
                                        2.超线程 
                                            每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。
                                            微妙
                                            CPU的 context switch 次数比较多. 一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行.需要将context信息重新加载
                                        3.避免 Redis 总是在不同 CPU 核上来回调度执行。于是，我们尝试着把 Redis实例和 CPU 核绑定了，让一个 Redis 实例固定运行在一个 CPU 核上。我们可以使用taskset 命令把一个程序绑定在一个核上运行

                                        taskset -c 0 ./redis-server

                                7.慢排查  --  结合redis架构.png 了解底层原理关系  -- redis log + latency monitor 
                                        1.某些时刻，有些 Redis 实例会出现很高的响应延迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟“毛刺
                                        2.当前环境下的 Redis 基线性能:  
                                            ./redis-cli --intrinsic-latency 120
                                            返回:Max latency so far: 119 microseconds. 最大119微妙
                                        3.把运行时延迟和基线性能进行对比，如果你观察到的 Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。

                                        为了避免网络对基线性能的影响，刚刚说的这个命令需要在服务器端直接运行，这也就是说，我们只考虑服务器端软硬件环境的影响。

                                        如果你想了解网络对 Redis 性能的影响，一个简单的方法是用 iPerf 这样的工具，测量从Redis 客户端到服务器端的网络延迟。


                                        1.慢查询命令  根据redis文档判断是否慢查询命令
                                                1.SMEMBERS -- SSCAN
                                                2.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例
                                                3.KEYS 命令需要遍历存储的键值对，所以操作延时高. KEYS 命令一般不被建议用于生产环境中

                                        2.过期key
                                                1.大量key同时过期 
                                                    如果一批 key 的确是同时过期，你还可以在EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力


                                        针对redis-cluster还可以使用scan命令么?

                                        Redis cluster模式下不支持跨节点的SCAN操作，要想得到整个集群的SCAN结果，可以遍历每个节点，分别进行SCAN操作，然后在客户端合并结果。另外有一个方法，是可以用Hash Tag，也就是在键值对的key中使用花括号{}，例如{user:}1, {user:}2这样。Redis cluster会针对花括号中的部分进行哈希，这样可以把具有相同前缀的key分配到同一个哈希槽里面。不过，这个方法的潜在风险是：大量相同前缀的key被分配到同一个哈希槽里面了，会导致数据在哈希槽之间分布不均衡。如果要用这个方法，需要评估下key的分布情况。

                                        3.操作系统/文件系统
                                                1.如果 Redis 的内存不够用了，操作系统会启动 swap机制，这就会直接拖慢 Redis

                                                    AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间

                                                        1.增加机器内存
                                                        2.集群

                                                    排查过程:
                                                        1.redis-cli info | grep process_id
                                                        2.cd /proc/5332
                                                        3.cat smaps | egrep '^(Swap|Size)'

                                                         MB，甚至 GB 级别的 swap 大小时，就表明，此时，Redis 实例的内存压力很大，很有可能会变慢。所以，swap 的大小是排查Redis 性能变慢是否由 swap 引起的重要指标

                                                2.内存大页:写时复制机制,修改较少,导致大量复制
                                                        线上禁止使用:echo never /sys/kernel/mm/transparent_hugepage/enabled



                                                3.写入文件持久化
                                                         always 策略的要求了。所以，always 策略并不使用后台子线程来执行。
                                                         如果在重写日志时，AOF 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。 <== 根据业务等级,可以丢失的就不要使用always,数据丢了从数据库获取

                                                         临时解决:no-appendfsync-on-rewrite yes
                                                                在 AOF 重写时，不进行 fsync 操作。也就是说，Redis 实例把写命令写到内存后，不调用后台线程进行 fsync 操作，就可以直接返回
                                                                数据会丢失

                                                                固态硬盘


                                8.内存碎片 不连续
                                        1.内存申请 分配器为了避免了一次分配操作,一般会按照整数页倍数申请
                                        2.键值对大小不一样和删改操作

                                        <==== 垃圾回收机制 / db analyze

                                        1.INFO memory
                                        2.mem_fragmentation_ratio = used_memory_rss/ used_memory
                                            Redis 申请使用了 100 字节（used_memory），操作系统实际分配了 128 字节（used_memory_rss），此时，mem_fragmentation_ratio 就是1.28

                                        ==> mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的
                                            mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了 50%

                                        redis自带的碎片清理
                                            1.开启:config set activedefrag yes
                                            2.active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。
                                            3.active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于25%，保证清理能正常开展；active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。info memory 命令是一个好工具，可以帮助你查看碎片率的情况；碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；

                                            既保证清理工作能正常进行，又避免了降低 Redis 性能。

                                9.缓冲区 - 处理速度不匹配进行暂存
                                        1.客户端和服务器端之间进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。
                                        2.主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据

                                        溢出造成数据丢失 / 过大导致内存占用 阈值
                                            1.写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；
                                            2.服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。

                                            CLIENTLIST 命令
                                                cmd，表示客户端最新执行的命令。这个例子中执行的是 CLIENT 命令。qbuf，表示输入缓冲区已经使用的大小。这个例子中的 CLIENT 命令已使用了 26 字节大小的缓冲区。qbuf-free，表示输入缓冲区尚未使用的大小。这个例子中的 CLIENT 命令还可以使用32742 字节的缓冲区。qbuf 和 qbuf-free 的总和就是，Redis 服务器端当前为已连接的这个客户端分配的缓冲区总大小。这个例子中总共分配了 26 + 32742 = 32768 字节，也就是 32KB 的缓冲区。

                                                如果 qbuf 很大，而同时 qbuf-free 很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。


                                                1GB 的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；另一方面，如果再大的话，Redis 就有可能因为客户端占用了过多的内存资源而崩溃。

                                            场景:服务器端返回 bigkey 的大量结果；
                                                 执行了 MONITOR 命令(不要在线上生产环境中持续使用 MONITOR)；
                                                 缓冲区大小设置得不合理。

                                                 通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为 0，也就是不做限制。 

                                            造成问题
                                                缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。

                                            造成原因
                                                针对命令数据发送过快过大的问题，对于普通客户端来说可以避免 bigkey，而对于复制缓冲区来说，就是避免过大的 RDB 文件。

                                                针对命令数据处理较慢的问题，解决方案就是减少 Redis 主线程上的阻塞操作，例如使用异步的删除操作。

                                                针对缓冲区空间过小的问题，解决方案就是使用 client-output-buffer-limit 配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改 Redis 源码。







            3.高扩展
                    1.消息队列
                            1.必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。
                                    1.消息保序 发送操作 比如减1,减2 而不是结果 10-5/10-3这种.存在问题:读取的时候乱序有问题
                                    2.重复消费 上面发送操作可能造成重复
                                    3.可靠性 可靠消息保证

                                    Redis 的 List 和 Streams 两种数据类型
                                    1.list本身就是有序的
                                    2.轮询读取改为brpop 阻塞式读取 有消息后再读取而不是死循环
                                    3.消费者实现幂等
                                    4.BRPOPLPUSH 消费消息后将该消息插入到另一个list进行备份 mqback

                            2.stream Streams 是 Redis 专门为消息队列设计的数据类型
                                    XADD：插入消息，保证有序，可以自动生成全局唯一 ID； --- XADD mqstream * repo 5
                                    XREAD：用于读取消息，可以按 ID 读取数据；
                                    XREADGROUP：按消费组形式读取消息； <=== kafka
                                    XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取

                                    XREAD BLOCK 100 STREAMS  mqstream 1599203861727-0 (毫秒+序号)








    2.场景 -- 共享数据所以分布式，高效；同时满足分布式下的可靠性、一致性、高可用..
            1.缓存
            2.数据库
            3.分布式锁


            坑：
                CPU 使用上的“坑”，例如数据结构的复杂度、跨 CPU 核的访问；
                内存使用上的“坑”，例如主从同步和 AOF 的内存竞争；
                存储持久化上的“坑”，例如在 SSD 上做快照的性能抖动；
                网络通信上的“坑”，例如多实例时的异常网络丢包

    3.场景问题：
            1.长尾延迟：平均延迟 
                == 如果有 100 万个请求，哪怕只有 1% 的请求是 100s，这也对应了 1 万个糟糕的用户体验。这 1% 的请求延迟就属于长尾延迟。

            2.redis慢操作
                    1.哈希表的冲突问题和 rehash 可能带来的操作阻塞
                        1.hash冲突链
                        2.java8 链表 转 红黑树  vs redis rehash
                                rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量

                                1.哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
                                2.把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
                                        1.copy阻塞 ==> 渐进式 rehash
                                        每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的entries。

                                        渐进rehash.png
                                3.释放哈希表 1 的空间。








    4.一个KV数据库到底是什么？
            1.假如你去实现，你又会如何？
                    1.分布式 ==> 单独的机器(使其作为共享中心)  快 ==> 内存  持久化 ==> 借鉴wal机制  集群等 ==> kafka/mysql等
                      kv ==> 构建一个大的concurrhashmap 

            2.simpleKV 数据模型和操作接口(<== 业务操作进行抽象)
                    1.一个关系型数据库可以转化为kv 比如<id,record>
                    2.它只提供简单的操作接口，无法支持复杂的聚合计算(比如count,max...)。但关系型可以
                    3.io模型
                            网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为 I/O 模型设计。不同的 I/O 模型对键值数据库的性能和可扩展性会有不同的影响。复制代码1PUT hello world
                      索引模型
                            见的有哈希表、B+ 树、字典树等。不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。
                            内存键值数据库（例如 Redis）采用哈希表作为索引
                            键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表O(1) 的操作复杂度相匹配

                            hash表要求都在内存处理

                            value 支持多种类型，当我们通过索引找到一个key 所对应的 value 后，仍然需要从 value 的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据 <== 根据数据特点进行对应的数据结构设计
                      存储模型
                            内存申请和释放 / 磁盘写入时机
                      分配器
                            值数据库的键值对通常大小不一，glibc 的分配器在处理随机的大小内存块分配时，表现并不好。内存碎片

            3.simpleKV到redis.png
                    redis多了：安全性 ，丰富的数据类型、数据压缩、过期机制、数据淘汰策略、主从复制、集群化、高可用等功能，另外还可以增加统计模块、通知模块、调试模块、元数据查询等辅助功能 序列化和反序列化

                    数据结构：缺乏广泛的数据结构支持，比如支持范围查询的 SkipList 和 Stream 等数据结构。
                    1.高可用：缺乏哨兵或者 master-slave 模式的高可用设计；
                    2.横向扩展：缺乏集群和分片功能；
                    3.内存安全性：缺乏内存过载时的 key 淘汰算法的支持；
                    4.内存利用率：没有充分对数据结构进行优化，提高内存利用率，例如使用压缩性的数据结构；
                    5.功能扩展：需要具备后续功能的拓展；
                    6.不具备事务性：无法保证多个操作的原子性

                    详见:simplekv和redis差距.png

            4.当把一个通用功能做成平台服务时，我们需要重点考虑的问题，包括平台平滑扩容、多租户支持和业务数据隔离、灵活的路由规则、丰富的监控功能等。

            5.redis实现小而精，没有使用复杂的多线程，而是精确使用cpu、内存、磁盘、网络、数据结构来解决内存占用和快速问题


=============实践篇====================



    5. 万金油”的String，为什么不好用   ,支持json对象吗?              
            1.string内部结构及缺点
                    1.string占用内存大
                    2.使用二级编码的方法，实现了用集合类型保存单值键值

            2.背景复现
                    1.1 亿张图片的信息，用了约 6.4GB 的内存.图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值，所以肯定可以表示 10 位数.
                      为社么6.4g/1亿 = 64byte?

                      String 类型还需要额外的内存空间记录数据长度、空间\一次访问的时间、被引用的次数 使用等信息，这些信息也叫作元数据 SDS.
                      全局哈希表保存所有键值对 dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry
                      jemalloc 实际会分配 8 字节空间

                      int、embstr 和 raw 这三种编码模式 


            3.压缩表
                    1.这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间

            4.从单值到集合转化
                    1.Hash 类型的 ' 二级编码方法  ' 

                    以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象ID 分别作为 Hash 类型值中的 key 和 value。
                    hset 1101000 060 3302000080  -- 看起来是hash底层可能是压缩列表或者hash

                    如何拆分key 
                            1.hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。
                              hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。
                              Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表
                            2.一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。

                            3.在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。


                            在内存空间的开销上，也许哈希表没有压缩列表高效但是哈希表的查询效率，要比压缩列表高。

                     Redis的设计和使用上，是一个典型的“系统”思维，也就是权衡（trade-off），根据自己的业务场景、数据量、访问特征，来进行选择。      



                    验证过程
                        1.info memory -- hset xx xx -- info memory 查看增加了多少 16

    ============        实践      ===========================
                      
    6.如何选择redis结构  TODO:12--14 / 36 redis支持秒杀 / 各种命令中的使用 运维 查看 api *****对应的场景及优化
            1.场景
                记录信息
                    1.手机 App 中的每天的用户登录信息：一天对应一系列用户 ID 或移动设备 ID；电商网站上商品的用户评论列表：一个商品对应了一系列的评论；用户在手机 App 上的签到打卡信息：一天对应一系列用户的签到记录；应用网站上的网页访问信息：一个网页对应一系列的访问点击。

                统计信息
                    在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；在电商网站的商品评论中，需要统计评论列表中的最新评论；在签到打卡中，需要统计一个月内连续打卡的用户数；在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。

                            1.常见统计模式
                                四种统计模式，包括聚合统计、排序统计、二值状态统计和基数统计。对于成千万、亿什么集合类型能够更快速地完成统计，而且还节省内存空间
                            2.实现
                                    1.SUNIONSTORE  user:id  user:id  user:id:20200803
                                      SDIFFSTORE  user:new  user:id:20200804 user:id
                                      SINTERSTORE user:id:rem user:id:20200803 user:id:20200804

                                      Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了

                                    2.List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set           可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。
                                            分页下，list问题 ： list 相同位置上的元素就会发生变化

                                        和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的
                                        假设越新的评论权重越大，目前最新评论的权重是 N
                                        ZRANGEBYSCORE comments N-9 N

                                    sorted set
                                    
                                    3.二值 签到
                                        Bitmap -- BITCOUNT 

                                        记录该用户 8 月 3 号已签到 SETBIT uid:sign:3000:202008 2 1 
                                        检查该用户 8 月 3 日是否签到 GETBIT uid:sign:3000:202008 2 
                                        统计该用户在 8 月份的签到次数  BITCOUNT uid:sign:3000:202008

                                        与操作
                                        每天使用 1 个 1 亿位的Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约为 120MB，内存压力不算太大。不过，在实际应用时，最好对 Bitmap 设置过期时间，让Redis 自动删除不再需要的签到记录，以节省内存开销。
                                    4.基数统计
                                        基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV
                                        set /hash都会消耗内存

                                        HyperLogLog     PFADD page1:uv user1 user2 user3 user4 user / PFCOUNT page1:uv
                                                    统计结果是有一定误差的，标准误算率是 0.81%

                                    5.时间序列数据的读写特点  --  更细粒度的划分场景特点和设计数据结构
                                        1.特点
                                                1.持续高并发写入
                                                2.插入新数据，而不是更新一个已存在的数据
                                                3.一个时间序列数据被记录后通常就不会变了，因为它就代表了一个设备在某个时刻的状态值
                                                4.复杂度要低，尽量不要阻塞
                                                5.时间序列数据的“读”，就是查询模式多
                                                        1.时间段 
                                                        2.聚合 最大...

                                        2.场景
                                                1.视频监控
                                        3.实现
                                                1.redis 提供了保存时间序列数据的两种方案，分别可以基于 Hash 和 Sorted Set 实现，以及基于RedisTimeSeries 模块实现。

                                                HGET device:temperature 202008030905 
                                                     key:device:temperature value：是hashmap 这个hash中key是202008030905

                                                sort set ZRANGEBYSCORE device:temperature 202008030907 20200803091

                                                hash对范围查询的效率低，需要遍历所有，所以结合sort set来完成范围

                                                ===> 写两份 
                                                如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？
                                                 事务 multi -- hset ... -- zdd --exec 

                                                如何对时间序列数据进行聚合计算
                                                        1.取回到客户端 ： 
                                                           大量数据在 Redis 实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢
                                                        2.服务端
                                                            RedisTimeSeries 支持直接在 Redis 实例上进行聚合计算

                                    6.秒杀  《36.redis支撑秒杀》
                                        1.三阶段
                                                1.秒杀活动前
                                                        把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。这样一来，秒杀前的大量请求可以直接由 CDN 或是浏览器缓存服务，不会到达服务器端了，这就减轻了服务器端的压力
                                                2.秒杀活动开始
                                                        库存查验、库存扣减和订单处理

                                                        1.订单处理可以在数据库中执行，但库存扣减操作，不能交给后端数据库处理
                                                                订单处理会涉及支付、商品出库、物流等多个关联操作，这些操作本身涉及数据库中的多张数据表，要保证处理的事务性，需要在数据库中完成。而且，订单处理时的请求压力已经不大了，数据库可以支撑这些订单处理请求。

                                                                1.额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。
                                                                2.下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。

                                                                接在 Redis 中进行库存扣减。具体的操作是，当库存查验完成后，一旦库存有余量，我们就立即在 Redis 中扣减库存。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性

                                                                        lua脚本
                                                                        分布式锁

                                                3.秒杀活动结束后




            2.选择
                    如果你只需要存储简单的键值对，或者是对数字进行递增递减操作，就可以使用 String存储；
                    如果需要一个简单的分布式队列服务，List 就可以满足你的需求；
                    如果除了需要存储键值数据，还想单独对某个字段进行操作，使用 Hash 就非常方便；如果想得到一个不重复的集合，就可以使用 Set，而且它还可以做并集、差集和交集运算；
                    如果想实现一个带权重的评论、排行榜列表，那么，Sorted Set 就能满足你。

                    数据量很小时，我们想要计算 App 里某一天的用户 UV 数，只需要使用一个 Set 存储这一天的访问用户，再使用 SCARD，就可以计算出结果
                    但是，假如一天的访问用户量达到了亿级，就不能这样存储了，因为这会消耗非常大的内存空间。而且，这么大的 key 在过期时会引发阻塞风险。

                    redis集合特点.png

            3.数据类型扩展
                    1.海量数据统计时，它们的内存开销很大，而且对于一些特殊的场景，它们是无法支持的。所以，Redis 还提供了 3种扩展数据类型，分别是 Bitmap、HyperLogLog 和 GEO
                    2.背景：
                        越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围
                    3.在设计一个数据类型的底层结构时，我们首先需要知道，要处理的数据有什么访问特点
                    4.但问题是，对于一个 LBS 应用来说，除了记录经纬度信息，还需要根据用户的经纬度信息在车辆的 Hash 集合中进行范围查询。一旦涉及到范围查询，就意味着集合中的元素需要有序，但 Hash 类型的元素是无序的，显然不能满足我们的要求。


                    1.Sorted Set 类型也支持一个 key 对应一个 value 的记录模式，其中，key 就是 SortedSet 中的元素，而 value 则是元素的权重分数。更重要的是，Sorted Set 可以根据元素的权重分数排序，支持范围查询。这就能满足 LBS 服务中查找相邻位置的需求了。
                    Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数
                    GeoHash 的编码方法
                            1.N次二分 逐渐逼近距离  == > 经纬度（116.37，39.86）的各自编码值是 11010 和 10111 <== 搜索中也用到

                    操作
                        GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；
                        GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。

                        GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10

                    我们需要一个数据类型既能像 Hash 那样支持快速的单键查询，又能像Sorted Set 那样支持范围查询


            3.微博在redis实践 红包飞活动，粉丝数、用户数、阅读数统计，信息流聚合，音乐榜单等 ---> 定制化开发



    6.1.命令
            1.info
                    1.redisInfo.png
            2.面向 Prometheus 的 Redis-exporter 监控
                    1.Prometheus + Grafana
                    2.开发一个 Lua 脚本,Redis-exporter 运行这个特定的脚本，从而可以满足业务层的多样化监控需求。
            3.小工具 
                    redis-stat和Redis Live
            4.Redis-shake 数据迁移
                    Redis-full-check 一致性比对工具
            5.Redis 集群运维管理的工具 CacheCloud

    
    6.2.redis使用规范
            1.键值对使用
                    1.key 的命名规范，只有命名规范，才能提供可读性强、可维护性好的 key，方便日常管理；
                    2.value 的设计规范，包括避免 bigkey、选择高效序列化方法和压缩方法、使用整数对象共享池、数据类型选择。

                    1.使用把业务名作为前缀，然后用冒号分隔，再加上具体的业务数据名，不用使用数据库切换
                            1.key 本身是字符串，底层的数据结构是 SDS。SDS 结构中会包含字符串长度、分配空间大小等元数据信息。从 Redis 3.2 版本开始，当 key 字符串的长度增加时，SDS 中的元数据也会占用更多内存空间。
                            2.缩写
                    2.避免使用 bigkey
                            1.在业务层，我们要尽量把 String 类型的数据大小控制在10KB 以下。减少key\value值占用    <==== 向量
                            2.键值对的值是集合类型，尽量把集合类型的元素个数控制在 1 万以下。

                            1.数据压缩
                            2.将大集合拆分成多个小集合保存
                                    1.在集合元素个数小于一定的阈值时，会使用内存紧凑型的底层数据结构进行保存，从而节省内存。例如，假设 Hash 集合的 hash-max-ziplist-entries 配置项是 1000，如果 Hash集合元素个数不超过 1000，就会使用 ziplist 保存数据。

                                    紧凑型数据结构虽然可以节省内存，但是会在一定程度上导致数据的读写性能下降。所以，如果业务应用更加需要保持高性能访问，而不是节省内存的话，在不会导致 bigkey 的前提下，你就不用刻意控制集合元素个数了。
                    3.使用高效序列化方法和压缩方法
                                    1.Redis 中的字符串都是使用二进制安全的字节数组来保存的，所以，我们可以把业务数据序列化成二进制数据写入到 Redis 中
                                    不同的序列化方法，在序列化速度和数据序列化后的占用内存空间这两个方面，效果是不一样的

                                    业务应用有时会使用字符串形式的 XML 和 JSON 格式保存数据

                                    XML 和 JSON 格式的数据占用的内存空间比较大。为了避免数据占用过大的内存空间，我建议使用压缩工具（例如 snappy 或 gzip），把数据压缩后再写入 Redis，这样就可以节省内存空间了。

                                    空间和压缩/解压缩之间如何取舍处理，内存和cpu
                    4.使用整数对象共享池
                            1.Redis 内部维护了 0 到 9999 这 1 万个整数对象，并把这些整数作为一个共享池使用。
                            2.不使用的情况：
                                    1.如果 Redis 中设置了 maxmemory，而且启用了 LRU 策略（allkeys-lru或 volatile-lru 策略），那么，整数对象共享池就无法使用了。这是因为，LRU 策略需要统计每个键值对的使用时间，如果不同的键值对都共享使用一个整数对象，LRU 策略就无法进行统计了。
                                    2.如果集合类型数据采用 ziplist 编码，而集合元素是整数，这个时候，也不能使用共享池。因为 ziplist 使用了紧凑型内存结构，判断整数对象的共享情况效率低
 
            2.业务数据保存
                    1.使用redis保存热数据
                    2.建议你把不同的业务数据放到不同的 Redis 实例中。这样一来，既可以避免单实例的内存使用量过大，也可以避免不同业务的操作相互干扰
                    3.在数据保存时，要设置过期时间
                    4.控制 Redis 实例的容量
                            1.Redis 单实例的内存大小都不要太大，根据我自己的经验值，建议你设置在 2~6GB 。这样一来，无论是 RDB 快照，还是主从集群进行数据同步，都能很快完成，不会阻塞正常请求的处理。  

            3.命令使用规范
                    1.线上禁用部分命令
                        1.KEYS，按照键值对的 key 内容进行匹配，返回符合匹配条件的键值对，该命令需要对Redis 的全局哈希表进行全表扫描，严重阻塞 Redis 主线程；
                        2.FLUSHALL，删除 Redis 实例上的所有数据，如果数据量很大，会严重阻塞 Redis 主线程；
                        3.FLUSHDB，删除当前数据库中的数据，如果数据量很大，同样会阻塞 Redis 主线程。

                        对于 KEYS 命令来说，你可以用 SCAN 命令代替 KEYS 命令，分批返回符合条件的键值对，避免造成主线程阻塞；
                        对于 FLUSHALL、FLUSHDB 命令来说，你可以加上 ASYNC 选项，让这两个命令使用后台线程异步删除数据，可以避免阻塞主线程。

                    2.慎用 MONITOR 命令
                    3.慎用全量操作命令
                        1.HGETALL
                        2.SMEMBERS

                    返回集合类型优化：
                        1.使用 SSCAN、HSCAN 命令分批返回集合中的数据，减少对主线程的阻塞。
                        2.可以化整为零，把一个大的 Hash 集合拆分成多个小的 Hash 集合。这个操作对应到业务层，就是对业务数据进行拆分，按照时间、地域、用户 ID 等属性把一个大集合的业务数据拆分成多个小集合数据。例如，当你统计用户的访问情况时，就可以按照天的粒度，把每天的数据作为一个 Hash 集合。
                        3.如果集合类型保存的是业务数据的多个属性，而每次查询时，也需要返回这些属性，那么，你可以使用 String 类型，将这些属性序列化后保存，每次直接返回 String 数据就行，不用再对集合类型做全量扫描了。








==========      工作原理、替换策略、异常处理和扩展机制     ==============

    7.redis执行过程
            1.关注点
                    1.工作原理、替换策略、异常处理和扩展机制
                    2.前提
                            1.cpu 20-40ns 1-32m
                              内存   100ns 32-96G
                              磁盘   3-5ms 1-4T

                            CPU 里面的末级缓存，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；
                            内存中的高速页缓存，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。
            2.缓存特征
                    1.缓存快于后端系统 / 缓存大小小于后端系统，代表数据换入换出--淘汰机制
            3.旁路缓存
                    平时在开发程序时，我们是没有专门在代码中显式地创建 LLC 或 page cache 的实例的，也没有显式调用过它们的 GET 接口。这是因为，我们在构建计算机硬件系统时，已经把 LLC 和 pagecache 放在了应用程序的数据访问路径上，应用程序访问数据时直接就能用上缓存。

                    而redis则需要将获取/更新逻辑由应用显式处理

                    独立的系统，我们可以单独对 Redis缓存进行扩容或性能优化。

            4.缓存类型
                    1.只读缓存
                            1.delete掉db中数据和redis中数据
                            2.get缓存中缺失
                            3.从db中读取并更新缓存

                            好处：
                            所有最新的数据都在数据库中，而数据库是提供数据可靠性保障的，这些数据不会有丢失的风险。当我们需要缓存图片、短视频这些用户只读的数据时，就可以使用只读缓存这个类型了

                    2.读写缓存
                            1.所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作，响应快速

                            有宕机风险

                    ==> 根据业务应用对数据可靠性和缓存性能的不同要求，我们会有同步直写和异步写回两种策略。
                                1.同步直写策略优先保证数据可靠性
                                        写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回
                                2.异步写回策略优先提供快速响应
                                        等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库

                    3.场景
                            1.在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。
                            2.短视频App 的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择
    
    8.替换策略       
                1.取舍-权衡-性价比 
                    1.1TB 内存的价格大约是 3.5 万元，而 1TB 磁盘的价格大约是 1000 元
                    2.“八二原理”，80% 的请求实际只访问了 20% 的数据 这 80% 的数据在访问量上就形成了一条长长的尾巴，我们也称为“长尾效应”。


                2.方案
                    1.设置多大缓存合适
                            1.结合应用数据实际访问特征和成本开销来综合考虑的，数据总量，业务场景
                            2.建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销
                    2.缓存是一定会放满的，所以一定要有清理策略  CONFIG SET maxmemory 4gb

                    3.淘汰策略：<-- 触发条件：键值对的过期时间是快到了 + Redis 的内存使用量达到了 maxmemory 阈值
                            1.不进行数据淘汰的策略    noeviction   
                            2.在设置了过期时间的数据中进行淘汰   
                                volatile-random:在设置了过期时间的键值对中，进行随机删除。
                                volatile-ttl:在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除
                                volatile-lru：会使用 LRU 算法筛选设置了过期时间的键值对 <-- Least Recently Used
                                volatile-lfu
                            3.在所有数据范围内进行淘汰
                                 allkeys-lru、allkeys-random、allkeys-lfu（Redis4.0 后新增）三种。

                    4.lru问题
                            1.要用链表管理所有的缓存数据，这会带来额外的空间开销。
                            2.当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能

                            简化：
                            1.Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构RedisObject 中的 lru 字段记录
                            2.Redis 在决定淘汰的数据时，第一次会随机选出N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把lru 字段值最小的数据从缓存中淘汰出去
                            3.能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。

                            _____同义转化
                            redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。

                            CONFIG SET maxmemory-samples 100 候选集个数

                    5.建议
                            1.优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。
                            如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random 策略，随机选择淘汰的数据就行。
                           
                            2.如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。

                            3.判断是否脏数据,判断是否修改过，如果没有就是新数据；修改过就是脏数据。最后要写回db

    9.异常处理
            1.缓存中的数据和数据库中的不一致
                    1.读写模式
                            直写模式
                                 1.写缓存和db要进行事务配置保证一致性 -- 重试
                            异步模式
                                电商商品的非关键属性或者短视频的创建或修改时间等，那么，我们可以使用异步写回策略
                    2.只读模式
                            新增数据
                                本身一致
                            删改数据 - 后一个操作失败 - 原子性如何保证？ 下面两个都有问题。同步而不是异步，异步问题更大，第一步操作都有
                                先缓存-后db ： 从数据库中读到旧值
                                先db-后缓存 ： 从缓存中读到旧值

                                解决：
                                    重试 ： 消息队列存取数据  对操作失败进行重试，超过重试次数，就抛到应用层


                                实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。

                                解决：
                                    延迟双删：先删除缓存，再更新数据库情况下
                                            redis.delKey(X)
                                            db.update(X)
                                            Thread.sleep(N)：让正在读取的线程将错误的值写入，使其稳定后在删除--还是存在小段时间问题
                                            redis.delKey(X)

                                    先更新数据库值，再删除缓存值 ：对业务影响较小。

                                缓存不一致问题.png

                    3.先更新数据库再删除缓存
                            1.先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；
                            2.果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置

                            如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。


---------问题向解决方案的转换----------------------不要总是追求完美------不可达------------
                            
            2.缓存雪崩
                    1.原因
                            1.缓存中有大量数据同时过期，导致大量请求无法得到处理
                            2.集群中redis实例宕

                    2.解决方案
                            1.避免给大量的数据设置相同的过期时间 / 如果业务层的确要求有些数据同时失效，你可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟）
                            2.降级
                                 1.当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；
                                 2.当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取
                            3.业务系统中实现服务熔断
                                发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问
                                缓存客户端并不把请求发给 Redis 缓存实例，直接返回
                            4.熔断导致服务不可用影响范围大，所以限流就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库
                    3.预防
                            1.监控
                            2.集群



            3.缓存击穿
                    1.针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增.和缓存雪崩相比，缓存击穿失效的数据数量要小很多

                    解决：
                        对于访问特别频繁的热点数据，我们就不设置过期时间了

            4.缓存穿透
                    1.访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据

                    2.原因
                            业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；
                            恶意攻击：专门访问数据库中没有的数据。

                    3.解决
                            1.缓存空值或缺省值。
                                一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）后续请求直接返回默认值
                            2.使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力
                                    首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。


                                    先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，我们查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存

                                    没有就一定没有。有不一定有

                                    *** 这里的多个hash函数是为了多个点论证不要因为一次就下结论吗 ***  

                            3.前端进行请求检测




            3.缓存污染
                        1.在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

                        2.可以避免的场景
                                1.明确知道数据被再次访问的情况下，volatile-ttl 可以有效避免缓存污染。
                                2.在其他情况下，volatile-random、allkeys-random、volatile-ttl 这三种策略并不能应对缓存污染问题。
                                3.LRU
                                        1.好处：热点数据 近点原理 通常作为临近查询，关联等操作
                                        2.坏处：因为只看数据的访问时间，使用 LRU 策略在处理  ‘ 扫描式单次查询操作 ’ 时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次

                                                <-== 类似于 db中搜索大量数据，都存在page中造成了无效占用

                                4.LFU
                                        1.LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

                                        1.Ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
                                        2.counter 值：lru 字段的后 8bit，表示数据的访问次数.最大255.==优化 +1操作 
                                            首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1  -=== 非线性递增的计数器方法  
                                        3.LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减
                                            LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。简单举个例子，假设 lfu_decay_time 取值为 1，如果数据在 N 分钟内没有被访问，那么它的访问次数就要减 N。如果 lfu_decay_time 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把lfu_decay_time 值设置为 1，这样一来，LFU 策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。


    10.Pika
            1.对比
                1.分片-集群：协调复杂度
                2.大内存:大容量实例在实例恢复、主从同步过程中会引起一系列潜在问题，例如恢复时间增长、主从切换开销大、缓冲区易溢出

    11.锁 <===这种公共服务如何处理 ‘ 并发操作 ’？ 
            1.解决方案
                        1.加锁
                                1.降低性能
                                2.Redis 客户端要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作
                        2.原子操作
                                1.读取 - 修改 - 写回”操作（Read-Modify-Write) 访问同一份数据的 RMW 操作代码，就叫做临界区代码。

                                1.把多个操作在 Redis 中实现成一个操作，也就是单命令操作； INCR/DECR. 
                                        <== 类似于cpu提供的原子操作
                                2.把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本
                                        <== 如果我们要执行的操作不是简单地增减数据，而是有更加复杂的判断逻辑或者是其他操作，那么，Redis 的单命令操作已经无法保证多个操作的互斥执行了,使用lua脚本

                                        限流
                                                        //获取ip对应的访问次数current = GET(ip)//如果超过访问次数超过20次，则报错IF current != NULL AND current > 20 THEN    ERROR "exceed 20 accesses per second"ELSE//如果访问次数不足20次，增加一次访问计数    value = INCR(ip)//如果是第一次访问，将键值对的过期时间设置为60s后    IF value == 1 THEN
                                                        XPIRE(ip,60)    END/

                                                   如果客户端使用多线程访问，访问次数初始值为 0，第一个线程执行了 INCR(ip) 操作后，第二个线程紧接着也执行了INCR(ip)，此时，ip 对应的访问次数就被增加到了 2，我们就无法再对这个 ip 设置过期时间了。这样就会导致，这个 ip 对应的客户端访问次数达到 20 次之后，就无法再进行访问了。即使过了 60s，也不能再继续访问，显然不符合业务要求。

                                            编写 Lua脚本时，你要避免把不需要做并发控制的操作写入脚本中。


            2.原理：
                    Redis 是使用 ‘ 单线程 ’ - 区分开这个的多路复用(为了前置操作，核心的操作就是单线程，专心完成这个事情)来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制



            3.分布式锁 
                    1.上面的lua脚本实现限流控制了 ‘ 单客户端 ’锁(客户端本地锁)，对于多客户端加锁，需要分布式锁支持
                      锁是保存在一个共享存储系统中的，可以被多个客户端共享访问和获取。redis正是因为这个，并且读写性能高，所以作为分布式锁

                    2.和单机锁的异同
                            1.同：加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功；释放锁时需要把锁变量值设置为                       0，表明客户端不再持有锁。
                            2.异：单机上操作锁不同的是，在分布式场景下，锁变量需要由一个共享存储系统来维护，只有这样，多个客户端才可以通过访问共享存储系统来访问锁变量。相应的，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。

                    3.要求：
                            1.分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；
                            2.共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。

                    4.实现：
                            1.因为 Redis 使用单线程处理请求，所以，即使客户端 A 和 C 同时把加锁请求发给了 Redis，Redis 也会串行处理它们的请求。
                            2.原子性：redis原子命令和lua脚本保证     
                                    分布式下应用上面的原子性：SETNX(不存在即设置) key value  doSomething DEL key
                                    EX 或 PX 选项，用来设置键值对的过期时间 
                                    SETkeyvalue [EX seconds | PX milliseconds]  [NX] 客户端标识

                                    //释放锁比较unique_value是否相等，避免误释放
                                    if redis.call("get",KEYS[1]) == ARGV[1] thenreturn redis.call("del",KEYS[1])else return 0end



                                    问题：避免死锁
                                                    1.给锁变量设置一个过期时间
                                          避免乱释放锁
                                                    1.客户端操作添加标识

                    5.集群下分布式锁
                            1.Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。

                            1.客户端获取当前时间
                            2.客户端按顺序依次向 N 个 Redis 实例执行加锁操作
                            3.一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。
                                客户端只有在满足下面的这两个条件时，才能认为是加锁成功
                                条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；
                                条件二：客户端获取锁的总耗时没有超过锁的有效时间
                                <=== 将集群整体看作一个例子来完成，所以要算总耗时

                                在满足了这两个条件后
                                        1.重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况
                                        2. 如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有 Redis 节点发起释放锁的操作。     


    12.事务
            1.上面讲了redis实现原子性，那可以实现ACID吗?        
               如果有些属性在一些场景下不能保证的话，很可能会导致数据出错，所以，我们必须要掌握 Redis 对这些 ‘ 属性的支持情况，并且提前准备应对策略 ’ 。

            2.实现
                    1.客户端要使用一个命令显式地表示一个事务的开启  MULTI
                    2.客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端   GET、SET  暂存到一个命令队列中，并不会立即执行
                    3.EXEC 命令就是执行事务提交 执行所有命令

                原子性
                    1.检测到问题命令则整个事务失败
                    2.未检测到，执行时发现，则事务的原子性就无法得到保证。正确命令仍会执行。部分先后 
                            DISCARD 命令 -- 把暂存的命令队列清空，起不到回滚
                    3.在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败
                            redis-check-aof 工具检查 AOF 日志文件，这个工具可以把已完成的事务操作从 AOF 文件中去除。这样一来，我们使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性

                一致性
                    1.命令入队时就报错 以保证数据库的一致性
                    2.命令入队时没报错，实际执行时报错  有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。
                    3.EXEC 命令执行时实例发生故障 
                            因为 RDB 快照不会在事务执行时执行 事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的。

                隔离性
                    1.并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证；
                            WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏
                    2.并发操作在 EXEC 命令后执行，此时，隔离性可以保证。

                持久性
                    1.不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的




    13.数据分布 - 数据倾斜
            1.数据都会先按照 CRC 算法的计算值对 Slot（逻辑槽）取模，同时，所有的 Slot 又会由运维管理员分配到不同的实例上
            2.种类
                    1.数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多
                            1.bigkey
                                    1.bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。
                                    2.bigkey 的操作一般都会造成实例 IO 线程阻塞，如果 bigkey 的访问量比较大，就会影响到这个实例上的其它请求被处理的速度。

                                    我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。

                                    如果 bigkey 正好是集合类型，我们还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。

                            2.slot分配不均衡
                                    1.如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜。
                                        Redis Cluster 一共有 16384 个 Slot，假设集群一共有 5 个实例

                                    2.查看  如果是 Redis Cluster，就用 CLUSTERSLOTS 命令；如果是 Codis，就可以在 codis dashboard 上查看。

                                    3.迁移
                                            1.CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例。
                                            2.CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key。
                                            3.MIGRATE：把一个 key 从源实例实际迁移到目标实例。
                            3.hashTag
                                    1.Hash Tag 是指加在键值对 key 中的一对花括号{} 这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值
                                    
                                    ====> 标识化 <===== 
                                    2.如果不同 key 的 Hash Tag 内容都是一样的，那么，这些 key对应的数据会被映射到同一个 Slot 中，同时会被分配到同一个实例上
                                    3.场景：Redis Cluster 和 Codis 本身并不支持跨实例的事务操作和范围查询，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果。
                                    Hash Tag 把要执行事务操作或是范围查询的数据映射到同一个实例上，这样就能很轻松地实现事务或范围查询了

                                    数据倾斜 -- 范围查询、事务执行的需求和数据倾斜带来的访问压力之间，进行取舍了

                                    建议是，如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用 Hash Tag 进行数据切片。因为事务和范围查询都还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用



                    2.数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。
                            1.采用热点数据多副本
                                    1.热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的 key 又不一样，会被映射到不同的 Slot中。在给这些 Slot 分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了

                                    2.1只是适合只读热点，如果是读写，多副本就会造成数据一致性开销问题

    14.Redis 6.0的新特性：多线程、客户端缓存与安全
                1.单个主线程处理网络请求的速度跟不上底层网络硬件的速度
                        1.用用户态网络协议栈（例如 DPDK）取代内核网络协议栈，让网络请求的处理不用在内核里执行，直接在用户态完成处理就行
                        2.采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度

                             1.Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。这是因为，Redis 处理请求时，网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。这样一来，Redis 线程模型实现就简单了

                             redis多线程.png

                             2.配置
                                1.设置 io-thread-do-reads 配置项为 yes，表示启用多线程  io-threads-do-reads yes
                                2.线程个数要小于 Redis 实例所在机器的 CPU 核个数 io-threads  6

                            实际应用中，发现 Redis 实例的 CPU 开销不大，吞吐量却没有提升，可以考虑使用 Redis 6.0 的多线程机制，加速网络处理，进而提升实例的吞吐量
                2.客户端缓存
                        1.traking模式
                        2.广播模式

                3.从简单的基于密码访问到细粒度的权限控制

                redis新功能.png

    15.NVM内存实践


        codis vs redis cluster 《35...》
                1.认识成套的解决方案 
        《加餐二 kaito如何学习redis的》：讲述面临问题及一步步解决方案,从问题出现-定位-解决-方案优化等链路上系统介绍 ***



TODO:
    1.HiKV    
    2.redis的多线程和单线程指的是什么？如何实现高效
    3.Redis中sorted set 底层实现是一个dict + 一个zskiplist， Redis底层为什么要如此设计。zadd key score value 这样的形式，那如果底层采用了跳表的数据结构zset到底是如何存储数据的呢？dict中存储的是什么，跳表中存储的又是什么呢？
        我们一般用sorted set时，会经常根据集合元素的分数进行范围查询，例如ZRANGEBYSCORE或者ZREVRANGEBYSCORE，这些操作基于跳表就可以实现O(logN)的复杂度。此时，跳表的每个节点同时保存了元素值和它的score。感兴趣可以进一步看下，redis源码的server.h中的zskiplistNode结构体。然后，就是你说的为什么还设计dict。不知道你有没有注意到，sorted set 还有ZSCORE这样的操作，而且它的操作复杂度为O(1)。如果只有跳表，这个是做不到O(1)的，之所以可以做到O(1)，就是因为还用了dict，里面存储的key是sorted set的member，value就是这个member的score。

    4.redis指令执行流程
    5.Huge page
    6.二级编码处理 向量的保存  .....减少内存占用 
    7.redis中操作LPUSH mq "101030001:stock:5" 这个是插入list?
    8.异步操作 包装到一个list<task> 遍历


