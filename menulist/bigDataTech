大数据量处理 -- 工业级解决方案包括图搜代码中的技术融合、取舍和业务场景的融合
    问题：当数据量大了之后如何存储，搜索
            1.数据中台之结构化大数据存储设计  ： https://www.infoq.cn/article/7cboxvbb6b5v0bjh6rfx
            2.大数据十年回顾：浪潮之巅数英雄  ： https://www.infoq.cn/article/o2wfzkiwfu*lnp3ijxgz
                1.技术迭代不断满足，出现，出现问题，解决。所以杜绝完美主义，最合理取舍
            3.未来方向：复杂业务 / 大数据选择搭配、性能处理 - 协调成本 / 人工智能

    0.和自己当前项目的大数据对比
        1.当前是基于自研db处理,而默认的大数据处理使用的hdfs文件系统那一套
        2.没有使用注册中心等而是借助k8s+rds ；并不支持动态配置
        3.没有灰度发布
        4.没有自动降级等springcloud等组件
        5.没有使用es


    1.mapReduce
        1.分治思想是所有计算机处理的核心
        2.缺点:
                1.多个map/reduce每步都有可能失败
                2.设计协调系统，状态机协调多个mapreduce，复杂性增加
                3.时间性能差，细微的配置
                        缓冲大小 (buffer size），
                        分片多少（number of shards）避免数据倾斜
                            -- 根据业务合理的分片机制  --动态分片技术 (dynamic sharding） <=== 所谓的动态其实就是将遇到的问题场景编码化，进行判断和自动调整
                            1.哈希算法(Consistent hashing)，后来发现增删节点泰麻烦，改为带虚拟节点的一致性哈希环开处理，稍微复杂点，但是性能还好
                            2.业务反转  比如20-30岁之间的人，则28-82来存储。 这样使分布均衡。但存在热点问题
                            3.不同权重计算值再取模分片
                            4.加随机数
                        预抓取策略（prefetch）
                        缓存大小（cache size）
        3.复杂度
             场景:预测美团的股价，其中一个重要特征是活跃在街头的美团外卖电动车数量，而你负责处理所有美团外卖电动车的图片
                    1.数据搜集（Data collection）部分，你至少需要 4 个 MapReduce 任务
                        1. 数据导入（data ingestion）：用来把散落的照片（比如众包公司上传到网盘的照片）下载到你的存储系统。
                        2. 数据统一化（data normalization）：用来把不同外包公司提供过来的各式各样的照片进行格式统一。
                        3. 数据压缩（compression）：你需要在质量可接受的范围内保持最小的存储资源消耗 。
                        4. 数据备份（backup）：大规模的数据处理系统我们都需要一定的数据冗余来降低风险。
                    2.数据质量控制(quality control)
                        1. 数据时间有效性验证 （date validation）：检测上传的图片是否是你想要的日期的。
                        2. 照片对焦检测（focus detection）：你需要筛选掉那些因对焦不准而无法使用的照片。
                    3.找到这些图片里的外卖电动车
                        1. 数据标注问题上传（question uploading）：上传你的标注工具，让你的标注者开始工作。
                        2. 标注结果下载（answer downloading）：抓取标注完的数据。
                        3. 标注异议整合（adjudication）：标注异议经常发生，比如一个标注者认为是美团外卖电动车，另一个标注者认为是京东快递电动车。
                        4. 标注结果结构化（structuralization）: 要让标注结果可用，你需要把可能非结构化的标注结果转化成你的存储系统接受的结构。
            场景：同步多个库信息到同一个库
                        1.弱一致性  mq 事务
                        2.强一致性  设置中间的状态机，当查询时查看状态机是否满足主从一致，来判断更新进度，来确定查询方案

    2.下一代大数据处理技术
            1.有向无环图（DAG）来抽象。因为有向图能为多个步骤的数据处理依赖关系，建立很好的模型
                        1.什么是DAG:https://zhidao.baidu.com/question/2143118371199193348.html
                                    https://baijiahao.baidu.com/s?id=1602410984624790167&wfr=spider&for=pc
                        2.番茄炒蛋流程

                        每一个节点都可以被抽象地表达成一种通用的数据集，每一条边都被表达成一种通用的数据变换
            2.自动化  -  而不是按部就班地就把每一个步骤就直接扔给机器去执行了
                        1.优化流程
                                1.番茄炒蛋 番茄炒牛腩 中都有对番茄处理过程，将这两个过程merge
                        2.计算资源自动弹性分配
                                1.容器自动扩容 
                                2.实例

            3.我们要能把数据处理的描述语言，与背后的运行引擎解耦合开来
                        1.有向图进行数据处理描述的话，实际上数据处理描述语言部分完全可以和后面的运算引擎分离了。有向图可以作为数据处理描述语言和运算引擎的前后端分离协议。
                        2.db中的引擎和server层处理逻辑
                        3.有向图表达需要数据处理描述语言和运算引擎协商一致，其他的实现都是灵活可拓展的。

            4.统一批处理和流处理的编程模型
                        1.批流对比
                            批处理处理的是有界离散的数据，比如处理一个文本文件；
                            流处理处理的是无界连续的数据，比如每时每刻的支付宝交易数据。

                        2.MapReduce 的一个局限是它为了批处理而设计的 是因为有 ‘ 写文件那一步操作使其变成了有界操作 ’？那实时不也的落地写库吗？实时计算？flink对每条消息实时处理？
                        3.真正的业务系统，批处理和流处理是常常混合共生，或者频繁变换的
                        4.
            5.架构层面提供异常处理和数据监控的能力
                        1.异常处理
                            1.边界处理
                            2.业务逻辑异常处理
                            3.物理逻辑异常处理
                            4.分布式下协同



    3.如何设计热销榜
            1.编程问题 coding 能力很强 -- 算法数据结构 -- 规模增长处理的技术思维   
            2.场景：
                    1.商品id 和购买时间{product_id, timestamp}，整个交易记录是 1000 亿行数据，TB 级  根据销售记录统计去年销量前 10 的商品
                            解决：
                                    1.小规模的经典算法
                                            1.统计每个商品的销量。你可以用哈希表（hashtable）数据结构来解决，是一个O(n) 的算法，这里 n 是 1000 亿。     
                                            2.找出销量前十，可以用经典的 Top K 算法，也是 O(n) 的算法。

                                            问题：
                                            1.内存占用  
                                                    找到单台计算机容纳那么大的哈希表了。你可能想到，那我不要用哈希表去统计商品销售量了，我把销量计数放在磁盘里完成好了。比如，就用一个 1000 亿行的文件或者表，然后再把销量统计结果一行一行读进后面的堆树/ 优先级队列
                                            2.磁盘 I/O 等延时问题
                                                    难以避免地需要把一些中间结果存进磁盘，以应对单步任务出错等问题。一次磁盘读取大概需要 10ms 的时间
                                                    O(n * log k) 的算法，就需要 10ms* 10^9 = 10 ^ 7 s = 115 天的时间
                                    2.分布式算法
                                            1.使用集群计算把上面的数据拆分
                                            2.topk merge

                                            问题：
                                            1.数据便宜，可能这个节点的topk都没有另一个节点的top2k质量高，如何处理?
                                                    计算的优化是一方面，有时候从数据层面去优化也会有更好的效果，以榜单为例，可以在时间维度和地域为度去拆解数据，先小聚再大聚
                                            2.分布式下多集群节点协调的复杂性

                                    3.大数据框架思维
                                            1.count -- topk 
                                            2.底层的处理屏蔽掉，而向 ‘ zookeeper 屏蔽了协调、通信等复杂 , netty 屏蔽了nio实现高性能通信 ’

        3.拆分，复制，异步，并行，是大规模数据处理和应用架构的常见手段，一致性根据业务场景适当妥协


    4.系统指标
        1.业务指标
        2.系统性能
                1.服务等级协议SLA(Service-Level Agreement)
                        1.可用性
                                系统服务能正常运行所占的时间百分比
                                四个9：99.99% 每年50min中断 认为是高可用
                        2.准确性
                                是否允许某些数据是不准确的或者是丢失了
                                错误率（Error Rate)=系统产生内部错误的有效请求数/期间有效请求数
                        3.系统容量
                                系统能够支持的预期负载量是多少，一般会以每秒的请求数为单位来表示
                                Twitter 系统可以响应 30 万的 QPS

                                        1.限流
                                            1.Google Guava 库中的 RateLimiter；根据日志反馈逐步调整
                                        2.性能测试
                                        3.日志

                                        雷区：
                                            1.缓存命中:有的开发者可能使用同一类型的请求参数，况下命中缓存（CacheHit）;浏览器缓存
                                                       内存、page cache 、..

                                            2.
                        4.延迟
                                统在收到用户的请求到响应这个请求之间的时间间隔
                                         p95 延迟是 1 秒的话，那就表示在 100 个请求里面有 95 个请求的响应时间会少于 1 秒，而剩下的 5 个请求响应时间会大于 1 秒
        3.工期指标


    5.分布式概念
            1.可扩展
                    1.横向 纵向
            2.一致性
                    1.分布式系统理论中还有很多别的一致性模型，如顺序一致性（SequentialConsistency），因果一致性（Casual Consistency）
                    2.在实际应用系统中，强一致性是很难实现的，应用最广的是最终一致性   
                        1.转账
                        2.12306买票等都是最终一致性

                    强一致性和弱一致性比对
                        区别于强一致性而定义的。广义上讲，任何不是强一致的，而又有某种同步性(最终一致性是通过mq这种异步操作来完成的)的分布式系统，我们都可以说它是弱一致的。而最终一致性是弱一致性的一个特例，而且是最常被各种分布式系统用到的一个特例。其他的比如因果一致性、FIFO一致性等都可以看作是弱一致性的特例，不同弱一致性只是对数据不同步的容忍程度不同，但是经过一段时间，所有节点的数据都要求要一致。

                    ****区分开，这里虽然不是强一致性，但同样需要保证数据不丢失****
                    金融股票大厅上的数据应该不会是强一致性的，延时误差也应该没有你想象的那么少



            3.持久性


            结合第四讲的概念。一共6-7个指标


    6.模式与架构
            1.复制模式（Copier Pattern)
                复制模式通常是将单个数据处理模块中的数据，完整地复制到两个或更多的数据处理模块中，然后再由不同的数据处理模块进行处理
                场景:
                        需要对同一个数据集采取多种不同的数据处理转换，比如不同码率、语言、视频分析..
                        在平台的背后，一个视频的数据集可能被自然语言理解（NLP）的数据处理模块分析---翻译系统，用以自动生成视频字幕；还有可能被视频分析的数据处理模块分析，用以产生更好的内容推荐系统。
            2.过滤模式（Filter Pattern）
                场景：
                        钻石会员单独邮件
            3.分离模式（Splitter Pattern）
                原来的数据集分组
            4.合并模式（Joiner Pattern）

            应用:一个机票订购系统如何设计
                1. 注册：合并模式（因为注册渠道可能会有手机号注册、邮箱注册、微信注册等等不同的渠道，所以需要合并）
                2. 购买机票：过滤+合并（首先过滤出用户查找的航班机票信息、之后查找出符合条件的机票由于可能来自不同的渠道，所有需要合并后返回给用户）
                3. 提醒：复制+过滤+分离..

                复制 → subquery
                过滤 → where
                分离 → group by
                合并 → join

            1.pub/sub
                1.在内存中通过dequeue完成，来实现请求的批量 
                    ===> mq(工业级 完成隔离和上面说到的扩展、持久--将服务模型抽离成中间件)
                2.kafka的(弱事务)和rocketmq事务(二阶段);但这些都保证了不丢失消息也就是持久性。必定的
                3.特点
                    1.解耦  比如链条调度中，a系统执行完，发送信号给q,其他订阅系统完成调度 ==> 单一职责==独立开发 互不知道
                            1.支付系统notify调用api诈骗系统 ,又要notify推广系统...
                            2.其他系统通过db直接操作支付系统的数据  安全性和性能
                    2.异步  
                            1.发送方在向接收方发送消息之后无需接收方进行实时响应
                    3.削峰填谷  缓冲buffer
                    4.高伸缩
                    4.暂存
                            1.数据一致性的要求只需要支持数据的最终一致性（Eventual Consistency）模型。

                    重试 == 如果你要保证操作一定成功，就要考虑用RPC来调用了。

            1.CAP理论
                1.一致性：C
                    A机器显示有货、B机器显示无货。则说明此时是不一致的。因为此时应该是无货的。所以分布式下如何实现强一致性、最终一致性
                2.可用性：A
                    在分布式系统中，任意非故障的服务器都必须对客户的请求产生响应。只要系统背后的服务器有一台还未崩溃，那么这个未崩溃的服务器必须最终响应客户端
                3.分区容错性：P
                    分布式下出现一些故障，可能会使得部分节点之间无法连通。障节点无法联通，造成整个网络就会被分成几块区域
                    即使出现这样的“错误”，系统也需要能“容忍”。也就是说，就算错误出现，系统也必须能够返回消息.将不同数据放置在不同
                    分区上。。kafka并不是，他是放在一起

                    大部分情况下，系统设计都会保留 P 属性，而在 C 和 A 中二选一。

                    但是分区机制不就是保证了容错么
                    解答：如果一个cluster里面领导者挂掉了，单单就这个cluster来说有再多的副本存在也是无法运行了，所以就Kafka Replication来说，它没有保留P属性。

                场景:
                    CP 系统：Google BigTable, Hbase, MongoDB, Redis, MemCacheDB，这些存储架构都是放弃了高可用性（High Availablity）而选择 CP 属性的。
                    AP 系统：Amazon Dynamo 系统以及它的衍生存储系统 Apache Cassandra 和Voldemort 都是属于 AP 系统CA 系统：Apache Kafka 是一个比较典型的 CA 系统。

                    Kafka 系统引入了 Replication 的概念。

                      通过将数据复制到不同的节点上，从而增强了数据在系统中的持久性（Durability）和可用性（Availability）。
                      在 Kafka Replication 的系统设计中，所有的数据日志存储是设计在同一个数据中心（Data Center）里面的，也就是说，对于kafka中失效的节点提出集群，所以也就没有了分区问题

                      在同一个数据中心里网络分区出现的可能性是十分之小的。

            在我看来，作为大规模数据处理的架构师，我们应该熟知自己的系统到底应该保留 CAP 中的哪两项属性，同时也需要熟知，自己所应用到的平台架构是保留着哪两项属性。



            1.lamdba架构
                1.背景：
                    大数量下实时推荐，不能使用批处理而使用实时处理。广告精准投放
                    投放错 临时性数据 用户 A 的电脑暂时借给用户 B 使用了一下，而用户 B 浏览了一些新的网站类型（与用户 A 不同）。这种情况下，我们无法判断用户 A 实际上是否对这类型的广告感兴趣，所以不能根据这些新的浏览记录给用户 A 推送广告
                2.Lambda 架构总共由三层系统组成：
                        批处理层（Batch Layer）
                                批处理层使用可处理大量数据的分布式处理系统预先计算结果。它通过处理所有的已有历史数据来实现数据的准确性。这意味着它是基于完整的数据集来重新计算的，能够修复任何错误，然后更新现有的数据视图。输出通常存储在只读数据库中，更新则完全取代现有的预先计算好的视图。
                        速度处理层（SpeedLayer）
                                速度层通过提供最新数据的实时视图来最小化延迟。速度层所生成的数据视图可能不如批处理层最终生成的视图那样准确或完整，但它们几乎在收到数据后立即可用。而当同样的数据在批处理层处理完成后，在速度层的数据就可以被替代掉了。

                                本质上，速度层弥补了批处理层所导致的数据视图滞后。
                        响应查询的服务层（Serving Layer）。
                                所有在批处理层和速度层处理完的结果都输出存储在服务层中，服务层通过返回预先计算的数据视图或从速度层处理构建好数据视图来响应查询。

                    而当“应该对用户投放什么样的广告”作为一个查询（Query）来到时，我们从服务层既查询服务层中保存好的批处理输出模型，也对速度层中处理的实时行为进行查询，这样我们就可以得到一个完整的用户行为历史了


                3.场景
                        如何高效准确的推荐用户去A\B\C三个停车场，入口离A最近。如果都去A将会导致没车停，再找，麻烦。所以如何准确推荐

                        解决：
                            利用这些停车场的历史数据，建立一个人工智能的预测模型，在推荐停车位的时候，不单单考虑到附近停车场的剩余停车位和用户与停车场的相邻距离，还能将 ‘  预测模型  ’ 应用在推荐里，看看未来的一段时间内这个停车场是否有可能会被停满了。 停车位推荐系统就变成了一个基于分数（Score）来推荐停车位的系统

                            批量层：
                                没错，这些停车场的历史数据或者每隔半小时拿到的停车位数据，我们可以把它作为批处理层的数据
                                很好的容错性，同时也因为保存着所有的历史记录，使产生的数据集具有很好的准确性

                            速度层：
                                那速度层的数据呢？我们可以将所有用户的 GPS 数据聚集起来，这些需要每秒收集的 GPS数据刚好又是速度层所擅长的实时流处理数据。从这些用户的实时 GPS 数据中，我们可以再建立一套预测模型来预测附近停车场位置的拥挤程度。服务层将从批处理层和速度层得到的分数结合后将得到最高分数的停车场推荐给用户。这样利用了历史数据（停车场数据）和实时数据（用户 GPS 数据）能大大提升推荐的准确率。

                            服务层将从批处理层和速度层得到的分数结合后将得到最高分数的停车场推荐给用户


                        实时数仓：满足Lambda 架构
                            1.批处理部分。定时拉取业务库的数据，并在hive做批处理计算。
                            2.速度部分。通过订阅mysql数据库的binlog，实时获取数据库的增删改等的操作，通过kafka和flink，生成相关结果。




                        缺点：
                            导致相似的处理逻辑在batch层和speed层都要开发一遍
                            kafka+storm+MR+Hbase来实现

            1.Kappa
                    基于上面的缺点，演进了以kafka为中心的kappa架构

                    改进批处理层的系统让它具有更低的延时性，又或者是改进速度层的系统，让它产生的数据视图更具准确性和更加接近历史数据呢？
                    解决：
                            像 Apache Kafka 这样的流处理平台是具有永久保存数据日志的功能的。通过平台的这一特性，我们可以重新处理部署于速度层架构中的历史数据  Log Offset 为 0 就可以重新读取所有内容

                    问题:
                        1.速度层上处理大规模数据可能会有数据更新出错的情况发生，这就需要我们花费更多的时间在处理这些错误异常上面
                        2.一套代码来处理算法逻辑的。所以 Kappa 架构并不适用于批处理和流处理代码逻辑不一致的场景。



    7.spark
            1.mapreduce缺陷
                1.MapReduce 模型的抽象层次低，大量的底层逻辑都需要开发者手工完成
                2.只提供 Map 和 Reduce 两个操作,比如join没有提供
                3.在 Hadoop 中，每一个 Job 的计算结果都会存储在 HDFS 文件存储系统中，所以每一步计算都要进行硬盘的读取和写入，大大增加了系统的延迟。
                4.只支持批数据处理，欠缺对流数据处理的支持
            2.特点
                1.丰富api RDD 是 Spark 最基本的数据结构(Resilient Distributed Dataset,RDD)
                    Map、Filter、flatMap、groupByKey 和 Union 等等，极大地提升了对各种复杂场景的支持
                2.内存暂存，加速
                3.资源更少 Spark 的并行机制是多线程模型，而 MapReduce 是多进程模型
                4.通用的数据处理平台，Spark 有五个主要的扩展库，分别是支持结构化数据的Spark SQL、处理实时数据的 Spark Streaming、用于机器学习的 MLlib、用于图计算的GraphX、用于统计分析的 Spark

                缺点：
                1.spark依然会存在数据倾斜的情况，在shuffle时有可能导致一个成为数据热点的情况

            3. hadoop很多组件  spark只是mapreduce替代
                 数据存储层：分布式文件存储系统 HDFS，分布式数据库存储的 HBase；
                 数据处理层：进行数据处理的 MapReduce，负责集群和资源管理的 YARN；
                 数据访问层：Hive、Pig、Mahout.....

            4.细节
                    1.RDD:已被分区、不可变的，并能够被并行操作的数据集合。
                            1.分区代表同一个 RDD 包含的数据被存储在系统的不同节点中，这也是它可以被并行处理的前提
                            2.抽象概念 底层是不同节点的不同数据块
                            3.不可变性：只读。有助于提升 Spark 的计算效率，并且使错误恢复更加容易。对于代表中间结果的 RDD，我们需要记录它是通过哪个 RDD 进行哪些转换操作得来，即依赖关系(弹性恢复)，而不用立刻去具体存储计算出的数据本身。

                            Spark 不需要将每个中间计算结果进行数据复制以防数据丢失，因为每一步产生的 RDD 里都会存储它的依赖关系，即它是通过哪个 RDD 经过哪个转换操作得到的。

                            类似于操作日志

                            4.并行操作
                    2.RDD包含：SparkContext /Partitions /Partitioner /checkpoint/storage level/...
                    3.依赖
                    4.checkpoint:
                        如果一个 RDD 的依赖链比较长，而且中间又有多个 RDD  出现故障的话，进行恢复可能会非常耗费时间和计算资源。checkpoint就是优化这些情况下的数据恢复。在连续的 transaction 列表中记录某几个 transaction 后数据的内容，从而加快错误恢复。

                    在计算过程中，对于一些计算过程比较耗时的 RDD，我们可以将它 ‘ 缓存至硬盘或 HDFS中 ’ == 取舍思想，标记这个 RDD 有被检查点处理过，并且清空它的所有依赖关系。

                    5.迭代函数（Iterator）
                        迭代函数会首先判断缓存中是否有想要计算的 RDD，如果有就直接读取，如果没有，就查找想要计算的 RDD 是否被检查点处理过。如果有，就直接读取，如果没有，就调用计算函数向上递归，查找父 RDD 进行计算

                    6.丰富的api，简化了应用开发：map  filter mapPartitions groupByKey Collect Reduce count countByKey
                            <==== stream操作  <=== db操作(大数据集操作)

                    7.spark sql（hive）- 是 Hive的 10 倍到 100 倍之多
                            底层就是操作RDD

                    8.spark stream
                            Spark Streaming 的原理与微积分的思想很类似
                            Spark 是一个高度统一的平台，所有的高级 API 都有相同的性质，它们之间可以很容易地相互转化。Spark 的野心就是用这一套工具统一所有数据处理的场景。

                            高低api转换、以及核心抽象、以及引擎

                    9.时间窗口  <==== 网络tcp滑动窗口
                            1.StreamingContext 中最重要的参数是批处理的时间间隔，即把流数据细分成数据块的粒度
                            2.时间间隔决定了流处理的延迟性，所以，需要我们根据需求和资源来权衡间隔的长度
                            3.每隔一段时间，统计过去某个时间段内的数据。比如，对热点搜索词语进行统计，每隔 10 秒钟输出过去 60 秒内排名前十位的热点词
                                    窗口长度（window length）：每次统计的数据的时间跨度，在例子中是 60 秒；
                                    滑动间隔（sliding interval）：每次统计的时间间隔，在例子中是 10 秒。

                    10. Spark Streaming 的主要缺点是
                            实时计算延迟较高，一般在秒的级别(不支持太小)。这是由于 SparkStreaming 不支持太小的批处理的时间间隔。无疑 Spark Streaming 是一个准实时系统。别的流处理框架，如 Storm 的延迟性就好很多，可以做到毫秒级。

                            每个数据块就是一个 RDD，所以 Spark Streaming 有 RDD 的所有优点，处理速度快，数据容错性好，支持高度并行计算


                    11.Structured Streaming
                                0.基于DataSet/DataFrame API，这套 API 在某种程度上统一了批处理和流处理
                                1.流数据处理最基本的问题就是如何对不断更新的无边界数据建模
                                2.把数据看成一个无边界的关系型的数据表。每一个数据都是表中的一行，不断会有新的数据行被添加到表里来。
                                3.Structured Streaming 的模型在根据事件时间（Event Time）处理数据时十分方便
                                4.更像是实时处理，能做到用更小的时间间隔，最小延迟在 100 毫秒左右
                                5.对事件时间的支持

                            ==> 所以任意的无论流操作其本质都是一个小的list处理，而不是一条一条。所以sql api是支持的。group.filter.
                            ==> 触发也不是一条一条触发

    8.spark vs flink
            1.不能继续用微批处理的模式，而要想办法实现真正的流处理，即 ' 每当有一条数据输入就立刻处理，不做等待 ' 。
                    1.这个不是应该考虑实际的逻辑，如果后台处理复杂，如何立即处理不堆积呢？
            2.基于操作符（Operator）的连续流模型
            3.Flink 中最核心的数据结构是 Stream，它代表一个运行在多个分区上的并行流。

              在 Stream 上同样可以进行各种转换操作（Transformation）。与 Spark 的 RDD 不同的是，Stream 代表一个数据流而不是静态数据的集合。所以，它包含的数据是随着时间增长而变化的。而且 Stream 上的转换操作都是 ‘ 逐条  
            ’进行的，即每当有新的数据进来，整个流程都会被执行并更新结果。这样的基本处理模式决定了 Flink 会比 Spark Streaming 有更低的流处理延迟性。

            4.source - sink 

            5.在 Flink 中，程序天生是并行和分布式的。一个 Stream 可以包含多个分区（Stream Partitions），一个操作符可以被分成多个操作符子任务，每一个子任务是在不同的线程或者不同的机器节点中独立执行的。


            相同点：
                都基于内存计算；
                都有统一的批处理和流处理 API，都支持类似 SQL 的编程接口；
                都支持很多相同的转换操作，编程都是用类似于 Scala Collection API 的函数式编程模式；
                都有完善的错误恢复机制；
                都支持 Exactly once 的语义一致性。
            不同点：   
                1.flinK来一笔操作一笔 
                2.Spark 对机器学习的支持很好，因为可以在内存中缓存中间计算结果来加速机器学习算法的运行。但是大部分机器学习算法其实是一个有环的数据流，在 Spark 中，却是用无环图来表示。而 Flink 支持在运行时间中的有环数据流，从而可以更有效的对机器学习算法进行运算。
                3.社区

    选择
            Spark
                数据量非常大而且逻辑复杂的批数据处理，并且对计算效率有较高要求（比如用大数据分析来构建推荐系统进行个性化推荐、广告定点投放等）；
                基于历史数据的交互式查询，要求响应较快；
                基于实时数据流的数据处理，延迟性要求在在数百毫秒到数秒之间。
            flink
                用于各种需要非常低延迟（微秒到毫秒级）的实时数据处理场景，比如实时日志报表分析。
    

    9.Beam
            1.Beam 提供了一套统一的 API 来处理这两种数据处理模式，让我们只需要将注意力专注于在数据处理的算法上，而不用再花时间去对两种数据处理模式上的差异进行维护。
            2.统一的编程模型思想，而我们可以通过这个统一出来的接口来编写符合自己需求的处理逻辑，这个处理逻辑将会被转化成为底层运行引擎相应的 API 去运行。
            3.第一层，是现在已有的各种大数据处理平台（例如 Apache Spark 或者 Apache Flink），在 Beam 中它们也被称为 Runner。
                第二层，是可移植的统一模型层，各个 Runners 将会依据中间抽象出来的这个模型思想，提供一套符合这个模型的 APIs 出来，以供上层转换。
                第三层，是 SDK 层。SDK 层将会给工程师提供不同语言版本的 API 来编写数据处理逻辑，这些逻辑就会被转化成 Runner 中相应的 API 来运行。
                第四层，是可扩展库层。工程师可以根据已有的 Beam SDK，贡献分享出更多的新开发者 SDK、IO 连接器、转换操作库等等。
                第五层，我们可以看作是应用层，各种应用将会通过下层的 Beam SDK 或工程师贡献的开发者 SDK 来实现。
                最上面的第六层，也就是社区一层。在这里，全世界的工程师可以提出问题，解决问题，实现解决问题的思路。

            4.模型
                    1.窗口（Window）
                    2.水印（Watermark）
                        水印是用来表示与数据事件时间相关联的输入完整性的概念。对于事件时间为 X 的水印是指：数据处理逻辑已经得到了所有事件时间小于 X 的无边界数据。在数据处理中，水印是用来测量数据进度的。
                    3.触发器（Triggers）
                    4.累加模式（Accumulation）


                    1.pcollection -- 可并行计算的数据集
                            1.无序
                            2.没有“固定大小”
                    2.transform
                    3.pipeline 
                            1.对于数据处理逻辑的一个封装，它包括了从读取数据集，将数据集转换成想要的结果和输出结果数据集这样的一整套流程。


                    match

            5.beam应用
                《30-36》



