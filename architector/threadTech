
1.并发
		1.背景
				1.职位要求
				2.面试踩坑
				3.从小牛到大牛必经之路
				4.并发是众多框架的核心
				5.juc是并发大神doug lee灵魂杰作 ,经典典范

		2.使用 --> 原理 
		3.学习流程
				1.并发学习流程图.png
				2.并发学习架构图.png     新手学技术、老手学思维、高手学格局
		4.学习方式  -- 整合而不是零碎
				1.对juc库分门别类给个击破
				2.场景+作用+原理+环环相扣
				3.线程“安全+治理+控制”三位一体
		5.Java并发成神之路——精通JUC并发工具十八般武艺 思维导图  <=== todo: 没有拿到

		6.鸟瞰并发
				1.为了并发安全
					1.从底层原理分类
						1.互斥同步 --先独占
								1.锁     悲观锁
										1.synchronized
										2.reentrantlock
										3.readwritelock
										..
								2.同步工具类
										1.CollectionUtils.synchronize...
										2.vector
						2.非互斥同步
								1.原子类 乐观锁 
										1.基本类型 
												atomicInteger 
												atomicBoolean
										2.数组(数组里得元素都可以保证原子性？==数组本身呢？)    
												atomicIntegerArray 
												atomicRefrenceArray
										3.引用类型  
												AtomicRefrence 
												AtomicStampedRefrence(带时间戳，解决ABA问题)
												AtomicMarkableRefrence 
										4.升级 升级普通类型为原子类型
												AtomicIntegerFiledUpdater
										5.Adder加法器 性能比atomic好
												LongAdder
										6.Accumulator累加器 性能比adder好
												LongAccumulator

						3.结合互斥和非互斥方案

										1.concurrentHashMap  cas + synchronized 
										2.copyonwriteArrayList  写写不共存
										3.并发队列		
												阻塞队列 - 线程池组成/mq组成
													1.arrayBlockingQueue
													2.linkedBlockingQueue
													3.PriorityBlockingQueue
													4.SynchronousQueue
													5.DelayedQueue
													6.TransferQueue
												非阻塞队列
													1.concurrentLinkedQueue
										4.concurrentSkipListMap和concurrentSkipListSet
						4.无同步方案 
								1.threadlocal  线程封闭
								2.final		   不可变

					2.从使用者角度
						1.避免共享变量
								1.线程封闭
										1.threadlocal
										2.栈封闭
						2.共享变量，加以控制和处理
								1.互斥同步
										1.synchronized
										2.lock接口相关类
								2.final关键字
						3.成熟工具类
								1.atomic包工具类
										1.结合上面的原子类

								2.线程安全得并发容器
										1.concurentHashmap
										2.copyonwritearrayList
										3.并发队列
										4.concurrentSkipListMap / concurrentSkipListSet
										5.同步工具类

						

				2.管理线程、提高效率
						1.线程池
								1.executor
								2.executors
								3.executorService
								4.常见线程池
										1.fixedThreadPool
										2.CachedThreadPool
										3.SchedualThreadPool
										4.SingleThreadPool
										5.ForkJoinPoll
										6.自定义线程池

						2.获取子线程运行结果
								1.callable
								2.future
								3.futureTask
								4.CompletableFuture


				3.线程协作,以满足业务逻辑 这些是aqs的表现
						1.countdownlatch
						2.cyclicBarrier
						3.semaphore
						4.condition
						5.exchanger
						6.phaser

=============是否深入思考和落地====类似于对缓存的思考============

		7.线程池  - 代码：threadpool
				1.是什么
						1.资源有限、计划经济、提前预估限制、合理统筹、灵活调整、不浪费、不丢失
						2.复用线程、无需创建和销毁、资源消耗 内存、cpu、计数器...
						3.加速
						4.统一管理，比如停止

					场景
						1.服务器
						2.创建5个以上的线程，考虑用池化

				2.创建和停止
						1.线程池构造函数含义
								线程池构造参数的参数.png
								线程池添加线程规则.png 
										队列塞满才认为是忙碌，才去扩展线程到max-thread
								

								keepAliveTime:上面的操作流程包含了5个要素，keepAliveTime对冗余(非高峰)对max-core线程回收
								threadFactory:Executors.defaultThreadFactory , 自己指定可以指定 线程名、线程组、优先级、是否是守护线程等
								workqueue:
										1.直接交换 synchronousQueue  -- 意味着不去暂存
										2.无界队列 linkedBlockingQueue
										3.有界队列 arrayBlockingQueue	***
								拒绝策略
										1.记录日志

						
				3.常见线程池特点和用法 有的放矢
						1.线程池应该手动创建还是自动创建
								1.Executors.newFixThreadPool   无界队列  oom
								2.Executors.SingleThreadPool
								3.cacheThreadPool  
										核心为0--直接交换 synchronousQueue 不能存储  + 线程数最大是max_value;任务结束后，60s会回收掉
								4.schedualedThreadPool      
										threadPool.scheduleAtFixedRate(new Task(), 1, 3, TimeUnit.SECONDS);
										按照自己的业务需求进行 ‘ 推迟 ’相关的操作
										定时器

								5.自定义
								6.workStealingPool : 
										线程是需要执行子任务的 比如矩阵计算，二叉树遍历
										窃取，线程把自己的子任务的线程放到自己队列，如果有的线程执行完了。可以帮助。
										不保证顺序
										递归


						2.线程池的线程数量设定为多少合适
								core.
										cpu密集 ： 加密/hash/计算距离       						2倍cpu
										io密集  ： 读写数据库/网络通信/读写文件					10倍cpu 因为大多数在等待io
										core=cpu核心数 * (1+平均等待/平均工作时间) ==> 压测

										读取系统的cpu个数 ： Runtime.getRuntime().availableProcessors()

						3.停止线程池的正确方法
								1.shutdown : 执行和队列中都执行完，不接受新任务  优雅关闭 
										isShutdown:执行了shutdown就返回true,和任务是否执行完无关
										isTerminated:线程池是否真正全部执行完成了
										awaitTermination:等待，如果线程执行完毕返回true,否则返回false.检测
												1.所有执行完成，返回true
												2.等待超时
												3.被中断
								2.shutdownnow：
												1.interrupted掉正在执行的线程
												2.返回存在队列中的任务，返回 【 未执行的任务 】，重新执行/写日志
								3.cancel
										1.异步判断后，取消后面的任务



				4.任务太多，如何拒绝  
						1.所有线程都在执行，并且队列慢 执行拒绝策略
						2.线程池关闭

						1.AbortPolicy  : 抛出异常
						2.discardPolicy: 丢失任务
						3.discardOldestPolicy: 丢掉最旧的
						4.CallerRunsPolicy: 提交任务的线程去做
								1.无损 2.负反馈，提交速度降低下来

				5.钩子方法，给线程池提添料
						1.每个任务执行前后记录日志 
						2.................  统计
						3.暂停线程池

						PauseableThreadPool.java

				6.实现原理、源码分析

				7.注意点  --哪个是线程池.png 
						1.executor  	      -- execute
							|继承
						  executerService     -- submit / invokeAll / shutdown / submit 
						    |
						  ThreadPoolExecutor 和上面一样
						  
						  executors   工具类，快速创建，类似Collections

						2.submit-优先使用 / execute 
								1、submit在执行过程中与execute不一样，不会抛出异常而是把异常保存在成员变量中，在FutureTask.get阻塞获取的时候再把异常抛出来。
								2、Spring的@Schedule注解的内部实现就是使用submit，因此，如果你构建的任务内部有未检查异常，你是永远也拿不到这个异常的。
								3、execute直接抛出异常之后线程就死掉了，submit保存异常线程没有死掉，因此execute的线程池可能会出现没有意义的情况，因为线程没有得到重用。而submit不会出现这种情况。

						3.不需要重复启动start(),而是一直去从队列中取task去执行

						4.threadPoolExecutor.submit(() -> {  java8 lamdar来代替内部类


		8.threadlocal
				1.场景
						1.每个线程需要独享某个对象(工具类线程不安全 simpleDateFormat Random)								
						2.每个线程内需要保存全局变量(例如拦截器获取信息)，可以在不同的方法间传递参数，而不用在接口间传递 vs netty中参数Context 或者 其他代码中的context
						  相当于一种隐形的传递，利用线程这个key,避免参数传递繁琐 --- 同一个线程不同方法间数据共享(跨对象/跨方法)
						3.中间状态保存-暂存且跨多个方法才去访问，为了避免没用的中间方法调用时候，所以放到threadlocal  <--- 多算法时候使用的问题
				
				2.threadlocal.java 一步步从同步 - 异步 - 线程池 - 静态对象(一个对象) - 锁 - threadlocal 

						1.注意对象创建，特别要注意多线程中代码对对象的创建
						2.simpleDateFormat从表面上虽然共享，但没有update操作，理解为都是利用了模板。
						  但是从 '源码底层，这个操作被付于其他对象，导致这个过程中发生了不安全！！'
				
				3.引入threadlocal，这里的给每个 ' 线程 '(线程池中的每个线程而不是每个task)，线程池中线程执行任务肯定是一个接着一个
				  所以不会有线程问题.

				4.避免传递参数比如user,判断,===> 线程(请求)保持自己的全局信息
						1.参数传递 - 全局map(不安全) - 各自map - 多线程访问所以安全concurrenthashmap有损耗(底层也是cas/锁) - threadlocal
						2.这个第二种方式使用中无需initail,第一种通过初始值创建进去，第二种
						  

						  UserContextHolder.holder.set(user); 这种赋值不会有线程安全吗？
						  同样是一个对象，set修改，他自己是包含了concurrenthashmap吗？

				5.好处
						1.达到线程安全
						2.不需要加锁，提高执行效率
						3.更高效的内存，更小的内存，比如上面simpledateformat
						4.免去传参 耦合低，优雅

				6.原理源码分析 -- 谁是key,持有关系
						1.ThreadLocal原理图.png 
								一个thread对应一个threadlocalmap对应多个threadlocal(因为一个线程可以使用多个threadlocal 比如日期工具threadlocal / 参数传递threadlocal)
						2.get 
								thread - threadlocalmap - get(this) this就是threadlocal - 返回初始化值或者initail值 。ThreadLocal原理图.png 
						3.set
								set的也是key是threadlocal set(value)==threadlocalMap.set(this,value),线程持有threadlocalmap成员

						4.remove 

						类似的hashmap 不同：
								1.处理hash冲突  threadlocal中使用向下探测，不会使用拉链和红黑树

				7.方法
						1.initailValue() : 返回当前线程对应的初始值，这是个延迟加载，只有调用get的时候，才会触发。初始化hashmap,string,日期格式化
										   如果方法在调用get前执行了set,那就不会执行initailValue方法了
										   每个线程最多调用一次改方法，如果调用remove,在调用get(),就会再次执行改方法
										   一般使用匿名类重写initailvalue方法
						2.set()
						3.get()
						4.remove()         删除该threadlocal中的内容，threadlocal对象就是null

==============>>> 还是有问题的 <<<<==================

				8.问题：
						0.底层是concurrenthashmap吗?
								1.不是，key不是thread而是将当前对象放到threadlocalmap
								2.ThreadLocal.ThreadLocalMap threadLocals = null;不是安全的
								3.存储结构的问题，线程之间有自己的threadlocalmap，所以线程之间不公用，没有安全问题

						1.是否是虚引用，可否稳定 ，是否会在传递中丢失
								1.强引用 对象被生命周期类的变量所引用。
								  软引用 SoftReference包装的对象是软引用,软引用在回收之后还是内存还是不够的情况下会被回收。
								  弱引用 WeakReference包装的对象是弱引用,下一次gc时会被回收。
								  虚引用 PhantomReference包装的对象是虚引用，无法通过虚引用访问对象的任何属性或函数，下一次gc时会被回收。
								

								2.不会 因为有用到的地方就会有强引用
								3.正确的步骤	使用完之后remove / 线程结束 / 利用weakRefrence自动回收 threadlocal 但此时value是回收不掉的呀。所以泄漏？
								4.正常使用是不会有影响的

								？有人说使用static来解决

					    2.在继承中，丢失传递
					    		1.inherit
					    		2.get / set 来传递
					    		3.封装到参数中作为父类，在上层对该参数处理；而不是每一步get/set


					    3.为什么加static ?





===> 对threadlocal的组成结构没透彻



						2.如何发生泄漏 
								1.是什么
										1.对象不在使用，但占用的内存一直没有回收		
								2.具体
										1.key
												1.static class Entry extends WeakReference<ThreadLocal<?>> {
												2 super(k); threadlocal就是弱引用， value = v;强引用
												3.key会被gc回收 value是强引用
												4.正常情况，线程终止；threadlocalmap;但如果是线程池呢，没有关闭，没有销毁数
												  所以只能通过remove清空。
												

										2.value
												5.断开if key = null,将value = null
												6.如果一个threadlocal不被使用，那么set/remove/rehash方法也不会被调用；
												  线程又不中止，value就一直存在，就发生
												7.但是如果一个threadlocal不被使用，那么实际set/remove/rehash不被调用，如果线程又不中止，那么调用链一直存在，导致value泄漏

												7.必须业务最后调用remove或者拦截器。


						3.context场景使用
						4.npe
								1.ThreadLocalNPE.java  Threadlocal<Long> vs long get... 转换异常空指针
						5.共享对象
								1.如果每个线程set进去的对象就是共享对象(spring中单例/static修饰)，即使使用了threadlocal包装，get()出来仍热是对象本身，同样有并发问题
						6.所以说threadlocal是针对线程的，栈的；简单理解为<thread,值>但实际比这个复杂
						7.不要强行使用，必须满足上面的两种条件下才使用



				9.threadlocal在框架中的使用
						1.spring.RequestContextHolder
										1.InheritableThreadLocal
						2.spring.DateTimeContextHolder

					问题：框架是如何处理上层来的 ' 多线程调用 '呢？




		9.锁  
				0.synchronized 
						1.类锁 vs 对象锁

				1.Lock接口
						1.作用
								1.必须使用锁，因为全局共享，计数
								2.为了性能，所以共享

						2.vs synchronized
								1.当synchronized不能满足使用，使用lock高级功能

								1.效率低：锁的释放情况少，试图获得锁时不能设定超时，不能中断一个正在试图获得锁的线程
								2.不够灵活：加锁和释放锁的时机单一，每个锁仅有单一条件(某个对象)，可能时不够的
								3.无法得知是否获得锁

						3.方法
								1.lock
										1.获取锁，如果被占用则等待
										2.lock不会在异常的时候自动释放锁，必须添加finally,保证在异常发生的时候释放锁	

								2.trylock -- TryLockDeadlock.java
										1.因为lock不能被中断,所以一旦陷入死锁就会永久等待
										2.避免死锁 trylock导致获取不到不会像lock一样阻塞那里，而是继续往下走，在finally中释放已持有的锁,
											结合随机睡眠解决 + for来再次获取
													lock1.unlock();
                           							Thread.sleep(new Random().nextInt(1000));

								3.trylock(long time ,timeunit timeunit)
										
										===> 死锁至少两把锁，且必须遵循写法 ，一层一层写规范小心遗漏				
											 Lock lock = ...;
		    								 * if (lock.tryLock()) {
		     								 *   try {
		     								 *     // manipulate protected state
		     								 *   } finally {
		    						  		 *     lock.unlock();
		    								 *   }
		    								 * } else {
		    								 *   // perform alternative actions
		     								 * }}</pre>

		     							==> 模拟死锁

								4.lockInterruptibly  LockInterruptibly.java
											{lock.lockInterruptibly();
											try..final...}
											1.根据业务判断是否需要catch，描述清楚是睡眠vs获取
											2.类似lock.lock(),相对于这个可以lockInterruptibly可在主函数中执行thread.interrupt()
											  这样就可以根据业务判断进行对应的 ’重要性打断操作‘


						4.可见性保证

								1.happen-before原则-保证
										1.事情发生，其他事情一定可以看到这个事情结果，最新值。则说明拥有happen-before能力
										2.锁（synchonized/lock）使得内存有这个特性；没用锁则不能保证线程a修改，b看到 



				2.锁分类

						1.从多个角度出发，一个锁可能是多个类型的锁，一种类型下可能有多个不同实现的锁，不冲突
						2.锁分类.png 
						3.具体比较
								1.悲观锁(互斥同步)/乐观锁(非互斥同步)  -- 思想
										1.优缺点(悲观锁)
												1.阻塞和唤醒性能消耗  用户态切换，上下文切换，检查是否要唤醒 ，乐观锁无需挂起
												2.永久阻塞  如果有锁的线程永久阻塞，遇到无限循环或者死锁等活跃性问题，那么等待该锁的线程将得不到执行
												3.优先级反转 优先级低的持有锁，导致高优先级的无法执行

										2.是什么
												1.从触发机制  前者先尝试，失败就再试或调整 认为成功，失败概率低 /后者则先考虑面面俱到，在去执行，认为失败，成功概率低
												2.从锁住资源  悲观锁：锁住资源，如果不锁就可能造成数据错乱，保证万无一失。synchnoze/lock都是悲观锁，虽然前者优化前面有一段乐观过程，但还是悲观锁

												那乐观锁不是不能保证数据准确性吗？
														如果数据和我拿到的不一样，’ 说明有人修改了该数据，那就放弃刚刚计划的执行 ‘，选择放弃、报错、重试
														利用cas算法实现--- 原子操作即在 比较+交换

										3.应用
												1.PessimismOptimismLock.java 利用乐观和悲观实现
												2.git提交 乐观锁 远端版本和当前版本是否超前。不能使用悲观锁，因为你锁住资源，别人就无法提交了。无法合作了。
												3.db select ... for update 	+ update    悲观锁 当前操作不能有其他线程进行更新；
												     ...........where version = 1   	乐观锁
										4.开销
												1.悲观锁好处：一劳永逸
												2.乐观锁好处：上面提到的优缺点
												===>> 根据不同的场景进行区分采用不同锁  ==>> 人生也是这样
										5.场景
												1.悲观锁
														1.写入操作多
														2.临界区持锁时间长，减少不必要自旋操作
																1.临界区有io操作
																2.临界区代码复杂或者循环量大
																3.临界区竞争激烈

												2.乐观锁
														1.写入少，读取多
								
								2.可重入锁/非可重入锁
										1.预定电影票：CinemaBookSeat.java
										2.打印字符串：LockDemo.java  保证一段逻辑关联整体输出(这里的字符串)
										3.可重入体现：
												1.是什么
														1.同一个线程可以再次获取同一把锁
														2.不需要再次竞争，无需释放，可以直接使用
														3.递归锁
												2.synchronized

												3.好处
														1.避免死锁 
															 一个持有锁的方法，调用另一个需要该锁的方法，这里就是可重入了。这种逻辑是存在的
														2.提升封装性
														     避免一次次解锁、加锁
												4.演示
														1.GetHoldCount.java
														2.RecursionDemo.java
										4.源码
												0.底层是AQS
												1.可重入锁和不可重入锁源码对比.png
												2.isHeldCurrentThread 
												3.getQueueLength  二者在开发调试中使用

								3.公平锁/非公平锁
										1.是什么
												1.公平：按照线程请求顺序来分配锁
												2.非公平：不完全按照请求来分配，在一定情况下，可以插队。'在合适的时机插队'，而不是盲目插队

												火车站买票
														1.从呆萌转到执行 从阻塞到执行 避免空档期
														2.第一个人()返回来问几点发车 本质上是没有影响到我买票这个操作的
														
														==> 问题：如何判断插队的是否可以迅速完成呢？能否在应该执行的时候释放临时占用锁？

										2.为什么会有非公平锁 - 默认非公平锁
												1.避免唤醒空档期，增加吞吐量

												1.在wait queue中1执行完，默认是唤醒2，2-3-4都在等待，如果此时5来临时占用是允许的，这就是非公平

										3.公平/非公平代码
												1.FairLock.java
														1.PrintQueue 打印两次才能完成，为了公平不公平演示。
														2.Thread.sleep(100);顺序启动
														3.执行结果就是0-1-2-3..先打印第一张完成后，因为队列中其他等待，所以依次都打印第一张，
														  再都打印第二涨 。 如果是非公平锁，0又想拿锁，1需要时间，优先将给到了线程0
										4.特例
												1.trylock不遵守公平原则，即默认带着插队属性的

										5.优缺点
												1.优点
														1.公平锁 		： 一定有执行机会
														2.非公平锁		： 更快
												2.缺点
														1.公平锁         ： 慢
														2.非公平锁		 ： 饥饿 
										6.源码
												1.公平锁判断是否队列等待 

								4.共享锁/排他锁 ReentrantReadWriteLock - 读多写少场景
										1.是什么
												1.共享锁 读锁 多个线程共享读，不可update
										2.特点
												1.多个线程申请读锁，可以申请到
												2.如果有线程持有读锁，来线程申请写锁，那么写锁需要等待读锁释放掉才能获取到
												3..............写............ 写/读.....读写锁都需要等待

												多读一写
										3.代码
												1.ReentrantReadWriteLock具体用法 1.png/2.png/3.png 
												2.CinemaReadWrite.java   多读一写
										4.进一步
												1.选择规则
												2.读线程插队
														问：2-3读、4想写所以等待、5读 5可以插队吗？这里可都是读锁
														答：性能高，但造成4饥饿 
														答：5排再4后面，这样可以写了；进来后先判断队列头部是否读，读，则让5插队，写，则乖乖排队 <=== 本质实现

														NonfairBargeDemo.java

												3.升降级 Upgrading.java
														问：写入日志-读取 不希望被打断 只有一开始写，后面读 ； 所以再中间过程中降级
														答：在不释放写锁情况下直接readLock.lock();

														只能降级不能升级，升级造成死锁 <-- 如果具备了这种能力，a需要b释放读锁才能到写锁，同理，b也是，导致死锁

												4.其实自己可以定义实现升级，只要是单个线程中，没有含义，升降级不就是为了提供效率么


									5.自旋锁/阻塞锁
											1.背景
												 同步资源锁定时间短，线程切换、上下文切换远远大于不停检测
											2.实现  cas
												 1.unsafe
												 2.do..while..
											3.SpinLock.java
											4.场景
												 1.多核服务器，在并发度不是特别高的场景下，比阻塞锁效率高
												 2.临界区短小

									6.中断锁/不可中断锁
											1.是什么
												 1.synchronozed不可中断、lock可中断 tryLock(time)\lockInterruptibly响应中断
												 2.一个线程等，如果不想等，’ 也 ‘可以中断 ，更灵活
											


				3.锁优化
						1.自旋锁和自适应
								1.自适应：尝试多次自旋后，转为阻塞锁；并且可以通过尝试次数设定下次旋转次数
						2.锁消除
								1.私有、无需加锁
						3.锁粗化
								1.有些情况，如果对一个对象反复加解锁，合并在一起，jvm动态检测
						4.锁细化
								自己写代码时
								锁代码块而不是方法
						5.减少锁次数
								将消息队列将写入暂存，一次写入多个，而不是频繁加解锁
						6.避免人为制造热点
								维护计数直接取出，而不是遍历获取总数
						7.锁中不要包含锁，避免死锁
						8.合适工具类

				4.总结
						

		10.原子类
				1.是什么
						1.一个操作不可中断，即便在多线程情况下也可以保证
						2.....concurrent.atomic包
						3.和锁一样都是为了线程安全
								1.粒度更细 将竞争范围缩小到变量级别
								2.性能较高 在高度竞争下不如锁 为什么？
				2.类型
						1.6类原子类纵览.png
				3.示例
						1.atomicInteger
								1.get
								2.getAndSet 获取当前值并设置
								3.getAndIncrement
								4.getAndAdd
								5.compareAndSet 

								private static volatile int basicCount = 0; 每个修饰符确定含义  volatile只能保证可见不能保证原子
								AtomicIntegerDemo1.java
						
						2.AtomicIntegerArray
								1.threadsDecrementer[i].join();使用join阻塞
								2.array.getAndIncrement(i); 循环为数组中的每个变量加1
								3.对于整个数组是安全的，通常都是执行整个数组的每个要素进行操作
								4.这个操作过程中，不要关注for，而是线程和资源

								AtomicArrayDemo.java

						3.AtomicRefrence
								1.作用
										1.保证一个对象原子性
								2.SpinLock.java
						
						4.AtomicFiledUpdater  -- 把普通变量升级为原子类
								1.偶尔的场景下需要原子操作，比如某个时间点有多线程访问，平时都是普通变量
								2.AtomicIntegerFieldUpdaterDemo.java 
										1.将线程、main、数据结构(static 类)放在一起，所以感觉乱，所以清晰每个部分的作用
										2.这里的并发点在那里？每个线程有自己的Candidate对象，只是公用了AtomicIntegerFieldUpdaterDemo对象
										  竞争点在那里？？？
										3.这里代码设计严谨性好
								3.特点
										1.底层反射 可见范围 不可修饰private
										2.不能被static修饰

						
						5.Adder/Accumulator累加器
								1.Adder相对于atomicInteger:
										空间换时间 
										竞争激烈时，不同线程对应不同的cell进行修改，降低冲突，利用多段锁理念(concurrentHashmap)，提高并发性

							    2.LongAdderDemo.java
							    3.AtomicLong的弊端.png ===》 LongAdder带来的改进和原理 .png / 2.png /3.png 
							    		每次flush/reflush将数据刷新到内存和每个线程中

							    	原理：每个线程有自己的计数区段(相当于数组段)，无需同步，只有最后统计的时候，再去汇总 
							    	      base变量和cell[] base：不激烈时使用  cell[]:激烈时，分段 曹 hash

							    4.场景
							    		1.竞争激烈 
							    		2.统计求和 只是求和 没有cas方法
							    5.Accumulator
							    		1.LongAccumulatorDemo.java
							    				1.new LongAccumulator((x, y) -> 2 + x * y, 1) --- 流处理
							    				2.灵活 可以写成 Math.max(x,y) 进行替换

							    				3.多线程并行计算、而for串行的
							    						 **** <==== 计算顺序不能要求，不影响最终结果才能用。 所以2+x*y这种是不对的，因为要求顺序。但x*y这种没有顺序是可以的


		11.CAS
				1.是什么
						1.并发 不可打断 一条cpu指令保证
						2.乐观的，先计算在判断能不能写，如果和拿到的不同，则不改，否则改

						SimulatedCAS.java 
						TwoThreadsCompetition.java

				2.场景
						1.乐观锁 - db 
						2.并发容器
						3.原子类

				3.原子类如何利用cas
						1.加载unsafe工具，用来直接操作内存数据
						2.unsafe实现底层
						3.使用volatile实现可见性

						unsafe:提供硬件级别的操作  
							   https://tech.meituan.com/2019/02/14/talk-about-java-magic-class-unsafe.html
				4.缺点
						1.aba问题 		 版本号解决
						2.自旋时间长，cpu消耗


		12.final
				1.是什么 不变性 immutable 
						1.如果对象被创建后，状态不能被修改，那么他就是不可变的
						  person对象 age和name都不能在变 引用也不可变 。 比如引用传递后修改呢?   ==>*** 注意
						  不需要采取额外的措施就是安全的
				2.作用
						1.类   防止继承
										1.不可被继承

						2.方法 防止重写
										1.不允许修饰构造方法
										2.子类中可以直接写static和父类同名的方法，并不是重写，只是属于子类。static绑定类。不是override

						3.属性 防止修改  --- 对于对象引用不可变，并不是对象不可变。比如final Person p = new Person  . p=new Person()这种操作是不可以的，但是你可以p.setxx其中的person属性，只要person的属性不是final
										双final   赋值后不可修改

										赋值时机：
										  成员
											final 
												1.声明即等号右边赋值
												2.构造函数赋值
												3.类初始化代码块赋值
											
											static final
												1.声明即等号右边赋值
												2.static {} 

												不能不复赋值
										  local -- 局部 -- 方法内
										  		1.使用前赋值


						4.保证不变性，保证线程安全，不需要额外同步开销


				3.用法
				4.注意点
						1.final修饰属性对象，引用不可变，而不是引用内部对象不可变
						2.编程习惯 见名之意
				5.不变性
						1.所有属性声明为final 
						2.对象创建后，其状态就不能改变 比如没有 ' set方法 / 其他改变方法 ' 
						3.对象创建过程中没有逸出

						1.栈封闭  StackConfinement.java
				6.面试题
						1.FinalStringDemo1.java  FinalStringDemo2.java
								1.final是编译时就确定的，在池中，所以拿来直接用，生成wukong2，并且和a一样都在常量池 所以 ==
								2.非final是具体执行时生成的，所以在堆上。所以一个堆一个栈，并不是一个对象


		13.并发容器
				1.概览
						1.历史
								1.Vector hashtable  性能/抛出异常
								2.Collections.synchronized() 
								3.ConcurrentHashmap / copyOnwriteArrayList 只有在写多读少情况下，Collections.synchronized(new ArrayList)才会好于2中 
						
				2.concurrentHashmap	
						0.
								HashMap分析 1.7 1.png
								HashMap分析 1.7 2.png
								HashMap分析 1.8 1.png
					    		HashMap分析 1.8 2.png
								Java 8 HashMap结构.png
								

						1.map特点 -- key不可变，即hash值不可变
								Map接口1.png  linkedHashmap:保证了插入顺序 / treeHashMap:按照顺序一定定义顺序排序
								Map接口2.png

								List接口.png  TreeList -- java.xx.collections中
								hashmap默认初始化：16 负载因子：0.75f
						2.hashmap缺点
								1.同时put碰撞导致数据丢失  :多个线程算出相同的hash值，put导致其中n-1个数据丢失
								2.同时put扩容导致数据丢失  ：......同时扩容，扩容后的数组只能保留一个，其他n-1个数据丢失
								3.死循环造成cpu 100%      ：死循环 
										1.https://blog.csdn.net/g6U8W7p06dCO99fQ3/article/details/104681428

						3.多线程调试
								1.使用debug thread功能
								2.将上面的分析在rehash地方出现问题，将两个线程同时停在rehash的地方，可以在idea的左边查看哪个线程
								3.点击开始，这时就模拟了多线程同时到达，复现上面的死循环

						4.底层结构
								JDK1.7的ConcurrentHashMap实现和分析 1.png
								JDK1.7的ConcurrentHashMap实现和分析 2.png

								 segment : 代码1k行 JAVA7concurrentHashmap实现分析.png  继承自Reentrantlock/默认16线程，最多支持16个写

								JDK1.8的ConcurrentHashMap实现和分析 1.png

								 红黑树：   代码6k行 

						5.特点
								1.key/value必须都不为null
								2.===> todo:描述put /get 方法  https://segmentfault.com/a/1190000021237438
								  getval流程.png / putval流程.png 

								  ***********************
						6.1.7--1.8concurrenthasmap升级
								1.提供并发性 1.7 ： 16个  1.8：每个node都独立
								2.hash碰撞       ：拉链      ：拉链 + 红黑树 加快查找 避免倾斜造成问题
								3.保证并发安全   ： 锁        ： cas + synchonized
								4.查询复杂度     ：o(n)       : o(logn)

							 为什么将链表超过8使用红黑树？
							 	1.元素少的时候，链表占据空间更小
							 	2.利用泊松分布.png 查看当超过8时，概率小
							 	3.为了平衡查询，转为更耗空间的红黑树
							 	4.日常中，达到旋转的概率不高？？？ 16 * 8 = 128个之后就比发生呀？

						7.concurrenthashmap 坑 --- 使用问题，不是说一个线程工具类安全的，你怎么用都安全，要理解作用点
								1.OptionsNotSafe.java
										1.concurrenthashmap保证多个线程同时put不会错乱，并不能保证  ‘ 复合操作 ’ 
										从get(x) -- score+1 -- put("",new score) 并不能保证线程安全

										2.转为replace + while + break 替代计划使用synchronized同步

								2.putIfAbsent 组合操作/原子操作 避免使用synchronized操作
						

						8.并发安全问题
								1.作为缓存保存时，能否使用普通hashmap /如果多个请求访问呢？会造成事故


						9.红黑树特点    
								1.节点必须是红色或者黑色，但根节点必须是黑色
								2.红色节点不能连续(红色节点的父亲孩子都不能是红色)
								3.从任一节点到子树中每一个叶子节点的路径包含相同数量的黑色节点
								4.所有的叶子都是黑色的

				3.CopyOnWriteArrayList - CopyOnWriteArrayset
						1.历史
								代替synchronizedList
								原因：锁粒度大、迭代时无法编辑
						2.场景
								读多于写，读要快、写要慢

								黑白名单，每日更新
								监听器：迭代操作远多余更新操作

						3.读写规则
								读写锁规则：读读共享、其他互斥(写写互斥、读写互斥、写读互斥)
								---------------  升级  -----------------
								CopyOnWriteArrayList规则：
										读取完全不加锁
										写入不会阻塞读取操作
										写入和写入之间同步

								CopyOnWriteArrayListDemo1.java CopyOnWriteArrayListDemo2.java
									1.支持迭代中add/remove 但是不影响迭代 ，拿着原来那份数据。 再次迭代就变了
									2.迭代的数据可能时 ‘ 过期的 ’
									
						4.原理
								1.不是直接操作该内存、而是copy-修改-重定向指针就完成了修改
								2.对读要求精确性没有那么高
								3.读写分离 使用完全不同容器
								4.不可变原理 新容器 、 旧容器不可变 避免同步操作
								

						5.缺点
								1.保证最终一致性、不能保证实时一致性、过期数据
								2.内存占用
						6.源码
								1.get没有加锁
								2.put reentrantlock进行加锁

				4.队列
						1.是什么、为什么
								1.用队列在线程间传递数据、生产者、消费者模式、银行转账
								2.考虑锁等线程安全问题从自己转移到队列上  				---    模式转换

						2.阻塞/非阻塞队列
								1.queue：底层是数组/链表 在这些上面进行特性控制，比如不能随机访问需要依次、先进先出、一头进一头出..
								2.blockingqueue:
												1.如果空无法取、如果满不能放
												一端给生产者、一端给消费者
												自身是线程安全的、所以生产者和消费者都可以使用多线程

												2.take:获取并移除头节点 ,没有则阻塞
												put:.............    ,满了则阻塞

												3.是否有界
												4.阻塞队列是线程池的重要组成部分

										1.ArrayBlockingQueue
												1.ArrayBlockingQueueDemo.java
												Java多线程——ArrayBlockingQueue的使用: https://blog.csdn.net/brucexiajun/article/details/80019384			
												Java阻塞队列ArrayBlockingQueue使用及原理分析:https://blog.csdn.net/csdn_xpw/article/details/78400225
												深入理解条件变量Condition:https://zhuanlan.zhihu.com/p/49301167
													使用很简单，只要将ArrayBlockingQueue的api比如offer/take调用即可；无需使用condition,notFull.notify...这些是ArrayBlockingQueue底层实现的
												
												
										2.LinkedBlockingQueue
												1.无界 integer.maxvalue

										3.PriorityBlockingQueue
												1.支持优先级 ，自然排序，不是先进先出
												2.无界对列 - put不阻塞，take没有则阻塞
												3.priority的线程安全


										4.SynchronousQueue
												1.容量0，不做存储，直接进/出 -- 很快
												2.极好的用来直接传递的并发数据结构
												3.Executors.newCachedThreadPool使用

										5.delayQueue
												1.无界队列
												2.Executors.SchedualedThreadPool

										6.方法
												 		1.put take                             判断取出如果没有阻塞
												 		2.add remove element				   判断取出如果没有抛出异常
												 		3.offer poll(取出删除)  peek(取出不删除) 判断取出如果没有返回boolean
								
								concurrentLinkedQueue:非阻塞队列
										1.非阻塞只有这一种
										2.链表
										3.cas非阻塞算法
										4.适用于对性能要求较高场景
										5.用的相对较少

										1.offer
												1.for死循环
												2.unsafe.compareAndSwapObject 

								阻塞队列和非阻塞队列 .png

						3.如何选择合适队列  -- ‘ 根据需求 ’ 
								1.边界
										1.有边界
										2.无边界
												1.容量大
												2.自动扩容

								2.空间
										1.arrayblockqueue比linkedblockqueue整齐 
								3.吞吐量
										1.linkedBlockqueue比ArrayBlockQueue性能好，前者有两把锁。

						4.concurrentSkipListMap  : 使用跳表数据结构进行快速查找
				5.总结		
					java.util.concurrent包下面
						1.concurrent*		: cas + synchronized
						2.copyOnWrite*		: 复制一份数据
						3.Blocking*			: aqs


		14.控制并发流程【做好线程之间的协调人】 - 控制并发流程
					1.是什么
							1.控制并发流程的工具类，作用就是帮助我们程序员更容易得让线程之间合作，让线程之间相互配合，来满足业务逻辑，比如让线程A等待线程B执行完毕后再执行等合作策略。
							2.将线程控制器的任务给到自己，让线程间配合完成业务需求

					2.常用的工具 -- 有哪些控制并发流程的工具类？ .png 
							1.countdownLatch
									1.倒数门闩
									2.购物拼团、大巴发车、人满发车、过山车
									3.倒数结束之前一直等待、

									2.方法
											1.countDownLatch(xx) -- 有几次倒数 特别是下面两种情况
											2.await
											3.countDown

									3.结合线程池 + for循环(多次读取)--load这里线程不安全bug <=== bjbk处理
									4.countDownLatch图示.png

									5.场景：
											1.：CountDownLatchDemo1.java 一个线程等待多个线程执行完成后，再继续自己的工作 比如质检/体检-不同指标最后都盖章就可以了  
											2.：CountDownLatchDemo2.java 多个线程等待同一个线程信号，同时开始执行            起跑发令/服务器压测(并发测试-等待统一信号)
											3.：CountDownLatchDemo1And2.java 复合操作
									6.注意点
											1.扩展 多个线程等待多个线程执行完成后，再同时执行 而不是上面的一等多，多等一
											2.该类不能重用，使用完后。要想重用，只能使用cyclicBarrier或者重新创建countdownlatch

							2.semaphore
									1.用来限制或者管理数量有限的资源
									2.污水排污
									3.可减可加 <--- 

									2.演变 -- 灵活的通过 ‘ 信号量 ’来缩小访问资源访问
											1.信号量1.png  信号量2.png
											2.信号量3.png 50个线程可能导致不可用？为什么不减少  
													===> 该流程中其他服务可以很快，可以满足50个线程处理，只有这个比较耗时的就需要 ‘ 特殊控制 ’，许可证
											3.信号量4.png  信号量5.png 信号量6.png  信号量7.png  信号量8.png
											4.信号量9.png
											5.信号量10.png
									3.使用流程
											1.初始化semaphore指定许可证数量
											2.需要请求时，调用acquire()/acquireUninterrupbily()
											3.执行完成后执行release
									4.方法
											1.构造   可指定公平不公平
											2.acquire() ...
											  tryAcquire()...返回Boolean  超时参数
											3.release
									5.代码
											1.SemaphoreDemo.java    
											2.不同申请不同个数的许可证 ===> 灵活配置不同权重 
									6.场景
											1.适用于 ‘ 速度慢 ’ 
											2.设置成公平
											3.获取和释放没有指定固定线程、可以跨线程、跨线程池、可以全局范围内访问不能太多
											4.可以实现countDownLoatch

							3.Condition
									1.原理
											Condition作用 .png
									2.方法
											1.signal / signall
											2.绑定在锁上面
									3.代码
											1.ConditionDemo1
											2.ConditionDemo2  <== 实现生产者消费者模式 平衡两端能力
													想象两条主线之间进行自己的流程时，在特定时间点，二者会 ' 交流、协作 '

									4.注意点
											1.如果说lock代替synchronized，那么condition用来代替wait/notify,所以用法和性质上一样
											2.await会自动释放持有的锁，和object.wait一样，不需要手动释放
											3.调用await之前，必须持有锁，否则会报异常
											4.相对于object ,一个lock锁可以和不同的condition。且二者是绑一起的

							4.cyclicBarrier
									1.10个人、每等够5个人就发车、循环使用 。 两个轮回
									2.CyclicBarrierDemo.java

									区别
											1.CyclicBarrier要等到固定数量的线程到达栅栏位置，而countdownloatch必须等到0
											  countdownloatch用于事件，CyclicBarrier用于线程
											2.可重复使用

							5.总结


		15.aqs（AbstractQueuedSynchronizer）并发灵魂
				1.思路
						1.
						2.


				2.为什么需要aqs
						1.锁 reentrantlock 和信号量 semaphore 共同点：闸门
						2.countdownlatch / reentrantWriteReadLock都有协作 ，同步功能
						==底层共同基类： aqs 上面公共部分的工具类并复用，每个锁/信号量都可以实现 ‘自己逻辑’

						AQS 1.png
						AQS 2.png
						AQS 3.png
						CountDownLatch源码分析 .png

				3.作用
						1.比喻群面/单面  上层 要人规则 semaphore:要指定人  countdownlatch:...
						2.hr 安排就做、叫号、叫号是否冲突、保证每个号都被叫道 都交给 aqs

						1.同步状态原子性管理
						2.线程的阻塞和解除阻塞
						3.队列管理

						用于构建锁、同步器、协作工具类的工具类(框架)


				4.重要性、地位
						1.基础类



				5.内部原理解析
						1.state  int  计数器  
								被volatile修饰，会被并发修改，所以所有的操作方法需要线程安全的。get../set/compareAndSetState
								这些依赖j.u.c.atomic包支持 ，下面是cpu指令
								reentrantlock中的重入次数

						2.控制线程抢锁和配合的FIFO队列
								AQS 3.png

						3.协作工具类实现获取/释放等重要方法
								依赖state的状态类判断能否获取/释放，不同的上层对其定义不同

				6.应用和源码
						1.写一个类，想好协作逻辑，实现获取/释放方法
						2.内部写一个sync类继承AbstractQueuedSynchronizer
						3.是否独占还是共享 tryAquire ..share

						countDownLoach
						semaphore
						reentrantLock



				7.自己实现流程控制类   OneShotLatch.java



				问题： 1.鸡生蛋/蛋生鸡疑惑  
							越来越底层、cpu支持、内存支持

				      2.既然有代码流程，就可能被cpu中断，那还怎么写？ 特别是底层的如何支持上层呢？
				      		中断没关系，有上下文维持，所以整体看起来就是完整的。
				      		所以有问题的就是 ‘ 当前上下文持有的变量是否会因为切换变化了 ’,所以这里就需要底层cpu支持-不可中断 / 内存可见性 volatile支持了

				      		????

				      3.为什么底层这么多死循环不会造成cpu爆炸？
				      		其实不是死循环，写了for(;;) / while(true) 但是中间方法有return /或者对应的方法判断 是否break...
				      		所以这根本不是死循环

				        那监听呢？监听一直存在那是死循环吧？ netty 


		16.获取子线程的执行结果【来而不往非礼也】  --- 治理线程第二大法宝 / 第一大法宝：线程池

				1.runnable vs callable runnable接口设计就是没有抛出异常、void
						1.没有返回值
						2.不能抛出check exception , 只能捕获   RunnableCantThrowsException.java

						为什么这么设计
						1.抛给的地方不是我们编写的，那只能在自己的地方解决掉，所以catch


						1.callable解决掉上面的问题

				2.future 
						1.构建方式
								1.线程池submit方法返回future对象
								2.用futureTask来创建

						2.callable和future关系
								1.利用future.get获取callable返回值；未执行完毕，则get()会阻塞当前调用线程
								2.isDone来判断任务是否执行完成
								3.cancle取消任务
						3.方法
								1.get() 
										抛出异常都是executionException,被包装   GetException.java 注意抛出时机，只在get()才会抛出，所以get前的操作都正常执行了
									    被取消 CancellationException  -- 重试
									    超时 timeOutException         -- 手动取消 在catch中
								2.cancle()
										如何取消
								3.isDone()
										只能说明线程执行完毕，与执行成功失败无关
								4.isCancled()		Timeout.java  / 参数true：强制中断interrupted /false 不强制 但二者都取消将不关心即使处理的返回，没关系了。没有对应输出
																	false含义是啥? 
																			不想要结果，只是。  对未执行影响最大，他不会在执行
									线程池的submit方法返回Future对象.png  : 先返回空的，等真正执行完再把值填入进去									

									cancle细节.png 


							用futureTask创建future
								1.线程池的submit方法返回Future对象2.png / 线程池的submit方法返回Future对象3.png
										既可以作为线程执行，又可以像future一样得到返回值
								2.FutureTaskDemo.java

						3.注意点
								1.为了避免在for中获取结果时，某个结果时间较长导致阻塞，那么无法返回结果，则可以使用complateFuture返回先执行完的结果
								2.future声明周期不能后退


				3.future和线程池组合使用
						1.submitAll返回List<Future<T>>    MultiFutures.java 可以优化直接提交list的任务
						2.循环取消未完成的任务





****************************结合缓存查看一个缓存中思考*****************************************************

		16.从0到1打造高性能缓存【学以致用，直击痛点】
				1.定义private static final Map mm = new HashMap<>();保证引用不会变，并不是map中内容不可变 / 增加安全性 ，明白这里时固定引用-缓存
				2.用装饰者模式来重构  ImoocCache2.java
						1.泛型
						2.同时实现了Computable.java
						3.引用了Computable.interface接口 即具体计算类
				3.性能差，不能并行计算  -- 因为缓存上的synchronized导致整体变慢
						ImoocCache3.java -  ImoocCache4.java 缩小代码块(同时读造成的问题造成不安全？？为什么？？？)
						--- 使用concurrentHashMap ImoocCache5.java
				4.在第一个还没计算完前，导致重复算了两次，缓存没有生效  计算两次.png ImoocCache6.java
				  -- 使用future和callable来解决  -- ImoocCache7.java 判断计算内容是否一样 。
				  用future包装 cache类型变为了key，future ,利用了future的后调用和concurrent的可见性保证
				5.用putiFAbsent解决同时放到得到null  putIfAbsent缓存中使用.png + ImoocCache8.java
				6.计算中抛出异常 while(true)重试  ImoocCache9.java
				7.缓存污染  ImoocCache9.java  cache.remove(arg);
				8.过期     ImoocCache10.java  定期扫描过期元素，过期就删除  定时线程池
				  避免雪崩  ................. computeRandomExpire 有个随机数

		17.压测
				1.用线程池测试缓存性能  ImoocCache12.java    countDownLatch同时并发到达
				2.用ThreadLocal确认时间的统一性  保证线程安全且生成simpledateformat 



*********************************************************************************


	问：
		1.原子类和乐观锁和cas关系
		类锁 / 对象锁区别？ 
		static修饰threadlocal以及如何在线程池中使其线程化： ThreadLocalNormalUsage05 
		static class  ** 创建和调用 
		thread的成员 *** 栈大小/ threadlocalmap 

		jmm -- 悟空 -- 慕课 《java并发实战精讲》
